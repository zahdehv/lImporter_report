\chapter{Introducción}
\label{chapter:introduccion}

% Párrafo Inicial: Importancia de la gestión del conocimiento y el potencial de los LLM.
En la era actual, caracterizada por una avalancha sin precedentes de información, la gestión eficaz del conocimiento personal se ha convertido en una habilidad indispensable, no solo para académicos e investigadores, sino para cualquier individuo que busque navegar y prosperar en este complejo panorama. La capacidad de capturar, organizar, sintetizar y recuperar información de manera eficiente es fundamental para el aprendizaje continuo, la toma de decisiones informada y la generación de nuevas ideas \citep{forteBuildingSecondBrain2022, ahrensHowTakeSmart2017}. Esta necesidad no es nueva; la práctica ancestral de tomar notas ha sido desde siempre un pilar en la construcción del saber individual y colectivo. Sin embargo, la reciente eclosión de los Grandes Modelos de Lenguaje (LLM, por sus siglas en inglés) presenta una oportunidad transformadora para potenciar estas prácticas. Estos modelos no solo ofrecen nuevas formas de interactuar con la información, sino que también abren la puerta a la automatización de la integración del conocimiento, unificando fuentes dispersas y facilitando la creación de comprensiones más profundas y conectadas. Este trabajo se sitúa en la intersección de estas dos corrientes: la perenne necesidad de gestionar el conocimiento personal y el emergente potencial de los LLM para revolucionar cómo lo hacemos.

\section{Gestión de conocimiento personal (second brain)}
\label{sec:gestion_conocimiento_personal}

% Definición de PKM y mención a Knowledge Workers.
La Gestión de Conocimiento Personal (PKM, por sus siglas en inglés: Personal Knowledge Management) emerge como una disciplina que sistematiza estos esfuerzos individuales. Se define como el proceso mediante el cual una persona recopila, clasifica, almacena, busca, recupera y comparte conocimiento en sus actividades diarias \citep{grundspenkisAgentBasedApproach2007}. En un entorno laboral cada vez más dominado por los denominados \textit{trabajadores del conocimiento} (Knowledge Workers) –profesionales para quienes el conocimiento es su principal activo–, la PKM se vuelve una competencia crítica para la productividad y el desarrollo profesional continuo.

% Desarrollo de la historia y relevancia de la toma de notas.
\paragraph{Note-taking}
La toma de notas es una práctica consustancial al esfuerzo humano por comprender y recordar el mundo. Desde los \textit{hypomnema} de la Antigua Grecia hasta los cuadernos de eruditos renacentistas, el acto de registrar información ha servido como una extensión de la memoria y una herramienta para el pensamiento crítico. Diversos estudios han corroborado que la toma de notas es una estrategia fundamental para mejorar el aprendizaje y la memoria \citep{jansenIntegrativeReviewCognitive2017}, ya que involucra procesos cognitivos de filtrado, organización y reformulación de la información.

\subsection{Metodologías de toma de notas}
\label{subsec:metodologias_toma_notas}

% Descripción de sistemas lineales y no lineales.
A lo largo del tiempo, se han desarrollado diversas metodologías para la toma de notas, que pueden clasificarse ampliamente en lineales y no lineales. Los métodos lineales, como la creación de esquemas (Outlining) o el método de frases (Sentence method), siguen un orden cronológico o secuencial de la información. Por otro lado, los métodos no lineales, como el mapeo conceptual (Mapping) o la creación de diagramas (Charting), buscan representar las relaciones entre ideas de una forma más visual y flexible. Un sistema híbrido bien conocido es el método de Cornell Notes, desarrollado por Walter Pauk, que organiza la página en secciones específicas para notas, pistas y resúmenes \citep{paukHowStudyCollege2010}. Estrategias de lectura y comprensión como SQ3R (Survey, Question, Read, Recite, Review) también incorporan la toma de notas como un componente esencial.

% Mención a Zettelkasten y PARA.
Más allá de estas técnicas generales, han surgido sistemas más estructurados y holísticos. El método Zettelkasten, popularizado por Niklas Luhmann, utiliza una \textit{caja de notas} (slip-box) donde ideas individuales, escritas en tarjetas discretas, se interconectan mediante un sistema de numeración y referencias cruzadas, fomentando así el desarrollo orgánico de pensamientos complejos y la escritura prolífica \citep{ahrensHowTakeSmart2017}. Aunque sus orígenes se remontan a mucho antes, su relevancia ha resurgido con las herramientas digitales. Complementariamente, el método PARA (Projects, Areas, Resources, Archives) propuesto por Tiago Forte, ofrece un sistema para organizar la información digital en función de su accionabilidad, facilitando la gestión de la vida digital y potenciando la productividad y la creatividad \citep{forteBuildingSecondBrain2022}.

\subsection{Bases de conocimiento personal}
\label{subsec:bases_conocimiento_personal}

% Introducción a las PKB y Memex.
La materialización de estos sistemas de gestión personal del conocimiento a menudo toma la forma de una Base de Conocimiento Personal (PKB, por sus siglas en inglés: Personal Knowledge Base). Una PKB es una herramienta electrónica diseñada para que un individuo exprese, capture y recupere su conocimiento subjetivo y particular. Este concepto tiene un precursor visionario en el \textit{Memex} (memory extension) de Vannevar Bush, un dispositivo hipotético descrito en 1945 que permitiría a un individuo almacenar todos sus libros, registros y comunicaciones, y mecanizar su consulta con velocidad y flexibilidad, creando senderos asociativos entre la información \citep{bushWeMayThink1945}.

% Discusión de Data Models según Davies.
La estructura y funcionalidad de las PKB contemporáneas varían significativamente, y una dimensión crucial para su diferenciación es el modelo de datos que utilizan para organizar el conocimiento. Estudios como los de Davies y colaboradores \citep{daviesBuildingMemexSixty, daviesStillBuildingMemex2011} han analizado estos sistemas en función de su marco estructural (árbol, grafo, etc.), los elementos de conocimiento que manejan (desde conceptos hasta notas de texto libre) y el esquema semántico que incorporan (sistemas de tipos, palabras clave, pares atributo-valor).

\paragraph{Grafos de conocimiento personal}
\label{par:grafos_conocimiento_personal}
% Introducción a los PKG.
Una evolución natural de las PKB, especialmente en el entorno digital, es el Grafo de Conocimiento Personal (PKG, por sus siglas en inglés: Personal Knowledge Graph). Este término se refiere a una PKB que no solo almacena notas individuales, sino que también enfatiza y visualiza las interconexiones entre ellas, formando una red semántica de conocimiento personal \citep{pyneMetaworkHowWe2022}. Esta estructura de grafo permite descubrir relaciones no evidentes y fomenta una comprensión más holística del propio acervo de conocimiento.

\paragraph{Sistemas digitales de toma de notas}
\label{par:sistemas_digitales_toma_notas}
% Transición desde Memex y mención a alternativas.
La visión del Memex de Bush, aunque concebida en una era predigital, resuena fuertemente con las capacidades de los sistemas digitales de toma de notas actuales. Si bien existen numerosas alternativas, como Roam Research, Notion, Evernote, Zettlr, Logseq, entre otras, cada una con sus particularidades en cuanto a almacenamiento (local o en la nube), formatos de exportación y representación visual, algunas plataformas como Obsidian han ganado tracción por su enfoque en la soberanía de los datos y la interconexión explícita del conocimiento.

% Detalle de Obsidian y su relación con los conceptos de PKB.
Obsidian, por ejemplo, implementa un modelo de datos donde las notas se almacenan como archivos locales en formato Markdown, un lenguaje de marcado ligero. Esto asegura la portabilidad y longevidad de la información. La funcionalidad central de Obsidian radica en su capacidad para crear enlaces bidireccionales entre notas, lo que permite la \textit{transclusión} de ideas –la capacidad de ver el mismo elemento de conocimiento en múltiples contextos, un concepto clave en el ideal de PKB de Davies \citep{daviesBuildingMemexSixty}. Estos enlaces, junto con el uso de etiquetas y carpetas, permiten construir un grafo de conocimiento personal que se puede visualizar y navegar, facilitando la emergencia de nuevas conexiones e ideas a partir del propio corpus de notas del usuario.

\section{Grandes Modelos de Lenguaje (LLM)}
\label{sec:grandes_modelos_lenguaje}

% Introducción general a los LLM y su impacto, con citas a reportes técnicos.
En paralelo al desarrollo de sofisticados sistemas de PKM, el campo de la inteligencia artificial ha experimentado un avance disruptivo con la aparición y rápida evolución de los Grandes Modelos de Lenguaje (LLM). Estos modelos, entrenados con vastas cantidades de datos textuales y de código, han demostrado capacidades sin precedentes en la comprensión, generación y manipulación del lenguaje natural. Hitos en este desarrollo incluyen modelos como GPT-4 \citep{openaiGPT4TechnicalReport2024}, Gemini \citep{teamGeminiFamilyHighly2024}, y alternativas de código abierto o con disponibilidad ampliada como Llama 3 \citep{grattafioriLlama3Herd2024}, Qwen \citep{baiQwenTechnicalReport2023} y DeepSeek \citep{deepseek-aiDeepSeekV3TechnicalReport2024}, cada uno empujando los límites de lo que es posible en el procesamiento del lenguaje.

\subsection{Técnicas de \textit{Prompting}}
\label{subsec:tecnicas_prompting}

% Importancia de la interacción efectiva y generalización.
Para aprovechar plenamente el potencial de los LLM, es crucial conocer las formas efectivas de interactuar con ellos, un campo conocido como ingeniería de prompts (\textit{prompt engineering}). Una característica notable de estos modelos es su capacidad de generalización a partir de pocos ejemplos (\textit{few-shot learning}) \citep{brownLanguageModelsAre2020}, o incluso con muchos ejemplos (\textit{many-shot in-context learning}) a medida que crece su ventana de contexto \citep{agarwalManyShotInContextLearning2024}. Curiosamente, se ha observado que la estructura y el formato de los ejemplos pueden ser más influyentes que la corrección de las etiquetas en sí mismas para guiar al modelo en la tarea deseada \citep{minRethinkingRoleDemonstrations2022}.

% Técnicas específicas de prompting.
Se han desarrollado diversas técnicas para refinar esta interacción. El \textit{Role Prompting} asigna un rol específico al LLM (e.g., \textit{actúa como un experto en historia medieval}) para guiar su comportamiento y tono \citep{kongBetterZeroShotReasoning2024}, mientras que el \textit{Style Prompting} se enfoca en especificar el estilo, tono o género deseado en la respuesta \citep{luBoundingCapabilitiesLarge2023}. Para mejorar la calidad del razonamiento, se ha demostrado que inducir a los modelos a generar pasos intermedios, como en el paradigma de Cadena de Pensamiento (Chain-of-Thought, CoT) \citep{nyeShowYourWork2021, weiChainofThoughtPromptingElicits2023}, resulta beneficioso. Este enfoque se ha explorado incluso sin el uso de ejemplos explícitos (\textit{zero-shot CoT}), donde una simple instrucción como \textit{pensemos paso a paso} puede elicitar un razonamiento más estructurado \citep{kojimaLargeLanguageModels2023, wangPlanandSolvePromptingImproving2023}.

Otras estrategias se basan en la descomposición de problemas complejos en sub-tareas más manejables (\textit{Complexity-Based Prompting}, \textit{Least-to-Most Prompting}) \citep{fuComplexityBasedPromptingMultiStep2023, zhouLeasttoMostPromptingEnables2023}. La consistencia entre múltiples generaciones de texto para una misma entrada (\textit{Self-Consistency}) también ha demostrado mejorar la robustez de las respuestas \citep{wangSelfConsistencyImprovesChain2023}. Técnicas más avanzadas proponen el uso de estructuras como árboles o grafos de pensamiento (\textit{Tree of Thoughts}, \textit{Graph of Thoughts}) para explorar sistemáticamente el espacio de soluciones después de una descomposición inicial \citep{yaoTreeThoughtsDeliberate2023, bestaGraphThoughtsSolving2024}.

El concepto de \textit{Buffer of Thoughts} permite a los LLM acumular cadenas de razonamiento y recuperarlas contextualmente para nuevas tareas, similar al razonamiento analógico que aprovecha experiencias pasadas \citep{yangBufferThoughtsThoughtAugmented2024, yasunagaLargeLanguageModels2024}. El \textit{Step-Back Prompting} instruye al modelo a resolver primero una versión más general y abstracta del problema, lo que puede simplificar la tarea y evitar desviaciones por detalles excesivos. Inducir al modelo a realizar un análisis previo del modo de proceder (\textit{Meta-Reasoning}) \citep{gaoMetaReasoningLarge2024} o a formular preguntas aclaratorias (\textit{Self-Ask}) \citep{pressMeasuringNarrowingCompositionality2023} también son enfoques prometedores. El marco iterativo de \textit{Self-Refine} utiliza el propio LLM para generar retroalimentación sobre sus respuestas iniciales y luego mejorarlas basándose en esa crítica \citep{madaanSelfRefineIterativeRefinement2023}. Además, se han explorado técnicas que reformulan la pregunta original o incitan al modelo a replantear el problema \citep{mishraReframingInstructionalPrompts2022, dengRephraseRespondLet2024}, así como aquellas que aprovechan representaciones gráficas textuales (\textit{Minds Eye} \citep{wuMindsEyeLLMs}) o simulan procesos cognitivos como el esbozo de ideas (\textit{Sketch of Thought} \citep{aytesSketchofThoughtEfficientLLM2025}) o la metacognición (\textit{Metacognitive Prompting} \citep{wangMetacognitivePromptingImproves2024}). Finalmente, el \textit{Cumulative Reasoning} genera y evalúa múltiples pasos potenciales, aceptándolos o rechazándolos iterativamente hasta alcanzar una solución satisfactoria \citep{zhangCumulativeReasoningLarge2025}.

\subsection{Agentes basados en LLM}
\label{subsec:agentes_basados_llm}

% Potencial de autonomía y uso de herramientas.
El verdadero potencial de los LLM podría residir no solo en su capacidad de generar texto, sino en su uso como el componente central de agentes autónomos capaces de realizar tareas complejas utilizando herramientas externas. Esta dirección surge de la necesidad de superar las limitaciones inherentes de los LLM en áreas como el cálculo matemático, el razonamiento lógico estricto y la verificación de hechos.

% Ejemplos de sistemas de agentes.
Un ejemplo temprano de esta arquitectura es el sistema MRKL (Modular Reasoning, Knowledge, and Language), que emplea un LLM como un \textit{router} que puede invocar diversas herramientas (e.g., una calculadora, un buscador web) y luego combinar sus salidas para generar una respuesta final \citep{karpasMRKLSystemsModular2022}. Modelos como PAL (Program-aided Language Model) \citep{gaoPALProgramaidedLanguage2023} y ToRA (Tool-Integrated Reasoning Agent) \citep{gouToRAToolIntegratedReasoning2024} llevan esto más allá, traduciendo problemas en código ejecutable o intercalando pasos de razonamiento con ejecución de código. El paradigma ReAct (Reasoning and Acting) propone un ciclo de \textit{pensamiento-acción-observación}, donde el LLM genera un plan, actúa (posiblemente usando una herramienta) y observa el resultado, incorporando esta secuencia en su contexto para refinar acciones futuras \citep{yaoReActSynergizingReasoning2023}. El sistema Reflexion amplía ReAct permitiendo al agente reflexionar verbalmente sobre la retroalimentación recibida y almacenar estas reflexiones para mejorar su toma de decisiones en intentos subsiguientes \citep{shinnReflexionLanguageAgents2023}. Finalmente, la Generación Aumentada por Recuperación (RAG, por sus siglas en inglés: Retrieval Augmented Generation) es un paradigma donde se recupera información de una fuente externa (e.g., una base de datos vectorial) y se inyecta en el prompt del LLM para mejorar la calidad de las respuestas en tareas intensivas en conocimiento \citep{lewisRetrievalAugmentedGenerationKnowledgeIntensive2021}; cuando la propia recuperación se considera una herramienta, los sistemas RAG pueden entenderse como agentes.

\section{Integración de herramientas basadas en LLM en aplicaciones de toma de notas}
\label{sec:integracion_herramientas_llm}

% Resumen de herramientas y funcionalidades existentes (basado en llm_tools_dr_gm.md y llm_tools_dr_gp.md).
Dada la evolución de los sistemas PKM y el poder emergente de los LLM, la integración de estos últimos en aplicaciones de toma de notas es un campo de desarrollo activo y prometedor. Actualmente, esta integración se manifiesta de diversas formas, tanto en herramientas especializadas como en plugins para plataformas existentes. Por ejemplo, en el ecosistema de Obsidian, existen numerosos plugins desarrollados por la comunidad que aprovechan LLM externos (como los de OpenAI o modelos locales vía Ollama) para ofrecer funcionalidades como resumen de texto, generación de ideas, traducción, respuesta a preguntas sobre el contenido de las notas (a menudo mediante RAG), e incluso asistencia en la escritura y etiquetado automático. Herramientas como Obsidian Co-Pilot o Text Generator son ejemplos de ello. Plataformas como Notion también han incorporado capacidades de IA nativas (Notion AI) para resumir, traducir y responder preguntas basadas en el espacio de trabajo del usuario. Otros sistemas como Logseq, a través de plugins como AssistSeq, o herramientas independientes como RemNote y Mem.ai, también están explorando la sinergia entre la gestión de notas y la inteligencia de los LLM, enfocándose en la creación incremental de notas, la sugerencia de enlaces, la búsqueda semántica y la generación de contenido contextualizado. Estas herramientas, si bien potentes, se centran principalmente en asistir al usuario en el procesamiento de información ya existente o en la generación de texto bajo demanda, más que en la construcción autónoma y progresiva de la base de conocimiento.

\section{Objetivos}
\label{sec:objetivos}

% Declaración del objetivo de la tesis, referenciando a Fraga y destacando la novedad.
El presente trabajo de tesis tiene como objetivo principal dar un paso adelante en la automatización de la construcción incremental y progresiva de bases de conocimiento personal. Partiendo de la línea de investigación iniciada en trabajos como el de \citet{fragaAutomaticGenerationKnowledge2023}, que exploró la generación automática de conocimiento en contextos específicos, esta tesis se enfoca en aprovechar las capacidades avanzadas de los Grandes Modelos de Lenguaje para generar y estructurar información directamente dentro del contexto de una base de conocimiento personal. Particularmente, se investigará el caso de las notas semiestructuradas, como aquellas escritas en lenguajes de marcado ligero (e.g., Markdown), que están interconectadas formando un grafo de conocimiento. Dada la flexibilidad inherente a estos sistemas de notas, se busca que la aproximación propuesta pueda cubrir, o al menos ser adaptable a, las diversas metodologías y sistemas de toma de notas previamente discutidos.

La contribución fundamental de este trabajo radica en explorar cómo los LLM pueden ir más allá de la simple asistencia (resumen, Q\&A) para convertirse en agentes activos en la expansión y refinamiento coherente de la base de conocimiento. Se investigará cómo las técnicas de \textit{prompting} avanzadas y los paradigmas de agentes basados en LLM pueden ser adaptados para generar nuevas notas que no solo sean relevantes contextualmente para las notas existentes, sino que también contribuyan a la elaboración de ideas, la identificación de lagunas de conocimiento y la sugerencia de nuevas vías de exploración, todo ello de forma incremental y preservando la estructura de grafo. Hasta donde llegan los conocimientos del autor, no existía previamente una herramienta o marco metodológico que abordara con esta finalidad específica la integración profunda de los LLM en la construcción autónoma y evolutiva de bases de conocimiento personal basadas en notas interconectadas.