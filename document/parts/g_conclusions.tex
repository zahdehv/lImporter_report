\chapter*{Conclusiones}
\addcontentsline{toc}{chapter}{Conclusiones}

El presente trabajo de tesis se propuso abordar el desafío de optimizar la integración de conocimiento en bases personales semiestructuradas, un proceso tradicionalmente manual y laborioso. La investigación partió de la pregunta de si un agente personalizable basado en Grandes Modelos de Lenguaje (\textit{LLM}) podría automatizar y enriquecer este proceso de manera eficaz y adaptable a diversos paradigmas de toma de notas. La respuesta, materializada en el prototipo \textbf{lImporter}, es afirmativa y abre la puerta a una nueva generación de herramientas para la Gestión del Conocimiento Personal (\textit{PKM}).

Se cumplieron los objetivos específicos planteados al inicio de la investigación. Primero, se desarrolló un \textit{framework} flexible en forma del \textit{plugin} `lImporter` para \textit{Obsidian.md}, capaz de procesar diversas fuentes de información. Segundo, se diseñó e implementó un agente autónomo basado en el paradigma \textit{ReAct}, cuya arquitectura combina la estrategia \textit{Plan-and-Solve} con la interacción fiable mediante \textit{function calling}, y un sistema de optimización de contexto para consultar eficientemente la bóveda del usuario. Finalmente, la evaluación, realizada a través de una serie de experimentos cualitativos, demostró la versatilidad y eficacia del sistema para cumplir con los requisitos de distintos flujos de trabajo.

Los experimentos revelaron capacidades clave y matices importantes del sistema. La creación de una base de conocimiento sobre \textit{Harry Potter} demostró la habilidad del agente para construir grafos de conocimiento estructurados y visualmente funcionales a partir de texto no estructurado. El mantenimiento de una \textit{wiki} tecnológica evidenció una capacidad crucial: el discernimiento para crear conexiones relevantes cuando existen, y para mantener aislados los conceptos nuevos y no relacionados, preservando así la integridad del conocimiento. El experimento con la metodología \textit{P.A.R.A}. validó su utilidad en escenarios de productividad personal más dinámicos y cotidianos. Por último, el experimento teórico de la Conjetura de \textit{Collatz} desveló una capacidad emergente y profunda: la posibilidad de utilizar la base de notas como una memoria externa fiable, permitiendo al \textit{LLM} realizar tareas iterativas y con estado de una manera robusta, análoga a un ciclo de computación.

\newpage

A pesar de los resultados positivos, el trabajo presenta limitaciones inherentes. La calidad de las acciones del agente está intrínsecamente ligada a la capacidad de razonamiento del \textit{LLM} subyacente. Asimismo, la dependencia de \textit{APIs} externas implica costos monetarios y límites de uso que pueden restringir la ejecución de tareas muy extensas. La versatilidad del sistema, si bien es una fortaleza, también introduce una dependencia de la habilidad del usuario para formular instrucciones claras y efectivas (\textit{prompting}). Finalmente, la evaluación fue de naturaleza cualitativa, centrándose en demostrar la viabilidad y el potencial, en lugar de realizar una comparativa cuantitativa rigurosa.

Las futuras líneas de investigación pueden expandir este trabajo en varias direcciones. La integración de modelos de lenguaje de código abierto y de ejecución local podría mitigar los costos y las preocupaciones de privacidad. Sería valioso dotar al agente de la capacidad de interactuar con otras herramientas y \textit{plugins} del ecosistema de \textit{Obsidian}, como \textit{Dataview}, para realizar consultas estructuradas sobre la base de conocimiento. Se podría explorar el desarrollo de agentes proactivos que operen en segundo plano, sugiriendo conexiones o reorganizaciones sin una petición explícita del usuario. La evolución hacia sistemas multi-agente, donde diferentes agentes especializados colaboran en tareas complejas, representa una frontera prometedora.

En conclusión, este trabajo demuestra que la sinergia entre los \textit{LLM} y los sistemas de \textit{PKM} va más allá de la simple asistencia conversacional. Al dotar a los modelos de lenguaje de un cuerpo de conocimiento externo y la capacidad de actuar sobre él, se transforman en verdaderos colaboradores cognitivos. \textbf{lImporter} se erige como un prototipo funcional que valida este paradigma, mostrando un camino viable hacia la construcción de un \textit{segundo cerebro} que no solo almacena información, sino que activamente ayuda a estructurarla, conectarla y generar nuevas ideas a partir de ella.