\chapter{Introducción}
\label{chapter:introduccion}

% La gestión del conocimiento se ha convertido en una piedra angular en la era de la información, donde la capacidad de organizar, sintetizar y recuperar datos de manera eficiente es crucial para el desarrollo personal y profesional.
La sobrecarga de información en la actualidad plantea un desafío significativo para la productividad y el aprendizaje efectivo. En este contexto, la gestión del conocimiento personal emerge como una disciplina fundamental, no solo para académicos e investigadores, sino para cualquier individuo que busque optimizar su capacidad de aprendizaje y generación de ideas. Como señala \cite{ahrensHowTakeSmart2017}, una gestión eficaz de las notas y el conocimiento adquirido no solo facilita la escritura y el estudio, sino que transforma la manera en que interactuamos con la información, convirtiéndola en un activo dinámico y generador de nuevas perspectivas. El desarrollo de un \textit{segundo cerebro} \citep{forteBuildingSecondBrain2022}, un sistema externo confiable para almacenar y conectar ideas, libera recursos cognitivos, permitiendo un enfoque más profundo en el pensamiento crítico y la creatividad.
% Se introduce la importancia de la gestión del conocimiento personal (PKM).
El potencial de los Grandes Modelos de Lenguaje (LLM) para revolucionar este campo es inmenso. Estas tecnologías ofrecen la posibilidad de automatizar y enriquecer la integración del conocimiento, asistiendo en la destilación de información, la identificación de conexiones y la generación de contenido relevante dentro de las bases de conocimiento personales. La automatización de estos procesos no solo promete un aumento en la eficiencia, sino también una democratización del acceso a metodologías avanzadas de gestión del conocimiento.

\section{Gestión del Conocimiento Personal}
\label{sec:pkm}
% Se introduce formalmente la PKM y su relevancia para los knowledge workers.
La Gestión del Conocimiento Personal (PKM, por sus siglas en inglés) se define como el proceso mediante el cual un individuo recopila, clasifica, almacena, busca, recupera y comparte conocimiento en sus actividades diarias \citep{grundspenkisAgentBasedApproach2007}. Esta disciplina es particularmente relevante para los denominados \textit{trabajadores del conocimiento} (Knowledge Workers), profesionales para quienes el conocimiento es su activo más valioso y que dedican una parte significativa de su tiempo a gestionar grandes cantidades de información. La PKM busca empoderar a estos individuos para que sean más efectivos en sus entornos personales, organizacionales y sociales.

\subsection{Toma de notas (Note-taking)}
% Se introduce la práctica ancestral de la toma de notas y su importancia cognitiva.
La toma de notas , lejos de ser un mero acto de transcripción, es una estrategia fundamental para mejorar el aprendizaje y la retención de información \citep{jansenIntegrativeReviewCognitive2017}. Al tomar notas, el individuo no solo registra la esencia de la información, sino que también se involucra en un proceso activo de filtrado, organización y reestructuración del conocimiento.

% Se describen diversas metodologías de toma de notas, dividiéndolas en lineales y no lineales.
Existen diversas metodologías para la toma de notas, que pueden clasificarse ampliamente en lineales y no lineales.
Las metodologías lineales implican registrar la información en el orden en que se recibe. Un ejemplo común es la creación de esquemas (Outlining), donde las notas y pensamientos se organizan de manera estructurada y lógica. Otra técnica lineal es el método de frases (Sentence method), que consiste en anotar cada tema como una oración corta y simple, ideal para lecciones de ritmo rápido.

Las metodologías no lineales, por otro lado, utilizan la organización espacial y los diagramas para ensamblar la información. Entre estas se encuentra el Charting, útil para temas que pueden desglosarse en categorías. El mapeo (Mapping), como los mapas mentales, organiza las ideas en una estructura de árbol a partir de un punto central. Las Notas Cornell, desarrolladas por Walter Pauk \citep{paukHowStudyCollege2010}, dividen la página en secciones para notas, pistas y un resumen. El método SQ3R (Survey, Question, Read, Recite, Review) es más una técnica de lectura comprensiva que implica generar preguntas y luego tomar notas para responderlas. Las notas guiadas (Guided notes) proporcionan un esquema predefinido con puntos clave faltantes que el estudiante completa.
% Se introduce el Zettelkasten y el método PARA.
Más allá de estas técnicas tradicionales, han surgido sistemas más sofisticados. El método Zettelkasten, popularizado por Niklas Luhmann y descrito en detalle por \cite{ahrensHowTakeSmart2017}, se basa en la creación de notas atómicas interconectadas, formando una red de conocimiento que fomenta la generación de ideas y la escritura prolífica. Este sistema, aunque con raíces históricas, ha ganado nueva relevancia en la era digital. Por otro lado, el método PARA (Projects, Areas, Resources, Archives), propuesto por \cite{forteBuildingSecondBrain2022}, ofrece un marco para organizar la información digital en función de su accionabilidad, facilitando la gestión de proyectos y responsabilidades a largo plazo.

\subsection{Bases de Conocimiento Personal (PKB)}
\label{subsec:pkb}
% Se introduce el concepto de PKB y su precursor, el Memex.
Una Base de Conocimiento Personal (PKB, por sus siglas en inglés) es una herramienta electrónica utilizada por un individuo para expresar, capturar y recuperar conocimiento personal. Se diferencia de una base de datos tradicional al contener material subjetivo y específico del propietario. El concepto de extender la memoria y las capacidades cognitivas del individuo mediante herramientas externas no es nuevo. Ya en 1945, Vannevar Bush imaginó el \textit{Memex} (memory extension), un dispositivo electromecánico en el que un individuo almacenaría todos sus libros, registros y comunicaciones, mecanizado de tal manera que pudiera ser consultado con gran velocidad y flexibilidad \citep{bushWeMayThink1945}. Bush previó un futuro donde la sobrecarga de información requeriría nuevas formas de acceder y conectar el conocimiento acumulado.

% Se mencionan los modelos de datos de las PKB según Davies.
La forma en que una PKB organiza el conocimiento se define por su modelo de datos. Estudios como los de Davies y colegas \citep{daviesBuildingMemexSixty, daviesStillBuildingMemex2011} han analizado estos modelos en función de su marco estructural (cómo se interrelacionan los elementos), los elementos de conocimiento (las unidades básicas de información) y su esquema (el nivel de semántica formal). Un aspecto crucial destacado es la transclusión, la capacidad de ver el mismo elemento de conocimiento en múltiples contextos sin duplicación.

\paragraph{Grafos de Conocimiento Personal (PKG)}
% Se introduce el concepto de PKG.
Dentro de las PKB, los Grafos de Conocimiento Personal (PKG, por sus siglas en inglés) han ganado prominencia. Un PKG representa el conocimiento como una red de nodos interconectados, donde cada nodo es una pieza de información y las aristas representan las relaciones entre ellas, a menudo con visualizaciones gráficas que facilitan la exploración y el descubrimiento de conexiones \citep{pyneMetaworkHowWe2022}.

\subsection{Sistemas Digitales de Toma de Notas}
\label{subsec:sistemas_digitales_toma_notas}
% Se conectan los sistemas digitales con la idea del Memex y se presentan diversas alternativas, con un foco en Obsidian.
La visión del Memex de Bush encuentra un eco contemporáneo en la plétora de sistemas digitales de toma de notas. Estos sistemas varían ampliamente en sus características y enfoques. Algunos, como Roam Research y Logseq, enfatizan los enlaces bidireccionales y la visualización gráfica, alineándose estrechamente con la idea de un PKG. Otros, como Notion, ofrecen una gran flexibilidad para crear bases de datos y vistas personalizadas, mientras que Evernote y Google Keep son populares por su simplicidad y accesibilidad multiplataforma. Microsoft OneNote se integra bien con el ecosistema de Microsoft. Alternativas de código abierto como Zettlr y Joplin también ofrecen robustas funcionalidades, a menudo con un enfoque en la privacidad y el control local de los datos. Herramientas más tradicionales como VimWiki (para usuarios de Vim) y OrgMode (para Emacs) ofrecen sistemas de toma de notas altamente personalizables y potentes para usuarios con conocimientos técnicos. Markor y SimpleNote se centran en la simplicidad y la edición Markdown.

Entre estas herramientas, Obsidian.md ha ganado una considerable popularidad para la escritura académica y la gestión del conocimiento personal. Siguiendo el modelo de datos de las PKB, Obsidian almacena las notas como archivos locales de texto plano en formato Markdown, lo que garantiza la portabilidad y la longevidad de los datos. Su marco estructural se basa en un grafo de conocimiento, donde cada nota es un nodo y los enlaces bidireccionales permiten crear una red interconectada de información. Esto facilita la transclusión, ya que una misma idea o nota puede ser referenciada y contextualizada desde múltiples puntos del grafo sin necesidad de duplicación. Los elementos de conocimiento son flexibles, desde conceptos simples hasta notas extensas. Obsidian también soporta un esquema enriquecido mediante el uso de metadatos (frontmatter), etiquetas y la posibilidad de extender su funcionalidad mediante plugins, como Dataview, que permite realizar consultas complejas sobre las notas. Su vista de grafo visualiza las conexiones, ayudando a identificar relaciones y patrones emergentes.

\section{Grandes Modelos de Lenguaje (LLM)}
\label{sec:llm}
% Se introducen los LLM y se citan los reportes técnicos de modelos prominentes.
Los Grandes Modelos de Lenguaje (LLM) representan un avance transformador en el campo de la inteligencia artificial, con la capacidad de comprender, generar y manipular el lenguaje natural a niveles sin precedentes. Modelos como GPT-4 de OpenAI \citep{openaiGPT4TechnicalReport2024} y Gemini de Google \citep{teamGeminiFamilyHighly2024} han demostrado habilidades notables en una amplia gama de tareas lingüísticas. En paralelo, la comunidad de código abierto ha respondido con modelos competitivos como DeepSeek \citep{deepseek-aiDeepSeekV3TechnicalReport2024}, Qwen \citep{baiQwenTechnicalReport2023} y LLaMa \citep{grattafioriLlama3Herd2024}, impulsando la innovación y la accesibilidad en este campo.

\subsection{Técnicas de Prompting}
\label{subsec:prompting_techniques}
% Se describe el desarrollo de técnicas de prompting para mejorar la interacción con los LLM.
Para interactuar eficazmente con estos modelos, se ha desarrollado un sinfín de técnicas de \textit{prompting} (formulación de instrucciones). Inicialmente, se descubrió que proporcionar unos pocos ejemplos (few-shot learning) mejoraba significativamente los resultados, apelando a la capacidad de generalización de los LLM sin necesidad de reentrenamiento \citep{brownLanguageModelsAre2020}. Investigaciones posteriores, como la de \cite{minRethinkingRoleDemonstrations2022}, han explorado qué partes de estos ejemplos son cruciales, sugiriendo que la estructura del texto, el formato o la forma de proceder pueden ser más importantes que la etiqueta correcta para que el modelo aprenda la tarea. Con el aumento de la ventana de contexto de los modelos más recientes, el aprendizaje con muchos ejemplos (many-shot in-context learning) se ha vuelto una estrategia viable y potente \citep{agarwalManyShotInContextLearning2024}.

% Se mencionan técnicas específicas de prompting.
Se han explorado diversas estrategias para guiar el comportamiento del modelo. El \textit{role-prompting} \citep{kongBetterZeroShotReasoning2024}, que asigna un rol específico al LLM (e.g., actuar como un experto en un tema), y el \textit{style prompting} \citep{luBoundingCapabilitiesLarge2023}, que especifica el estilo o tono deseado, permiten adaptar la respuesta a necesidades concretas. La capacidad de generalización de los LLM también se ha aprovechado para inducirlos a generar pasos intermedios de razonamiento, mejorando la calidad de las respuestas en tareas complejas, un enfoque conocido como \textit{cadena de pensamiento} (Chain-of-Thought) \citep{nyeShowYourWork2021, weiChainofThoughtPromptingElicits2023}. Este paradigma se ha extendido incluso a escenarios sin ejemplos explícitos (zero-shot CoT), donde se instruye al modelo a \textit{pensar paso a paso} \citep{kojimaLargeLanguageModels2023, wangPlanandSolvePromptingImproving2023}.

Otras técnicas se centran en la complejidad y la descomposición. El \textit{complexity-based prompting} aprovecha la observación de que respuestas más largas o complejas a menudo correlacionan con una mayor probabilidad de acierto \citep{fuComplexityBasedPromptingMultiStep2023}, mientras que la descomposición de problemas (\textit{least-to-most prompting}) se basa en que el modelo resuelva sub-tareas más simples para luego integrar sus respuestas en la solución de un problema mayor \citep{zhouLeasttoMostPromptingEnables2023}. La consistencia también se ha utilizado como un criterio de selección, generando múltiples respuestas y eligiendo la más frecuente (\textit{self-consistency}) \citep{wangSelfConsistencyImprovesChain2023}.

Para problemas que requieren exploración o planificación, se han propuesto estructuras como el \textit{Tree of Thoughts} y el \textit{Graph of Thoughts}, que permiten al LLM explorar diferentes caminos de razonamiento tras descomponer el problema inicial \citep{yaoTreeThoughtsDeliberate2023, bestaGraphThoughtsSolving2024}. El \textit{Buffer of Thought} \citep{yangBufferThoughtsThoughtAugmented2024} acumula cadenas de razonamiento previas y las recupera selectivamente para nuevas tareas, de forma similar al razonamiento analógico, que busca aprovechar experiencias pasadas \citep{yasunagaLargeLanguageModels2024}. La técnica de \textit{step-back prompting} instruye al modelo a resolver primero una versión más general y abstracta del problema, lo que puede simplificar la tarea y evitar desviaciones por detalles excesivos. También se ha investigado la inducción de un análisis previo del modo de proceder antes de generar la cadena de razonamiento (\textit{meta-reasoning}) \citep{gaoMetaReasoningLarge2024}. Técnicas como \textit{Self-Ask} incitan al LLM a generar y responder preguntas de seguimiento para clarificar la tarea original antes de abordarla \citep{pressMeasuringNarrowingCompositionality2023}, mientras que \textit{Self-Refine} establece un marco iterativo donde el modelo critica y mejora sus propias respuestas \citep{madaanSelfRefineIterativeRefinement2023}. La reformulación del problema o la instrucción inicial también ha demostrado ser efectiva \citep{mishraReframingInstructionalPrompts2022, dengRephraseRespondLet2024}. Finalmente, se exploran enfoques que aprovechan representaciones gráficas textuales (\textit{Mind's Eye}) \citep{wuMindsEyeLLMs} o procesos cognitivos como el \textit{Sketch of Thought} \citep{aytesSketchofThoughtEfficientLLM2025} y el \textit{Metacognitive Prompting} \citep{wangMetacognitivePromptingImproves2024}. El \textit{Cumulative Reasoning} genera y evalúa pasos potenciales de forma iterativa hasta alcanzar una solución satisfactoria \citep{zhangCumulativeReasoningLarge2025}.

\subsection{Agentes Basados en LLM}
\label{subsec:agentes_llm}
% Se introduce el concepto de agentes LLM y su capacidad de usar herramientas.
El verdadero potencial de los Grandes Modelos de Lenguaje podría residir en su capacidad para actuar de forma autónoma y utilizar herramientas externas para superar sus limitaciones inherentes, como en cálculos matemáticos, razonamiento complejo o la verificación de hechos. A medida que los LLM han mejorado, investigadores y empresas han explorado cómo permitirles interactuar con sistemas externos.
% Se mencionan arquitecturas de agentes.
El sistema MRKL (Modular Reasoning, Knowledge, and Language) \citep{karpasMRKLSystemsModular2022} es una de las formulaciones más simples de un agente, utilizando un LLM como \textit{router} para acceder a múltiples herramientas (e.g., obtener el clima o la fecha actual) y combinar la información para generar una respuesta final. Modelos como PAL (Program-aided Language Model) \citep{gaoPALProgramaidedLanguage2023} traducen problemas directamente a código ejecutable, mientras que ToRA (Tool-Integrated Reasoning Agent) \citep{gouToRAToolIntegratedReasoning2024} intercala pasos de código y razonamiento. El paradigma ReAct (Reasoning and Acting) \citep{yaoReActSynergizingReasoning2023} permite a los agentes generar un pensamiento, tomar una acción y recibir una observación, manteniendo un historial de estos pasos para informar decisiones futuras. Reflexion \citep{shinnReflexionLanguageAgents2023} extiende ReAct incorporando retroalimentación lingüística para refinar el comportamiento del agente. La Generación Aumentada por Recuperación (RAG, por sus siglas en inglés) \citep{lewisRetrievalAugmentedGenerationKnowledgeIntensive2021}, donde se recupera información de una fuente externa para insertarla en el prompt, se considera un sistema de agente cuando la propia recuperación se trata como una herramienta externa.

\section{Integración de Herramientas Basadas en LLM en Aplicaciones de Toma de Notas}
\label{sec:integracion_llm_pkm}
% Se discute cómo los LLM se están integrando en herramientas de PKM, basándose en los documentos proporcionados.
Los avances en los Grandes Modelos de Lenguaje han catalizado el desarrollo de numerosas herramientas que buscan automatizar y enriquecer la toma de notas, la sumarización, la creación de enlaces y la búsqueda dentro de los sistemas de PKM. En el ecosistema de Obsidian, la comunidad ha sido prolífica, ofreciendo múltiples plugins de código abierto que, aunque a menudo dependen de APIs externas (como OpenAI) o LLMs locales, extienden significativamente sus capacidades. Por ejemplo, Obsidian Co-Pilot ofrece una interfaz de chat para interactuar con modelos como GPT-3.5/4, utilizando la nota activa como contexto e incluso guardando las conversaciones como nuevas notas, facilitando así la acumulación incremental de contenido generado por IA. LLM Workspace permite agrupar notas y prompts para proyectos específicos, mientras que LLM Summary puede generar resúmenes y extraer conceptos clave, creando nuevas notas para ellos y enlazándolas. Herramientas como Semantic Search utilizan embeddings para ofrecer búsquedas semánticas y sugerir enlaces entre notas relacionadas, y AI Tagger Universe automatiza la creación de etiquetas.

Plataformas como Notion también han integrado capacidades de IA de forma nativa (Notion AI), permitiendo resumir notas, responder preguntas sobre el espacio de trabajo y generar contenido. Aunque Notion AI no crea enlaces automáticamente, herramientas de terceros como ZenoChat (TextCortex) pueden conectar con Notion para indexar sus páginas como una base de conocimiento y permitir consultas con modelos más avanzados. Logseq, un outliner de código abierto, cuenta con el plugin AssistSeq, que ofrece un asistente contextual capaz de leer el documento actual e indexar notas relacionadas para responder preguntas considerando el contexto completo. Para Roam Research, aunque sin IA nativa, existen extensiones comunitarias como Roam AI que integran GPT-3 para asistir en la escritura y generación de ideas dentro del grafo de Roam.

Herramientas de PKM independientes también están adoptando la IA. RemNote, por ejemplo, facilita la creación de flashcards y resúmenes asistidos por IA a partir de diversas fuentes. Mem.ai se enfoca en organizar notas cronológicamente y utiliza IA para comprender el contexto y enlazar información relacionada automáticamente. Recall, una extensión de navegador y PKM, construye automáticamente una base de conocimiento resumiendo y enlazando contenido web guardado previamente. En comparación, los servicios generales de LLM como ChatGPT o Claude, si bien versátiles, no gestionan ni enlazan incrementalmente un grafo de conocimiento personal de forma nativa, requiriendo ingeniería adicional (e.g., RAG) para integrarse con datos personales. Esta tendencia general hacia la integración de LLMs en herramientas de PKM subraya un esfuerzo por automatizar tareas, mejorar la interconexión de ideas y potenciar la utilidad de los sistemas de gestión del conocimiento personal.

\section{Objetivos de la Tesis}
\label{sec:objetivos}
% Se definen los objetivos de la tesis, conectando con la automatización de la construcción de PKB y el trabajo previo.
El presente trabajo de tesis tiene como objetivo principal avanzar en la automatización de la construcción incremental y progresiva de bases de conocimiento personal. Este esfuerzo se alinea y busca continuar la línea de investigación explorada en trabajos como el de \cite{fragaAutomaticGenerationKnowledge2023}, que abordó la generación automática de conocimiento. Sin embargo, esta tesis se enfoca específicamente en el aprovechamiento de las capacidades de los Grandes Modelos de Lenguaje para generar y enriquecer información directamente en el contexto de una base de conocimiento personal existente o en desarrollo.

Particularmente, se investigará la aplicación de LLMs para la creación y expansión de notas semiestructuradas, utilizando lenguajes de marcado como Markdown, que son comunes en sistemas de PKM modernos. Estas notas, al estar interconectadas, forman un grafo de conocimiento dinámico. Dada la flexibilidad inherente a este formato de notas, se busca que la solución propuesta sea compatible con diversas metodologías y sistemas de toma de notas previamente discutidos, desde el Zettelkasten hasta enfoques más fluidos.

Hasta donde alcanza el conocimiento del autor, no existe actualmente una herramienta que combine de manera integral la potencia de los LLM con el objetivo específico de asistir en la construcción progresiva y contextualizada de una base de conocimiento personal basada en notas interconectadas y semiestructuradas. Para abordar esta brecha, se ha desarrollado un prototipo de programa capaz de procesar archivos en diversas modalidades (e.g., texto, documentos PDF, páginas web) y, mediante la interacción con un LLM, extraer, sintetizar e integrar el conocimiento relevante en una base de notas existente (o crear una nueva desde cero), generando nuevas notas, resúmenes, conexiones y metadatos que enriquezcan el grafo de conocimiento del usuario de manera coherente y contextualmente apropiada. Este trabajo explorará la viabilidad, eficacia y los desafíos de dicha automatización.