\chapter{Introducción}
\label{chapter:introduccion}

% La gestión del conocimiento se ha convertido en una piedra angular en la era de la información, donde la capacidad de organizar, sintetizar y recuperar datos de manera eficiente es crucial para el desarrollo personal y profesional.
La sobrecarga de información en la actualidad plantea un desafío significativo para la productividad y el aprendizaje efectivo. En este contexto, la gestión del conocimiento personal emerge como una disciplina fundamental, no solo para académicos e investigadores, sino para cualquier individuo que busque optimizar su capacidad de aprendizaje y generación de ideas. Como señala \cite{ahrensHowTakeSmart2017}, una gestión eficaz de las notas y el conocimiento adquirido no solo facilita la escritura y el estudio, sino que transforma la manera en que interactuamos con la información, convirtiéndola en un activo dinámico y generador de nuevas perspectivas. El desarrollo de un \textit{segundo cerebro} \parencite{forteBuildingSecondBrain2022}, un sistema externo confiable para almacenar y conectar ideas, libera recursos cognitivos, permitiendo un enfoque más profundo en el pensamiento crítico y la creatividad.
% Se introduce la importancia de la gestión del conocimiento personal (PKM).
El potencial de los Grandes Modelos de Lenguaje (LLM) para revolucionar este campo es inmenso. Estas tecnologías ofrecen la posibilidad de automatizar y enriquecer la integración del conocimiento, asistiendo en la destilación de información, la identificación de conexiones y la generación de contenido relevante dentro de las bases de conocimiento personales. La automatización de estos procesos no solo promete un aumento en la eficiencia, sino también una democratización del acceso a metodologías avanzadas de gestión del conocimiento.

\section{Gestión del Conocimiento Personal (PKM)}
\label{sec:pkm}
% Se introduce formalmente la PKM y su relevancia para los knowledge workers.
La Gestión del Conocimiento Personal (PKM, por sus siglas en inglés) se define como el proceso mediante el cual un individuo recopila, clasifica, almacena, busca, recupera y comparte conocimiento en sus actividades diarias \parencite{grundspenkisAgentBasedApproach2007}. Esta disciplina es particularmente relevante para los denominados \textit{trabajadores del conocimiento} (Knowledge Workers), profesionales para quienes el conocimiento es su activo más valioso y que dedican una parte significativa de su tiempo a gestionar grandes cantidades de información. La PKM busca empoderar a estos individuos para que sean más efectivos en sus entornos personales, organizacionales y sociales.

\subsection{Toma de notas (Note-taking)}
% Se introduce la práctica ancestral de la toma de notas y su importancia cognitiva.
La toma de notas , lejos de ser un mero acto de transcripción, es una estrategia fundamental para mejorar el aprendizaje y la retención de información \parencite{jansenIntegrativeReviewCognitive2017}. Al tomar notas, el individuo no solo registra la esencia de la información, sino que también se involucra en un proceso activo de filtrado, organización y reestructuración del conocimiento.

% Se describen diversas metodologías de toma de notas, dividiéndolas en lineales y no lineales.
Existen diversas metodologías para la toma de notas, que pueden clasificarse ampliamente en lineales y no lineales.
Las metodologías lineales implican registrar la información en el orden en que se recibe. Un ejemplo común es la creación de esquemas (Outlining), donde las notas y pensamientos se organizan de manera estructurada y lógica. Otra técnica lineal es el método de frases (Sentence method), que consiste en anotar cada tema como una oración corta y simple, ideal para lecciones de ritmo rápido.

Las metodologías no lineales, por otro lado, utilizan la organización espacial y los diagramas para ensamblar la información. Entre estas se encuentra el Charting, útil para temas que pueden desglosarse en categorías. El mapeo (Mapping), como los mapas mentales, organiza las ideas en una estructura de árbol a partir de un punto central. Las Notas Cornell, desarrolladas por Walter Pauk \parencite{paukHowStudyCollege2010}, dividen la página en secciones para notas, pistas y un resumen. El método SQ3R (Survey, Question, Read, Recite, Review) es más una técnica de lectura comprensiva que implica generar preguntas y luego tomar notas para responderlas. Las notas guiadas (Guided notes) proporcionan un esquema predefinido con puntos clave faltantes que el estudiante completa.
% Se introduce el Zettelkasten y el método PARA.
Más allá de estas técnicas tradicionales, han surgido sistemas más sofisticados. El método Zettelkasten, popularizado por Niklas Luhmann y descrito en detalle por \cite{ahrensHowTakeSmart2017}, se basa en la creación de notas atómicas interconectadas, formando una red de conocimiento que fomenta la generación de ideas y la escritura prolífica. Este sistema, aunque con raíces históricas, ha ganado nueva relevancia en la era digital. Por otro lado, el método PARA (Projects, Areas, Resources, Archives), propuesto por \cite{forteBuildingSecondBrain2022}, ofrece un marco para organizar la información digital en función de su accionabilidad, facilitando la gestión de proyectos y responsabilidades a largo plazo.

\subsection{Bases de Conocimiento Personal (PKB)}
\label{subsec:pkb}
% Se introduce el concepto de PKB y su precursor, el Memex.
Una Base de Conocimiento Personal (PKB, por sus siglas en inglés) es una herramienta electrónica utilizada por un individuo para expresar, capturar y recuperar conocimiento personal. Se diferencia de una base de datos tradicional al contener material subjetivo y específico del propietario. El concepto de extender la memoria y las capacidades cognitivas del individuo mediante herramientas externas no es nuevo. Ya en 1945, Vannevar Bush imaginó el \textit{Memex} (memory extension), un dispositivo electromecánico en el que un individuo almacenaría todos sus libros, registros y comunicaciones, mecanizado de tal manera que pudiera ser consultado con gran velocidad y flexibilidad \parencite{bushWeMayThink1945}. Bush previó un futuro donde la sobrecarga de información requeriría nuevas formas de acceder y conectar el conocimiento acumulado.

% Se mencionan los modelos de datos de las PKB según Davies.
La forma en que una PKB organiza el conocimiento se define por su modelo de datos. Estudios como los de Davies y colegas \parencite{daviesBuildingMemexSixty, daviesStillBuildingMemex2011} han analizado estos modelos en función de su marco estructural (cómo se interrelacionan los elementos), los elementos de conocimiento (las unidades básicas de información) y su esquema (el nivel de semántica formal). Un aspecto crucial destacado es la transclusión, la capacidad de ver el mismo elemento de conocimiento en múltiples contextos sin duplicación.

\paragraph{Grafos de Conocimiento Personal (PKG)}
% Se introduce el concepto de PKG.
Dentro de las PKB, los Grafos de Conocimiento Personal (PKG, por sus siglas en inglés) han ganado prominencia. Un PKG representa el conocimiento como una red de nodos interconectados, donde cada nodo es una pieza de información y las aristas representan las relaciones entre ellas, a menudo con visualizaciones gráficas que facilitan la exploración y el descubrimiento de conexiones \parencite{pyneMetaworkHowWe2022}.

\subsection{Sistemas Digitales de Toma de Notas}
\label{subsec:sistemas_digitales_toma_notas}
% Se conectan los sistemas digitales con la idea del Memex y se presentan diversas alternativas, con un foco en Obsidian.
La visión del Memex de Bush encuentra un eco contemporáneo en la plétora de sistemas digitales de toma de notas. Estos sistemas varían ampliamente en sus características y enfoques. Algunos, como Roam Research y Logseq, enfatizan los enlaces bidireccionales y la visualización gráfica, alineándose estrechamente con la idea de un PKG. Otros, como Notion, ofrecen una gran flexibilidad para crear bases de datos y vistas personalizadas, mientras que Evernote y Google Keep son populares por su simplicidad y accesibilidad multiplataforma. Microsoft OneNote se integra bien con el ecosistema de Microsoft. Alternativas de código abierto como Zettlr y Joplin también ofrecen robustas funcionalidades, a menudo con un enfoque en la privacidad y el control local de los datos. Herramientas más tradicionales como VimWiki (para usuarios de Vim) y OrgMode (para Emacs) ofrecen sistemas de toma de notas altamente personalizables y potentes para usuarios con conocimientos técnicos. Markor y SimpleNote se centran en la simplicidad y la edición Markdown.

Entre estas herramientas, Obsidian.md ha ganado una considerable popularidad para la escritura académica y la gestión del conocimiento personal. Siguiendo el modelo de datos de las PKB, Obsidian almacena las notas como archivos locales de texto plano en formato Markdown, lo que garantiza la portabilidad y la longevidad de los datos. Su marco estructural se basa en un grafo de conocimiento, donde cada nota es un nodo y los enlaces bidireccionales permiten crear una red interconectada de información. Esto facilita la transclusión, ya que una misma idea o nota puede ser referenciada y contextualizada desde múltiples puntos del grafo sin necesidad de duplicación. Los elementos de conocimiento son flexibles, desde conceptos simples hasta notas extensas. Obsidian también soporta un esquema enriquecido mediante el uso de metadatos (frontmatter), etiquetas y la posibilidad de extender su funcionalidad mediante plugins, como Dataview, que permite realizar consultas complejas sobre las notas. Su vista de grafo visualiza las conexiones, ayudando a identificar relaciones y patrones emergentes.

\section{Grandes Modelos de Lenguaje (LLM)}
\label{sec:llm}
% Se introducen los LLM y se citan los reportes técnicos de modelos prominentes.
Los Grandes Modelos de Lenguaje (LLM) representan un avance transformador en el campo de la inteligencia artificial, con la capacidad de comprender, generar y manipular el lenguaje natural a niveles sin precedentes. Modelos como GPT-4 de OpenAI \parencite{openaiGPT4TechnicalReport2024} y Gemini de Google \parencite{teamGeminiFamilyHighly2024} han demostrado habilidades notables en una amplia gama de tareas lingüísticas. En paralelo, la comunidad de código abierto ha respondido con modelos competitivos como DeepSeek \parencite{deepseek-aiDeepSeekV3TechnicalReport2024}, Qwen \parencite{baiQwenTechnicalReport2023} y LLaMa \parencite{grattafioriLlama3Herd2024}, impulsando la innovación y la accesibilidad en este campo.

\subsection{Técnicas de Prompting}
\label{subsec:prompting_techniques}
% Se describe el desarrollo de técnicas de prompting para mejorar la interacción con los LLM.
Para interactuar eficazmente con estos modelos, se ha desarrollado un sinfín de técnicas de \textit{prompting} (formulación de instrucciones). Inicialmente, se descubrió que proporcionar unos pocos ejemplos (few-shot learning) mejoraba significativamente los resultados, apelando a la capacidad de generalización de los LLM sin necesidad de reentrenamiento \parencite{brownLanguageModelsAre2020}. Investigaciones posteriores, como la de \cite{minRethinkingRoleDemonstrations2022}, han explorado qué partes de estos ejemplos son cruciales, sugiriendo que la estructura del texto, el formato o la forma de proceder pueden ser más importantes que la etiqueta correcta para que el modelo aprenda la tarea. Con el aumento de la ventana de contexto de los modelos más recientes, el aprendizaje con muchos ejemplos (many-shot in-context learning) se ha vuelto una estrategia viable y potente \parencite{agarwalManyShotInContextLearning2024}.

% Se mencionan técnicas específicas de prompting.
Se han explorado diversas estrategias para guiar el comportamiento del modelo. El \textit{role-prompting} \parencite{kongBetterZeroShotReasoning2024}, que asigna un rol específico al LLM (e.g., actuar como un experto en un tema), y el \textit{style prompting} \parencite{luBoundingCapabilitiesLarge2023}, que especifica el estilo o tono deseado, permiten adaptar la respuesta a necesidades concretas. La capacidad de generalización de los LLM también se ha aprovechado para inducirlos a generar pasos intermedios de razonamiento, mejorando la calidad de las respuestas en tareas complejas, un enfoque conocido como \textit{cadena de pensamiento} (Chain-of-Thought) \parencite{nyeShowYourWork2021, weiChainofThoughtPromptingElicits2023}. Este paradigma se ha extendido incluso a escenarios sin ejemplos explícitos (zero-shot CoT), donde se instruye al modelo a \textit{pensar paso a paso} \parencite{kojimaLargeLanguageModels2023, wangPlanandSolvePromptingImproving2023}.

Otras técnicas se centran en la complejidad y la descomposición. El \textit{complexity-based prompting} aprovecha la observación de que respuestas más largas o complejas a menudo correlacionan con una mayor probabilidad de acierto \parencite{fuComplexityBasedPromptingMultiStep2023}, mientras que la descomposición de problemas (\textit{least-to-most prompting}) se basa en que el modelo resuelva sub-tareas más simples para luego integrar sus respuestas en la solución de un problema mayor \parencite{zhouLeasttoMostPromptingEnables2023}. La consistencia también se ha utilizado como un criterio de selección, generando múltiples respuestas y eligiendo la más frecuente (\textit{self-consistency}) \parencite{wangSelfConsistencyImprovesChain2023}.

Para problemas que requieren exploración o planificación, se han propuesto estructuras como el \textit{Tree of Thoughts} y el \textit{Graph of Thoughts}, que permiten al LLM explorar diferentes caminos de razonamiento tras descomponer el problema inicial \parencite{yaoTreeThoughtsDeliberate2023, bestaGraphThoughtsSolving2024}. El \textit{Buffer of Thought} \parencite{yangBufferThoughtsThoughtAugmented2024} acumula cadenas de razonamiento previas y las recupera selectivamente para nuevas tareas, de forma similar al razonamiento analógico, que busca aprovechar experiencias pasadas \parencite{yasunagaLargeLanguageModels2024}. La técnica de \textit{step-back prompting}\parencite{zhengTakeStepBack2024} instruye al modelo a resolver primero una versión más general y abstracta del problema, lo que puede simplificar la tarea y evitar desviaciones por detalles excesivos. También se ha investigado la inducción de un análisis previo del modo de proceder antes de generar la cadena de razonamiento (\textit{meta-reasoning}) \parencite{gaoMetaReasoningLarge2024}. Técnicas como \textit{Self-Ask} incitan al LLM a generar y responder preguntas de seguimiento para clarificar la tarea original antes de abordarla \parencite{pressMeasuringNarrowingCompositionality2023}, mientras que \textit{Self-Refine} establece un marco iterativo donde el modelo critica y mejora sus propias respuestas \parencite{madaanSelfRefineIterativeRefinement2023}. La reformulación del problema o la instrucción inicial también ha demostrado ser efectiva \parencite{mishraReframingInstructionalPrompts2022, dengRephraseRespondLet2024}. Finalmente, se exploran enfoques que aprovechan representaciones gráficas textuales (\textit{Mind's Eye}) \parencite{wuMindsEyeLLMs} o procesos cognitivos como el \textit{Sketch of Thought} \parencite{aytesSketchofThoughtEfficientLLM2025} y el \textit{Metacognitive Prompting} \parencite{wangMetacognitivePromptingImproves2024}. El \textit{Cumulative Reasoning} genera y evalúa pasos potenciales de forma iterativa hasta alcanzar una solución satisfactoria \parencite{zhangCumulativeReasoningLarge2025}.

\subsection{Agentes Basados en LLM}
\label{subsec:agentes_llm}
% Se introduce el concepto de agentes LLM y su capacidad de usar herramientas.
El verdadero potencial de los Grandes Modelos de Lenguaje podría residir en su capacidad para actuar de forma autónoma y utilizar herramientas externas para superar sus limitaciones inherentes, como en cálculos matemáticos, razonamiento complejo o la verificación de hechos. A medida que los LLM han mejorado, investigadores y empresas han explorado cómo permitirles interactuar con sistemas externos.
% Se mencionan arquitecturas de agentes.
El sistema MRKL (Modular Reasoning, Knowledge, and Language) \parencite{karpasMRKLSystemsModular2022} es una de las formulaciones más simples de un agente, utilizando un LLM como \textit{router} para acceder a múltiples herramientas (e.g., obtener el clima o la fecha actual) y combinar la información para generar una respuesta final. Modelos como PAL (Program-aided Language Model) \parencite{gaoPALProgramaidedLanguage2023} traducen problemas directamente a código ejecutable, mientras que ToRA (Tool-Integrated Reasoning Agent) \parencite{gouToRAToolIntegratedReasoning2024} intercala pasos de código y razonamiento. El paradigma ReAct (Reasoning and Acting) \parencite{yaoReActSynergizingReasoning2023} permite a los agentes generar un pensamiento, tomar una acción y recibir una observación, manteniendo un historial de estos pasos para informar decisiones futuras. Reflexion \parencite{shinnReflexionLanguageAgents2023} extiende ReAct incorporando retroalimentación lingüística para refinar el comportamiento del agente. La Generación Aumentada por Recuperación (RAG, por sus siglas en inglés) \parencite{lewisRetrievalAugmentedGenerationKnowledgeIntensive2021}, donde se recupera información de una fuente externa para insertarla en el prompt, se considera un sistema de agente cuando la propia recuperación se trata como una herramienta externa.

\section{Integración de Herramientas Basadas en LLM en Aplicaciones de Toma de Notas}
\label{sec:integracion_llm_pkm}
% Se discute cómo los LLM se están integrando en herramientas de PKM, basándose en los documentos proporcionados.
Los avances en los Grandes Modelos de Lenguaje han catalizado el desarrollo de numerosas herramientas que buscan automatizar y enriquecer la toma de notas, la sumarización, la creación de enlaces y la búsqueda dentro de los sistemas de PKM. Estas herramientas varían desde aplicaciones web independientes hasta plugins específicos para plataformas de gestión del conocimiento consolidadas.

Un ejemplo destacado de aplicación web es \textbf{InfraNodus}, que visualiza texto como redes de conocimiento, permitiendo identificar términos influyentes y lagunas conceptuales mediante el análisis de grafos generados a partir de texto y metadatos como \textit{\#hashtags} y \textit{@mentions}. Aunque no es estrictamente una herramienta de toma de notas, su capacidad para generar nodos (conceptos) y conexiones (co-ocurrencias) a partir de texto ilustra el potencial de los modelos gráficos para la gestión del conocimiento.

En el ecosistema de \textbf{Logseq}, han surgido múltiples plugins. \textbf{Logseq Copilot} (por chhabrakadabra) y \textbf{Logseq Copilot Plugin} (por chloe-15) ofrecen interfaces de chat con IA, indexando las notas del usuario para proporcionar respuestas contextualizadas y, en algunos casos, permitiendo la recuperación de contenido de páginas enlazadas. El plugin \textbf{ollama-logseq} y \textbf{logseq-rag} se centran en la integración con LLMs locales a través de Ollama, facilitando la generación de resúmenes, tarjetas de estudio y la descomposición de tareas, utilizando el contexto de la página o bloque actual. \textbf{Logseq Composer} va un paso más allá al permitir la conexión de notas con cualquier LLM mediante Retrieval-Augmented Generation (RAG) a través de LiteLLM, enfocándose en la recuperación de notas relevantes para enriquecer las interacciones con la IA.

El entorno de \textbf{Obsidian.md} también ha visto una explosión de herramientas impulsadas por LLM. \textbf{Cannoli} permite construir y ejecutar scripts de LLM sin código directamente en el editor Canvas de Obsidian, posibilitando la creación de chatbots con lógica personalizada y la interacción con el contenido de la bóveda. \textbf{ExMemo Tools} y su predecesor, \textbf{ExMemo Assistant}, se enfocan en la gestión inteligente de documentos, ofreciendo archivado automático, inserción de contenido y generación de metadatos como etiquetas y descripciones. Para la mejora de la escritura y la organización, \textbf{Zettelkasten LLM Tools} proporciona búsqueda semántica y un copiloto de IA para reescribir y mejorar la estructura de las notas. La generación de contenido específico también es una capacidad común, con plugins como \textbf{Obsidian Flashcards LLM} para crear tarjetas de estudio, \textbf{Canvas LLM Extender} para añadir nodos de texto generados por IA al Canvas, y \textbf{Daily Summary Plugin for Obsidian} para crear informes diarios a partir de las notas del día.

La integración con LLMs locales es una tendencia creciente, como se observa en \textbf{Local LLM Helper - Obsidian Plugin} y \textbf{Obsidian AI plugin}, que conectan con servidores como Ollama o LM Studio para procesar texto, generar backlinks o chatear con las notas, manteniendo la privacidad de los datos. La creación de material de estudio se ve potenciada por herramientas como \textbf{LLM Testing Plugin} y \textbf{Quiz Generator}, que generan preguntas y cuestionarios a partir de las notas utilizando una variedad de proveedores de LLM. Para una interacción más profunda y contextualizada, \textbf{LLM Workspace plugin for Obsidian} permite la creación de conjuntos de fuentes curadas manualmente para fundamentar las conversaciones con la IA mediante RAG. \textbf{LLM Summary} automatiza la creación de resúmenes de archivos PDF y la extracción de conceptos clave, generando nuevas notas y enlazándolas. La organización se facilita con \textbf{Obsidian LLM Tagger Plugin}, que utiliza LLMs locales para etiquetar notas automáticamente.

Otras herramientas como \textbf{Interact with LLMs in Obsidian} y \textbf{BMO Chatbot for Obsidian} proporcionan interfaces de chat versátiles, conectándose tanto a servicios en la nube (OpenAI, Anthropic, Google) como a LLMs locales (GPT4All, Ollama), permitiendo referenciar la nota actual en las conversaciones. \textbf{InsightA Obsidian Plugin} se especializa en transformar artículos largos en notas atómicas interconectadas y generar Mapas de Contenido (MOC). \textbf{ChatGPT MD} ofrece una integración profunda con ChatGPT, OpenRouter.ai y Ollama, permitiendo conversaciones interactivas que pueden tomar contexto de notas enlazadas. Herramientas más especializadas como \textbf{LaTeX Generator Plugin for Obsidian} convierten lenguaje natural a ecuaciones LaTeX usando Ollama, mientras que \textbf{Simple Prompt} facilita la generación de contenido y la reescritura de selecciones o documentos completos. \textbf{Obsidian Explain Selection with AI Plugin} permite obtener elaboraciones sobre texto seleccionado utilizando diversos LLMs. \textbf{Obsidian Cloud Atlas Plugin} introduce flujos de trabajo en Canvas o Markdown para procesar notas y obtener respuestas contextuales, con capacidades adicionales como reconocimiento de entidades para crear wikilinks. Finalmente, \textbf{Caret Obsidian Plugin} también ofrece un Canvas de IA para chat no lineal y la capacidad de referenciar archivos de la bóveda.

Plataformas como Notion también han integrado capacidades de IA de forma nativa (Notion AI), permitiendo resumir notas, responder preguntas sobre el espacio de trabajo y generar contenido. Aunque Notion AI no crea enlaces automáticamente, herramientas de terceros pueden conectar con Notion para indexar sus páginas como una base de conocimiento.

Esta tendencia general hacia la integración de LLMs en herramientas de PKM subraya un esfuerzo por automatizar tareas, mejorar la interconexión de ideas y potenciar la utilidad de los sistemas de gestión del conocimiento personal. La diversidad de enfoques, desde el chat contextual hasta la generación estructurada de notas y metadatos, refleja la búsqueda de soluciones que se adapten a las necesidades específicas de los usuarios en la construcción y mantenimiento de sus bases de conocimiento.

\section{Objetivos de la Tesis}
\label{sec:objetivos}
% Se definen los objetivos de la tesis, conectando con la automatización de la construcción de PKB y el trabajo previo.
El presente trabajo de tesis tiene como objetivo principal avanzar en la automatización de la construcción incremental y progresiva de bases de conocimiento personal. Este esfuerzo se alinea y busca continuar la línea de investigación explorada en trabajos como el de \cite{fragaAutomaticGenerationKnowledge2023}, que abordó la generación automática de conocimiento. Sin embargo, esta tesis se enfoca específicamente en el aprovechamiento de las capacidades de los Grandes Modelos de Lenguaje para generar y enriquecer información directamente en el contexto de una base de conocimiento personal existente o en desarrollo.

Particularmente, se investigará la aplicación de LLMs para la creación y expansión de notas semiestructuradas, utilizando lenguajes de marcado como Markdown, que son comunes en sistemas de PKM modernos. Estas notas, al estar interconectadas, forman un grafo de conocimiento dinámico. Dada la flexibilidad inherente a este formato de notas, se busca que la solución propuesta sea compatible con diversas metodologías y sistemas de toma de notas previamente discutidos, desde el Zettelkasten hasta enfoques más fluidos.

Hasta donde alcanza el conocimiento del autor, no existe actualmente una herramienta que combine de manera integral la potencia de los LLM con el objetivo específico de asistir en la construcción progresiva y contextualizada de una base de conocimiento personal basada en notas interconectadas y semiestructuradas. Para abordar esta brecha, se ha desarrollado un prototipo de programa capaz de procesar archivos en diversas modalidades (e.g., texto, documentos PDF, páginas web) y, mediante la interacción con un LLM, extraer, sintetizar e integrar el conocimiento relevante en una base de notas existente (o crear una nueva desde cero), generando nuevas notas, resúmenes, conexiones y metadatos que enriquezcan el grafo de conocimiento del usuario de manera coherente y contextualmente apropiada. Este trabajo explorará la viabilidad, eficacia y los desafíos de dicha automatización.