\chapter{Introducción}
\label{chapter:introduccion}

% La gestión del conocimiento se ha convertido en una piedra angular en la era de la información, donde la capacidad de organizar, sintetizar y recuperar datos de manera eficiente es crucial para el desarrollo personal y profesional.
La sobrecarga de información en la actualidad plantea un desafío significativo para la productividad y el aprendizaje efectivo. En este contexto, la gestión del conocimiento personal emerge como una disciplina fundamental, no solo para académicos e investigadores, sino para cualquier individuo que busque optimizar su capacidad de aprendizaje y generación de ideas. Como señala \cite{ahrensHowTakeSmart2017}, una gestión eficaz de las notas y el conocimiento adquirido no solo facilita la escritura y el estudio, sino que transforma la manera en que se interactúa con la información, convirtiéndola en un activo dinámico y generador de nuevas perspectivas. El desarrollo de un \textit{segundo cerebro} \parencite{forteBuildingSecondBrain2022}, un sistema externo confiable para almacenar y conectar ideas, libera recursos cognitivos, permitiendo un enfoque más profundo en el pensamiento crítico y la creatividad.
El potencial de los Grandes Modelos de Lenguaje (\textit{LLM}) para revolucionar este campo es inmenso. Estas tecnologías ofrecen la posibilidad de automatizar y enriquecer la integración del conocimiento, asistiendo en la destilación de información, la identificación de conexiones y la generación de contenido relevante dentro de las bases de conocimiento personales. La automatización de estos procesos no solo promete un aumento en la eficiencia, sino también una democratización del acceso a metodologías avanzadas de gestión del conocimiento.

\section{Gestión del Conocimiento Personal}
\label{sec:pkm}
La Gestión del Conocimiento Personal (\textit{PKM}, por sus siglas en inglés) se define como el proceso mediante el cual un individuo recopila, clasifica, almacena, busca, recupera y comparte conocimiento en sus actividades diarias \parencite{grundspenkisAgentBasedApproach2007}. Esta disciplina es particularmente relevante para los denominados \textit{knowledge workers}, profesionales para quienes el conocimiento es su activo más valioso y que dedican una parte significativa de su tiempo a gestionar grandes cantidades de información. La PKM busca empoderar a estos individuos para que sean más efectivos en sus entornos personales, organizacionales y sociales.

\subsection{Toma de notas}
La toma de notas, lejos de ser un mero acto de transcripción, es una estrategia fundamental para mejorar el aprendizaje y la retención de información \parencite{jansenIntegrativeReviewCognitive2017}. Al tomar notas, el individuo no solo registra la esencia de la información, sino que también se involucra en un proceso activo de filtrado, organización y reestructuración del conocimiento.

Existen diversas metodologías para la toma de notas, que pueden clasificarse ampliamente en lineales y no lineales.
Las metodologías lineales implican registrar la información en el orden en que se recibe. Un ejemplo común es denominado \textit{outlining}, donde las notas y pensamientos se organizan de manera estructurada y lógica. Otra técnica lineal es el \textit{sentence method}, que consiste en anotar cada tema como una oración corta y simple, ideal para lecciones de ritmo rápido.

Las metodologías no lineales, por otro lado, utilizan la organización espacial y los diagramas para ensamblar la información. Entre estas se encuentra el \textit{charting}, útil para temas que pueden desglosarse en categorías. El \textit{mapping}, como los mapas mentales, organiza las ideas en una estructura de árbol a partir de un punto central. Las Notas Cornell, desarrolladas por Walter Pauk \parencite{paukHowStudyCollege2010}, dividen la página en secciones para notas, pistas y un resumen. Las \textit{guided notes} proporcionan un esquema predefinido con puntos clave faltantes que el estudiante completa.
Más allá de estas técnicas tradicionales, han surgido sistemas más sofisticados. El método \textit{Zettelkasten}, popularizado por Niklas Luhmann y descrito en detalle por \cite{ahrensHowTakeSmart2017}, se basa en la creación de notas atómicas interconectadas, formando una red de conocimiento que fomenta la generación de ideas y la escritura prolífica. Este sistema, aunque con raíces históricas, ha ganado nueva relevancia en la era digital. Por otro lado, el método PARA \textit{(Projects, Areas, Resources, Archives)}, propuesto por \cite{forteBuildingSecondBrain2022}, ofrece un marco para organizar la información digital en función de su accionabilidad, facilitando la gestión de proyectos y responsabilidades a largo plazo.

\subsection{Bases de Conocimiento Personal}
\label{subsec:pkb}
Una Base de Conocimiento Personal (\textit{PKB}) es una herramienta electrónica utilizada por un individuo para expresar, capturar y recuperar conocimiento personal. Se diferencia de una base de datos tradicional al contener material subjetivo y específico del propietario. El concepto de extender la memoria y las capacidades cognitivas del individuo mediante herramientas externas no es nuevo. Ya en 1945, Vannevar Bush imaginó el \textit{Memex} (de \textit{memory extension}), un dispositivo electromecánico en el que un individuo almacenaría todos sus libros, registros y comunicaciones, mecanizado de tal manera que pudiera ser consultado con gran velocidad y flexibilidad \parencite{bushWeMayThink1945}. Bush previó un futuro donde la sobrecarga de información requeriría nuevas formas de acceder y conectar el conocimiento acumulado.

La forma en que una PKB organiza el conocimiento se define por su modelo de datos. Estudios como los de Davies y colegas \parencite{daviesBuildingMemexSixty2005, daviesStillBuildingMemex2011} han analizado estos modelos en función de su marco estructural (cómo se interrelacionan los elementos), los elementos de conocimiento (las unidades básicas de información) y su esquema (el nivel de semántica formal). Un aspecto crucial destacado es la transclusión, la capacidad de ver el mismo elemento de conocimiento en múltiples contextos sin duplicación.

\paragraph{Grafos de Conocimiento Personal (\textit{PKG})}
Dentro de las PKB, los Grafos de Conocimiento Personal han ganado prominencia. Un PKG representa el conocimiento como una red de nodos interconectados, donde cada nodo es una pieza de información y las aristas representan las relaciones entre ellas, a menudo con visualizaciones gráficas que facilitan la exploración y el descubrimiento de conexiones \parencite{pyneMetaworkHowWe2022}.

\subsection{Sistemas Digitales de Toma de Notas}
\label{subsec:sistemas_digitales_toma_notas}
La visión del \textit{Memex} de Bush encuentra un eco contemporáneo en la plétora de sistemas digitales de toma de notas. Estos sistemas varían ampliamente en sus características y enfoques. Algunos, como \textit{Roam Research} y \textit{Logseq}, enfatizan los enlaces bidireccionales y la visualización gráfica, alineándose estrechamente con la idea de un \textit{PKG}. Otros, como \textit{Notion}, ofrecen una gran flexibilidad para crear bases de datos y vistas personalizadas, mientras que \textit{Evernote} y \textit{Google Keep} son populares por su simplicidad y accesibilidad multiplataforma. \textit{Microsoft OneNote} tiene casi todos los \textit{checks} en el articulo de la \textit{Wikipedia}. Alternativas de código abierto como \textit{Zettlr} y \textit{Joplin} también ofrecen robustas funcionalidades, a menudo con un enfoque en la privacidad y el control local de los datos. Herramientas más tradicionales como \textit{VimWiki} (para usuarios de \textit{Vim}) y \textit{OrgMode} (para \textit{Emacs}) ofrecen sistemas de toma de notas altamente personalizables y potentes para usuarios con conocimientos técnicos. \textit{Markor} y \textit{SimpleNote} se centran en la simplicidad y la edición \textit{Markdown}.

Entre estas herramientas, \textit{Obsidian.md} ha ganado una considerable popularidad para la escritura académica y la gestión del conocimiento personal. Siguiendo el modelo de datos de las \textit{PKB}, \textit{Obsidian} almacena las notas como archivos locales de texto plano en formato \textit{Markdown}, lo que garantiza la portabilidad y la longevidad de los datos. Su marco estructural se basa en un grafo de conocimiento, donde cada nota es un nodo y los enlaces bidireccionales permiten crear una red interconectada de información. Esto facilita la \textit{transclusión}, ya que una misma idea o nota puede ser referenciada y contextualizada desde múltiples puntos del grafo sin necesidad de duplicación. Los elementos de conocimiento son flexibles, desde conceptos simples hasta notas extensas. Obsidian también soporta un esquema enriquecido mediante el uso de metadatos (\textit{frontmatter}), etiquetas y la posibilidad de extender su funcionalidad mediante \textit{plugins}, como \textit{Dataview}, que permite realizar consultas complejas sobre las notas. Su vista de grafo visualiza las conexiones, ayudando a identificar relaciones y patrones emergentes.

\section{Grandes Modelos de Lenguaje}
\label{sec:llm}
Los Grandes Modelos de Lenguaje (\textit{LLM}) representan un avance transformador en el campo de la inteligencia artificial, con la capacidad de comprender, generar y manipular el lenguaje natural a niveles sin precedentes. Modelos como \textit{GPT-4} de \textit{OpenAI} \parencite{openaiGPT4TechnicalReport2024} y \textit{Gemini} de \textit{Google} \parencite{teamGeminiFamilyHighly2024} han demostrado habilidades notables en una amplia gama de tareas lingüísticas. En paralelo, la comunidad de código abierto ha respondido con modelos competitivos como \textit{DeepSeek} \parencite{deepseek-aiDeepSeekV3TechnicalReport2024}, \textit{Qwen} \parencite{baiQwenTechnicalReport2023} y \textit{LLaMa} \parencite{grattafioriLlama3Herd2024}, impulsando la innovación y la accesibilidad en este campo.

\subsection{Técnicas de \textit{Prompting}}
\label{subsec:prompting_techniques}
Para interactuar eficazmente con estos modelos, se ha desarrollado un sinfín de técnicas de \textit{prompting} (formulación de instrucciones). Inicialmente, se descubrió que proporcionar unos pocos ejemplos (\textit{few-shot learning}) mejoraba significativamente los resultados, apelando a la capacidad de generalización de los LLM sin necesidad de \textit{reentrenamiento} \parencite{brownLanguageModelsAre2020}. Investigaciones posteriores, como la de \cite{minRethinkingRoleDemonstrations2022}, han explorado qué partes de estos ejemplos son cruciales, sugiriendo que la estructura del texto, el formato o la forma de proceder pueden ser más importantes que la etiqueta correcta para que el modelo aprenda la tarea. Con el aumento de la ventana de contexto de los modelos más recientes, el aprendizaje con muchos ejemplos (\textit{many-shot in-context learning}) se ha vuelto una estrategia viable y potente \parencite{agarwalManyShotInContextLearning2024}.

Se han explorado diversas estrategias para guiar el comportamiento del modelo. El \textit{role-prompting} \parencite{kongBetterZeroShotReasoning2024}, que asigna un rol específico al \textit{LLM} (e.g., actuar como un experto en un tema), y el \textit{style prompting} \parencite{luBoundingCapabilitiesLarge2023}, que especifica el estilo o tono deseado, permiten adaptar la respuesta a necesidades concretas. La capacidad de generalización de los LLM también se ha aprovechado para inducirlos a generar pasos intermedios de razonamiento, mejorando la calidad de las respuestas en tareas complejas, un enfoque conocido como \textit{cadena de pensamiento} (\textit{Chain-of-Thought}) \parencite{nyeShowYourWork2021, weiChainofThoughtPromptingElicits2023}. Este paradigma se ha extendido incluso a escenarios sin ejemplos explícitos (\textit{zero-shot CoT}), donde se instruye al modelo a \textit{pensar paso a paso} \parencite{kojimaLargeLanguageModels2023, wangPlanandSolvePromptingImproving2023}.

Otras técnicas se centran en la complejidad y la descomposición. El \textit{complexity-based prompting} aprovecha la observación de que respuestas más largas o complejas a menudo correlacionan con una mayor probabilidad de acierto \parencite{fuComplexityBasedPromptingMultiStep2023}, mientras que la descomposición de problemas (\textit{least-to-most prompting}) se basa en que el modelo resuelva sub-tareas más simples para luego integrar sus respuestas en la solución de un problema mayor \parencite{zhouLeasttoMostPromptingEnables2023}. La consistencia también se ha utilizado como un criterio de selección, generando múltiples respuestas y eligiendo la más frecuente (\textit{self-consistency}) \parencite{wangSelfConsistencyImprovesChain2023}.

Para problemas que requieren exploración o planificación, se han propuesto estructuras como el \textit{Tree of Thoughts} y el \textit{Graph of Thoughts}, que permiten al \textit{LLM} explorar diferentes caminos de razonamiento tras descomponer el problema inicial \parencite{yaoTreeThoughtsDeliberate2023, bestaGraphThoughtsSolving2024}. El \textit{Buffer of Thought} \parencite{yangBufferThoughtsThoughtAugmented2024} acumula cadenas de razonamiento previas y las recupera selectivamente para nuevas tareas, de forma similar al razonamiento analógico, que busca aprovechar experiencias pasadas \parencite{yasunagaLargeLanguageModels2024}. La técnica de \textit{step-back prompting}\parencite{zhengTakeStepBack2024} instruye al modelo a resolver primero una versión más general y abstracta del problema, lo que puede simplificar la tarea y evitar desviaciones por detalles excesivos. También se ha investigado la inducción de un análisis previo del modo de proceder antes de generar la cadena de razonamiento (\textit{meta-reasoning}) \parencite{gaoMetaReasoningLarge2024}. Técnicas como \textit{Self-Ask} incitan al \textit{LLM} a generar y responder preguntas de seguimiento para clarificar la tarea original antes de abordarla \parencite{pressMeasuringNarrowingCompositionality2023}, mientras que \textit{Self-Refine} establece un marco iterativo donde el modelo critica y mejora sus propias respuestas \parencite{madaanSelfRefineIterativeRefinement2023}. La reformulación del problema o la instrucción inicial también ha demostrado ser efectiva \parencite{mishraReframingInstructionalPrompts2022, dengRephraseRespondLet2024}. Finalmente, se exploran enfoques que aprovechan representaciones gráficas textuales (\textit{Mind's Eye}) \parencite{wuMindsEyeLLMs2024} o procesos cognitivos como el \textit{Sketch of Thought} \parencite{aytesSketchofThoughtEfficientLLM2025} y el \textit{Metacognitive Prompting} \parencite{wangMetacognitivePromptingImproves2024}. El \textit{Cumulative Reasoning} genera y evalúa pasos potenciales de forma iterativa hasta alcanzar una solución satisfactoria \parencite{zhangCumulativeReasoningLarge2025}.

\subsection{Agentes Basados en LLM}
\label{subsec:agentes_llm}
El verdadero potencial de los \textit{LLMs} podría residir en su capacidad para actuar de forma autónoma y utilizar herramientas externas para superar sus limitaciones inherentes, como en cálculos matemáticos, razonamiento complejo o la verificación de hechos. A medida que los LLM han mejorado, investigadores y empresas han explorado cómo permitirles interactuar con sistemas externos.
El sistema \textit{MRKL} (\textit{Modular Reasoning, Knowledge, and Language}) \parencite{karpasMRKLSystemsModular2022} es una de las formulaciones más simples de un agente, utilizando un LLM como \textit{router} para acceder a múltiples herramientas (e.g., obtener el clima o la fecha actual) y combinar la información para generar una respuesta final. Modelos como \textit{PAL (Program-aided Language Model)} \parencite{gaoPALProgramaidedLanguage2023} traducen problemas directamente a código ejecutable, mientras que \textit{ToRA (Tool-Integrated Reasoning Agent)} \parencite{gouToRAToolIntegratedReasoning2024} intercala pasos de código y razonamiento. El paradigma \textit{ReAct (Reasoning and Acting)} \parencite{yaoReActSynergizingReasoning2023} permite a los agentes generar un pensamiento, tomar una acción y recibir una observación, manteniendo un historial de estos pasos para informar decisiones futuras. Reflexion \parencite{shinnReflexionLanguageAgents2023} extiende \textit{ReAct} incorporando retroalimentación lingüística para refinar el comportamiento del agente. La Generación Aumentada por Recuperación (\textit{RAG}, por sus siglas en inglés) \parencite{lewisRetrievalAugmentedGenerationKnowledgeIntensive2021}, donde se recupera información de una fuente externa para insertarla en el \textit{prompt}, se considera un sistema de agente cuando la propia recuperación se trata como una herramienta externa.

\section{Extracción de Conocimiento y Enlaces}
\label{sec:extraccion_conocimiento_enlaces}
La extracción de conocimiento y la creación de enlaces entre piezas de información son tareas fundamentales en la construcción de bases de conocimiento robustas y útiles. Tradicionalmente, estos procesos han sido manuales y laboriosos, pero los avances recientes en \textit{LLMs} han abierto nuevas vías para su automatización y enriquecimiento.

La extracción de conocimiento, en el contexto de la gestión del conocimiento personal, implica identificar y capturar las ideas clave, entidades y relaciones presentes en diversas fuentes de información, como textos, documentos PDF o páginas web. Los \textit{LLM} han demostrado una notable capacidad para procesar y comprender el lenguaje natural, lo que los convierte en herramientas prometedoras para esta tarea. Investigaciones como las de \parencite{vandurmeOpenKnowledgeExtraction2008} y \parencite{mccuskerLOKELinkedOpen2023} exploran la extracción de conocimiento abierto a partir de texto, buscando generar proposiciones bien formadas y representaciones lógicas. Otros trabajos se centran en la extracción de entidades y relaciones específicas, como se evidencia en \parencite{martinez-rodriguezMiningInformationSentences2022} y \parencite{liAutomatedClinicalData2024}, este último aplicando \textit{LLM} para extraer información de informes clínicos. La capacidad de los \textit{LLM} para realizar extracción de información en dominios específicos, incluso con esquemas complejos o sin esquemas predefinidos, es un área de investigación activa, como se muestra en \parencite{liKnowCoderCodingStructured2024} y \parencite{zhangExtractDefineCanonicalize2024}.

La creación de enlaces, por otro lado, se refiere al establecimiento de conexiones significativas entre las piezas de conocimiento extraídas, formando así un grafo de conocimiento interconectado. Los \textit{LLM} pueden asistir en esta tarea al identificar relaciones semánticas entre conceptos, incluso aquellas que no son explícitas en el texto original. El trabajo de \parencite{shuKnowledgeGraphLarge2024} y \parencite{heLinkGPTTeachingLarge2024} se enfoca específicamente en la predicción de enlaces faltantes en grafos de conocimiento utilizando \textit{LLM}, demostrando su potencial para inferir nuevas conexiones. La capacidad de los \textit{LLM} para razonar sobre datos estructurados y realizar predicciones de enlaces en escenarios de cero o pocos ejemplos (zero-shot y few-shot) es particularmente relevante, como se explora en \parencite{cartaIterativeZeroShotLLM2023}. Además, la integración de ontologías y esquemas, como se investiga en \parencite{fengOntologygroundedAutomaticKnowledge2024} y \parencite{luoOneKEDockerizedSchemaGuided2025}, puede guiar a los \textit{LLM} en la creación de enlaces más coherentes y contextualmente apropiados.

La combinación de la extracción de conocimiento y la creación de enlaces mediante LLM tiene el potencial de transformar la forma en que se construyen y utilizan las bases de conocimiento personal. Trabajos como \parencite{zhuLLMsKnowledgeGraph2024} y \parencite{machadoLLMStoreLeveraging2024} exploran las capacidades generales de los \textit{LLM} para la construcción y razonamiento sobre grafos de conocimiento. La investigación en este campo también aborda desafíos como la interpretabilidad y la auditabilidad del conocimiento generado por \textit{LLM}, como se discute en \parencite{fengOntologygroundedAutomaticKnowledge2024}. Además, la adaptación de estas técnicas a dominios específicos y la mejora de la eficiencia y escalabilidad son áreas de interés continuo, como se refleja en \parencite{biLPNLScalableLink2024} y \parencite{parkEnhancingFutureLink2024}. La capacidad de los LLM para trabajar con información incompleta o ruidosa, y para generar conocimiento estructurado a partir de fuentes no estructuradas, como se investiga en \parencite{songOpenFactFactualityEnhanced2023} y \parencite{qianOpenDomainKnowledge2023}, es crucial para su aplicación en escenarios del mundo real. Finalmente, la exploración de arquitecturas de agentes y la integración de herramientas externas, como se propone en \parencite{kommineniHumanExpertsMachines2024} y \parencite{abolhasaniLeveragingLLMAutomated2024}, buscan superar las limitaciones inherentes de los \textit{LLM} y potenciar su utilidad en la gestión del conocimiento.

\section{\textit{LLM} en Aplicaciones de Toma de Notas}
\label{sec:integracion_llm_pkm}
Los avances en los \textit{LLMs} han catalizado una diversidad de herramientas para automatizar y enriquecer la toma de notas y la gestión del conocimiento personal (\textit{PKM}). Estas varían desde aplicaciones web hasta \textit{plugins} para plataformas consolidadas, enfocándose en distintos casos de uso.

Un área prominente es la \textit{asistencia conversacional y la respuesta a preguntas contextualizadas}. En \textit{Logseq}, \textit{plugins} como \textit{Logseq Copilot} permiten interactuar con la IA, indexando las notas del usuario para ofrecer respuestas basadas en el propio conocimiento. En \textit{Obsidian.md}, herramientas como \textit{BMO Chatbot for Obsidian} y \textit{ChatGPT MD} ofrecen interfaces de chat versátiles, conectándose a servicios en la nube y \textit{LLMs} locales, y permitiendo referenciar la nota actual o notas enlazadas en las conversaciones. \textit{Caret Obsidian Plugin} extiende esta funcionalidad al \textit{Canvas} para un chat no lineal. \textit{Notion AI} también integra de forma nativa la capacidad de responder preguntas sobre el espacio de trabajo.

La \textit{generación y mejora de contenido} es otro caso de uso fundamental. Herramientas como \textit{LLM Summary} en \textit{Obsidian} automatizan la creación de resúmenes de archivos \textit{PDF} y la extracción de conceptos clave. Para la creación de material de estudio, \textit{plugins} como \textit{Obsidian Flashcards LLM} y \textit{Quiz Generator} facilitan la generación de tarjetas de estudio y cuestionarios. En Logseq, \textit{ollama-logseq} y \textit{logseq-rag} permiten generar resúmenes y tarjetas de estudio. La mejora de la escritura y la reestructuración de notas se abordan con \textit{Zettelkasten LLM Tools} y \textit{Simple Prompt} en Obsidian, mientras que \textit{LaTeX Generator Plugin for Obsidian} convierte lenguaje natural a ecuaciones \textit{LaTeX}. Para la generación de contenido dentro de lienzos visuales, \textit{Canvas LLM Extender} en Obsidian añade nodos de texto generados por IA.

En cuanto a la \textit{organización, estructuración y enlace del conocimiento}, \textit{InfraNodus} destaca como una aplicación web que visualiza texto como redes para identificar términos influyentes y lagunas conceptuales. En Obsidian, \textit{ExMemo Tools} se enfoca en la gestión de documentos y la generación de metadatos como etiquetas, una tarea que \textit{Obsidian LLM Tagger Plugin} también realiza usando \textit{LLMs} locales. \textit{InsightA Obsidian Plugin} transforma artículos largos en notas atómicas interconectadas y genera Mapas de Contenido (\textit{MOCs}). \textit{Obsidian Cloud Atlas Plugin} utiliza reconocimiento de entidades para crear \textit{wikilinks} automáticamente, mejorando la interconexión.

La **integración con \textit{LLMs} locales para mayor privacidad y control** es una tendencia creciente. En Logseq, \textit{ollama-logseq} y \textit{logseq-rag} se integran con \textit{Ollama}. Para Obsidian, \textit{Local LLM Helper - Obsidian Plugin} y \textit{Obsidian AI plugin} conectan con servidores locales como \textit{Ollama} o \textit{LM Studio}. Muchas de las herramientas de chat y generación de contenido mencionadas también ofrecen la opción de operar con \textit{LLMs} locales.

Finalmente, la \textit{automatización de flujos de trabajo} y el \textit{RAG} permiten interacciones más sofisticadas. \textit{Logseq Composer} conecta notas con cualquier \textit{LLM} mediante \textit{RAG} a través de \textit{LiteLLM}. En \textit{Obsidian}, \textit{Cannoli} permite construir \textit{scripts} de \textit{LLM} sin código en el editor \textit{Canvas}, y \textit{LLM Workspace plugin for Obsidian} permite crear conjuntos de fuentes curadas para fundamentar las conversaciones con IA mediante \textit{RAG}. \textit{Obsidian Cloud Atlas Plugin} también introduce flujos de trabajo en \textit{Canvas} o \textit{Markdown}.

Esta evolución subraya un esfuerzo por automatizar tareas, mejorar la interconexión de ideas y potenciar la utilidad de los sistemas de \textit{PKM}, con una diversidad de enfoques que buscan adaptarse a las necesidades específicas de los usuarios.

\section{Fundamentos y Alcance de la Investigación}
\label{sec:fundamentos_investigacion}
El presente trabajo de tesis se enmarca en la intersección de la Gestión del Conocimiento Personal (PKM) y los avances en Inteligencia Artificial, específicamente los \textit{LLM}. La investigación busca abordar los desafíos inherentes a la integración eficiente y significativa de nuevo conocimiento en bases de conocimiento personales semiestructuradas.

El problema científico que se aborda es la optimización del proceso de integración de conocimiento en dichas bases. Tradicionalmente, este proceso es manual y consume tiempo, especialmente al incorporar información de diversas fuentes y formatos, y al establecer conexiones relevantes. Se busca explorar cómo los \textit{LLM} pueden automatizar y enriquecer esta tarea, facilitando la asimilación de información y la adaptación a diferentes paradigmas de toma de notas (e.g., \textit{Zettelkasten}, notas conectadas, resúmenes progresivos). El objeto de estudio es, por tanto, el proceso de construcción y enriquecimiento automatizado de bases de conocimiento personal mediante LLM, centrándose el campo de acción en sistemas basados en lenguajes de marcado como \textit{Markdown} y la representación del conocimiento mediante grafos, con especial atención a los \textit{trabajadores del conocimiento}.

La investigación se guía por la pregunta: ¿En qué medida la aplicación de \textit{LLMs}, a través de un \textit{framework} de agentes personalizables, puede automatizar y optimizar la integración de conocimiento proveniente de diversas fuentes (predominantemente no estructuradas) en bases de conocimiento personales semiestructuradas (como las basadas en \textit{Markdown} y grafos), y cómo se adapta esta automatización a diferentes paradigmas de toma de notas?

Para responder a esta pregunta, el \textit{Objetivo General} es avanzar en la automatización de la construcción incremental y progresiva de bases de conocimiento personal, con un enfoque en la integración contextualizada de información mediante \textit{LLM}. Los \textit{Objetivos Específicos} son:
\begin{enumerate}
    \item Desarrollar un \textit{framework} flexible capaz de procesar datos en múltiples formatos (e.g., texto, \textit{PDF}, web), predominantemente no estructurados, para su integración en bases de conocimiento personales existentes (e.g., \textit{Obsidian.md}).
    \item Diseñar e implementar un conjunto de agentes basados en \textit{LLM} con distintas capacidades (resumen, extracción de entidades, generación de enlaces, creación de notas atómicas) para la integración de conocimiento.
    \item Evaluar la eficacia y adaptabilidad del sistema para soportar diversos paradigmas de toma de notas, analizando la coherencia, relevancia y utilidad del conocimiento integrado.
\end{enumerate}

Este esfuerzo continúa la línea de investigación de trabajos como \cite{fragaAutomaticGenerationKnowledge2023}, pero se enfoca en el aprovechamiento de LLM para generar y enriquecer información directamente en el contexto de una base de conocimiento personal existente o en desarrollo, particularmente para la creación y expansión de notas semiestructuradas en \textit{Markdown} que forman un grafo de conocimiento dinámico. Hasta donde alcanza el conocimiento del autor, no existe una herramienta que combine integralmente \textit{LLM} para la construcción progresiva y contextualizada de una base de conocimiento personal basada en notas interconectadas, considerando la diversidad de fuentes y paradigmas. Para abordar esta brecha, se ha desarrollado un prototipo que procesa archivos, interactúa con un \textit{LLM} para extraer, sintetizar e integrar conocimiento en una base de notas (existente o nueva), generando nuevas notas, resúmenes, conexiones y metadatos. Este trabajo explorará la viabilidad, eficacia y desafíos de dicha automatización, buscando una contribución significativa a la \textit{PKM} y a las aplicaciones prácticas de los \textit{LLM}.