@misc{abolhasaniLeveragingLLMAutomated2024,
  title = {Leveraging {{LLM}} for {{Automated Ontology Extraction}} and {{Knowledge Graph Generation}}},
  author = {Abolhasani, Mohammad Sadeq and Pan, Rong},
  year = {2024},
  month = dec,
  number = {arXiv:2412.00608},
  eprint = {2412.00608},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.00608},
  urldate = {2025-05-15},
  abstract = {Extracting relevant and structured knowledge from large, complex technical documents within the Reliability and Maintainability (RAM) domain is labor-intensive and prone to errors. Our work addresses this challenge by presenting OntoKGen, a genuine pipeline for ontology extraction and Knowledge Graph (KG) generation. OntoKGen leverages Large Language Models (LLMs) through an interactive user interface guided by our adaptive iterative Chain of Thought (CoT) algorithm to ensure that the ontology extraction process and, thus, KG generation align with user-specific requirements. Although KG generation follows a clear, structured path based on the confirmed ontology, there is no universally correct ontology as it is inherently based on the user's preferences. OntoKGen recommends an ontology grounded in best practices, minimizing user effort and providing valuable insights that may have been overlooked, all while giving the user complete control over the final ontology. Having generated the KG based on the confirmed ontology, OntoKGen enables seamless integration into schemeless, non-relational databases like Neo4j. This integration allows for flexible storage and retrieval of knowledge from diverse, unstructured sources, facilitating advanced querying, analysis, and decision-making. Moreover, the generated KG serves as a robust foundation for future integration into Retrieval Augmented Generation (RAG) systems, offering enhanced capabilities for developing domain-specific intelligent applications.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\RRK2I9TX\\Abolhasani and Pan - 2024 - Leveraging LLM for Automated Ontology Extraction and Knowledge Graph Generation.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\WNIA5W8P\\2412.html}
}

@misc{agarwalManyShotInContextLearning2024,
  title = {Many-{{Shot In-Context Learning}}},
  author = {Agarwal, Rishabh and Singh, Avi and Zhang, Lei M. and Bohnet, Bernd and Rosias, Luis and Chan, Stephanie and Zhang, Biao and Anand, Ankesh and Abbas, Zaheer and Nova, Azade and {Co-Reyes}, John D. and Chu, Eric and Behbahani, Feryal and Faust, Aleksandra and Larochelle, Hugo},
  year = {2024},
  month = oct,
  number = {arXiv:2404.11018},
  eprint = {2404.11018},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2404.11018},
  urldate = {2025-02-28},
  abstract = {Large language models (LLMs) excel at few-shot in-context learning (ICL) -- learning from a few examples provided in context at inference, without any weight updates. Newly expanded context windows allow us to investigate ICL with hundreds or thousands of examples -- the many-shot regime. Going from few-shot to many-shot, we observe significant performance gains across a wide variety of generative and discriminative tasks. While promising, many-shot ICL can be bottlenecked by the available amount of human-generated examples. To mitigate this limitation, we explore two new settings: Reinforced and Unsupervised ICL. Reinforced ICL uses model-generated chain-of-thought rationales in place of human examples. Unsupervised ICL removes rationales from the prompt altogether, and prompts the model only with domain-specific questions. We find that both Reinforced and Unsupervised ICL can be quite effective in the many-shot regime, particularly on complex reasoning tasks. Finally, we demonstrate that, unlike few-shot learning, many-shot learning is effective at overriding pretraining biases, can learn high-dimensional functions with numerical inputs, and performs comparably to fine-tuning. We also find that inference cost increases linearly in the many-shot regime, and frontier LLMs benefit from many-shot ICL to varying degrees. Our analysis also reveals the limitations of next-token prediction loss as an indicator of downstream ICL performance.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C:\Users\zahdehv\Zotero\storage\6MSGDPAW\Agarwal et al. - 2024 - Many-Shot In-Context Learning.pdf}
}

@book{ahrensHowTakeSmart2017,
  title = {How to {{Take Smart Notes}}: {{One Simple Technique}} to {{Boost Writing}}, {{Learning}} and {{Thinking}} -- for {{Students}}, {{Academics}} and {{Nonfiction Book Writers}}},
  author = {Ahrens, S{\"o}nke},
  year = {2017},
  month = feb,
  langid = {english},
  annotation = {Item ID: \_:n0},
  file = {C:\Users\zahdehv\Zotero\storage\V7I8B9HL\Ahrens - 2017 - How to Take Smart Notes One Simple Technique to Boost Writing, Learning and Thinking – for Students.epub}
}

@book{ahrensHowTakeSmart2022,
  title = {How to Take Smart Notes: One Simple Technique to Boost Writing, Learning and Thinking},
  shorttitle = {How to Take Smart Notes},
  author = {Ahrens, S{\"o}nke},
  year = {2022},
  edition = {2nd edition, revised and expanded edition},
  publisher = {S{\"o}nke Ahrens},
  address = {Hamburg, Germany},
  abstract = {Klappentext: This is the second, revised and expanded edition. The first edition was published under the slightly longer title "How to Take Smart Notes. One Simple Technique to Boost Writing, Learning and Thinking - for Students, Academics and Nonfiction Book Writers". The key to good and efficient writing lies in the intelligent organisation of ideas and notes. This book helps students, academics and other knowledge workers to get more done, write intelligent texts and learn for the long run. It teaches you how to take smart notes and ensure they bring you and your projects forward. The Take Smart Notes principle is based on established psychological insight and draws from a tried and tested note-taking technique: the Zettelkasten. This is the first comprehensive guide and description of this system in English, and not only does it explain how it works, but also why. It suits students and academics in the social sciences and humanities, nonfiction writers and others who are in the business of reading, thinking and writing. Instead of wasting your time searching for your notes, quotes or references, you can focus on what really counts: thinking, understanding and developing new ideas in writing. Dr. S{\"o}nke Ahrens is a writer and researcher in the field of education and social science. He is the author of the award-winning book ``Experiment and Exploration: Forms of World Disclosure'' (Springer). Since its first publication, How to Take Smart Notes has sold more than 100,000 copies and has been translated into seven languages},
  isbn = {978-3-9824388-1-8 978-3-9824388-0-1},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\ABYLFMX4\Ahrens - 2022 - How to take smart notes one simple technique to boost writing, learning and thinking.epub}
}

@book{allenGettingThingsDone2015,
  title = {Getting {{Things Done}}: {{The Art}} of {{Stress-Free Productivity}}},
  author = {Allen, David},
  year = {2015},
  month = mar,
  publisher = {Penguin Publishing Group},
  langid = {english},
  annotation = {Item ID: \_:n2},
  file = {C:\Users\zahdehv\Zotero\storage\UJLFI7EC\Allen - 2015 - Getting Things Done The Art of Stress-Free Productivity.epub}
}

@misc{aytesSketchofThoughtEfficientLLM2025,
  title = {Sketch-of-{{Thought}}: {{Efficient LLM Reasoning}} with {{Adaptive Cognitive-Inspired Sketching}}},
  shorttitle = {Sketch-of-{{Thought}}},
  author = {Aytes, Simon A. and Baek, Jinheon and Hwang, Sung Ju},
  year = {2025},
  month = mar,
  number = {arXiv:2503.05179},
  eprint = {2503.05179},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2503.05179},
  urldate = {2025-03-22},
  abstract = {Recent advances in large language models have demonstrated remarkable reasoning capabilities through Chain of Thought (CoT) prompting, but often at the cost of excessive verbosity in their intermediate outputs, which increases computational overhead. We introduce Sketchof-Thought (SoT), a novel prompting framework that combines cognitive-inspired reasoning paradigms with linguistic constraints to minimize token usage while preserving reasoning accuracy. SoT is designed as a flexible framework that can incorporate any custom reasoning paradigms based on cognitive science, and we instantiate it with three such paradigms---Conceptual Chaining, Chunked Symbolism, and Expert Lexicons---each tailored to different reasoning tasks and selected dynamically via a lightweight routing model. Through comprehensive evaluation across 15 reasoning datasets with multiple languages and multimodal scenarios, we demonstrate that SoT achieves token reductions of 76\% with negligible accuracy impact. In certain domains like mathematical and multi-hop reasoning, it even improves accuracy while using significantly fewer tokens. Our code is publicly available1.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C:\Users\zahdehv\Zotero\storage\QJSH8R42\Aytes et al. - 2025 - Sketch-of-Thought Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching.pdf}
}

@inproceedings{baiMythQAQueryBasedLargeScale2023,
  title = {{{MythQA}}: {{Query-Based Large-Scale Check-Worthy Claim Detection}} through {{Multi-Answer Open-Domain Question Answering}}},
  shorttitle = {{{MythQA}}},
  booktitle = {Proceedings of the 46th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Bai, Yang and Colas, Anthony and Wang, Daisy Zhe},
  year = {2023},
  month = jul,
  eprint = {2307.11848},
  primaryclass = {cs},
  pages = {3017--3026},
  doi = {10.1145/3539618.3591907},
  urldate = {2025-04-25},
  abstract = {Check-worthy claim detection aims at providing plausible misinformation to downstream fact-checking systems or human experts to check. This is a crucial step toward accelerating the fact-checking process. Many efforts have been put into how to identify check-worthy claims from a small scale of pre-collected claims, but how to efficiently detect check-worthy claims directly from a large-scale information source, such as Twitter, remains underexplored. To fill this gap, we introduce MythQA, a new multi-answer open-domain question answering(QA) task that involves contradictory stance mining for query-based large-scale check-worthy claim detection. The idea behind this is that contradictory claims are a strong indicator of misinformation that merits scrutiny by the appropriate authorities. To study this task, we construct TweetMythQA, an evaluation dataset containing 522 factoid multi-answer questions based on controversial topics. Each question is annotated with multiple answers. Moreover, we collect relevant tweets for each distinct answer, then classify them into three categories: "Supporting", "Refuting", and "Neutral". In total, we annotated 5.3K tweets. Contradictory evidence is collected for all answers in the dataset. Finally, we present a baseline system for MythQA and evaluate existing NLP models for each system component using the TweetMythQA dataset. We provide initial benchmarks and identify key challenges for future models to improve upon. Code and data are available at: https://github.com/TonyBY/Myth-QA},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval},
  file = {C:\Users\zahdehv\Zotero\storage\NRRLAK3X\Bai et al. - 2023 - MythQA Query-Based Large-Scale Check-Worthy Claim Detection through Multi-Answer Open-Domain Questi.pdf}
}

@misc{baiQwenTechnicalReport2023,
  title = {Qwen {{Technical Report}}},
  author = {Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and Hui, Binyuan and Ji, Luo and Li, Mei and Lin, Junyang and Lin, Runji and Liu, Dayiheng and Liu, Gao and Lu, Chengqiang and Lu, Keming and Ma, Jianxin and Men, Rui and Ren, Xingzhang and Ren, Xuancheng and Tan, Chuanqi and Tan, Sinan and Tu, Jianhong and Wang, Peng and Wang, Shijie and Wang, Wei and Wu, Shengguang and Xu, Benfeng and Xu, Jin and Yang, An and Yang, Hao and Yang, Jian and Yang, Shusheng and Yao, Yang and Yu, Bowen and Yuan, Hongyi and Yuan, Zheng and Zhang, Jianwei and Zhang, Xingxuan and Zhang, Yichang and Zhang, Zhenru and Zhou, Chang and Zhou, Jingren and Zhou, Xiaohuan and Zhu, Tianhang},
  year = {2023},
  month = sep,
  number = {arXiv:2309.16609},
  eprint = {2309.16609},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.16609},
  urldate = {2025-05-07},
  abstract = {Large language models (LLMs) have revolutionized the field of artificial intelligence, enabling natural language processing tasks that were previously thought to be exclusive to humans. In this work, we introduce Qwen, the first installment of our large language model series. Qwen is a comprehensive language model series that encompasses distinct models with varying parameter counts. It includes Qwen, the base pretrained language models, and Qwen-Chat, the chat models finetuned with human alignment techniques. The base language models consistently demonstrate superior performance across a multitude of downstream tasks, and the chat models, particularly those trained using Reinforcement Learning from Human Feedback (RLHF), are highly competitive. The chat models possess advanced tool-use and planning capabilities for creating agent applications, showcasing impressive performance even when compared to bigger models on complex tasks like utilizing a code interpreter. Furthermore, we have developed coding-specialized models, Code-Qwen and Code-Qwen-Chat, as well as mathematics-focused models, Math-Qwen-Chat, which are built upon base language models. These models demonstrate significantly improved performance in comparison with open-source models, and slightly fall behind the proprietary models.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\GJZILHZ8\\Bai et al. - 2023 - Qwen Technical Report.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\JZ2USSPF\\2309.html}
}

@article{bekoulisReviewFactExtraction2021,
  title = {A {{Review}} on {{Fact Extraction}} and {{Verification}}},
  author = {Bekoulis, Giannis and Papagiannopoulou, Christina and Deligiannis, Nikos},
  year = {2021},
  month = nov,
  journal = {ACM Comput. Surv.},
  volume = {55},
  number = {1},
  pages = {12:1--12:35},
  issn = {0360-0300},
  doi = {10.1145/3485127},
  urldate = {2025-05-14},
  abstract = {We study the fact-checking problem, which aims to identify the veracity of a given claim. Specifically, we focus on the task of Fact Extraction and VERification (FEVER) and its accompanied dataset. The task consists of the subtasks of retrieving the relevant documents (and sentences) from Wikipedia and validating whether the information in the documents supports or refutes a given claim. This task is essential and can be the building block of applications such as fake news detection and medical claim verification. In this article, we aim at a better understanding of the challenges of the task by presenting the literature in a structured and comprehensive way. We describe the proposed methods by analyzing the technical perspectives of the different approaches and discussing the performance results on the FEVER dataset, which is the most well-studied and formally structured dataset on the fact extraction and verification task. We also conduct the largest experimental study to date on identifying beneficial loss functions for the sentence retrieval component. Our analysis indicates that sampling negative sentences is important for improving the performance and decreasing the computational complexity. Finally, we describe open issues and future challenges, and we motivate future research in the task.},
  file = {C:\Users\zahdehv\Zotero\storage\RQC8BL9W\Bekoulis et al. - 2021 - A Review on Fact Extraction and Verification.pdf}
}

@article{bestaGraphThoughtsSolving2024,
  title = {Graph of {{Thoughts}}: {{Solving Elaborate Problems}} with {{Large Language Models}}},
  shorttitle = {Graph of {{Thoughts}}},
  author = {Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and Hoefler, Torsten},
  year = {2024},
  month = mar,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {38},
  number = {16},
  eprint = {2308.09687},
  primaryclass = {cs},
  pages = {17682--17690},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v38i16.29720},
  urldate = {2025-02-28},
  abstract = {We introduce Graph of Thoughts (GoT): a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-ofThought or Tree of Thoughts (ToT). The key idea and primary advantage of GoT is the ability to model the information generated by an LLM as an arbitrary graph, where units of information (``LLM thoughts'') are vertices, and edges correspond to dependencies between these vertices. This approach enables combining arbitrary LLM thoughts into synergistic outcomes, distilling the essence of whole networks of thoughts, or enhancing thoughts using feedback loops. We illustrate that GoT offers advantages over state of the art on different tasks, for example increasing the quality of sorting by 62\% over ToT, while simultaneously reducing costs by {$>$}31\%. We ensure that GoT is extensible with new thought transformations and thus can be used to spearhead new prompting schemes. This work brings the LLM reasoning closer to human thinking or brain mechanisms such as recurrence, both of which form complex networks.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C:\Users\zahdehv\Zotero\storage\68WJR4TA\Besta et al. - 2024 - Graph of Thoughts Solving Elaborate Problems with Large Language Models.pdf}
}

@misc{biLPNLScalableLink2024,
  title = {{{LPNL}}: {{Scalable Link Prediction}} with {{Large Language Models}}},
  shorttitle = {{{LPNL}}},
  author = {Bi, Baolong and Liu, Shenghua and Wang, Yiwei and Mei, Lingrui and Cheng, Xueqi},
  year = {2024},
  month = feb,
  number = {arXiv:2401.13227},
  eprint = {2401.13227},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.13227},
  urldate = {2025-05-15},
  abstract = {Exploring the application of large language models (LLMs) to graph learning is a emerging endeavor. However, the vast amount of information inherent in large graphs poses significant challenges to this process. This work focuses on the link prediction task and introduces \${\textbackslash}textbf\{LPNL\}\$ (Link Prediction via Natural Language), a framework based on large language models designed for scalable link prediction on large-scale heterogeneous graphs. We design novel prompts for link prediction that articulate graph details in natural language. We propose a two-stage sampling pipeline to extract crucial information from the graphs, and a divide-and-conquer strategy to control the input tokens within predefined limits, addressing the challenge of overwhelming information. We fine-tune a T5 model based on our self-supervised learning designed for link prediction. Extensive experimental results demonstrate that LPNL outperforms multiple advanced baselines in link prediction tasks on large-scale graphs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\2A4QRKAI\\Bi et al. - 2024 - LPNL Scalable Link Prediction with Large Language Models.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\J4S3V8JA\\2401.html}
}

@inproceedings{brownLanguageModelsAre2020,
  title = {Language Models Are Few-Shot Learners},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and {Herbert-Voss}, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  year = {2020},
  month = dec,
  series = {{{NIPS}} '20},
  pages = {1877--1901},
  publisher = {Curran Associates Inc.},
  address = {Red Hook, NY, USA},
  urldate = {2025-05-01},
  abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
  isbn = {978-1-7138-2954-6},
  file = {C:\Users\zahdehv\Zotero\storage\W7X8GUHM\Brown et al. - 2020 - Language models are few-shot learners.pdf}
}

@book{bushWeMayThink1945,
  title = {As {{We May Think}}},
  author = {Bush, Vannevar},
  year = {1945},
  month = jan,
  langid = {british},
  annotation = {Item ID: \_:n0},
  file = {C:\Users\zahdehv\Zotero\storage\6USYMKDQ\Bush - 1945 - As We May Think.epub}
}

@article{bushWeMayThink1979,
  title = {As We May Think},
  author = {Bush, Vannevar},
  year = {1979},
  month = apr,
  journal = {ACM SIGPC Notes},
  volume = {1},
  number = {4},
  pages = {36--44},
  issn = {0163-5816},
  doi = {10.1145/1113634.1113638},
  urldate = {2025-05-03},
  abstract = {As Director of the Office of Scientific Research and Development, Dr. Vannevar Bush has coordinated the activities of some six thousand leading American scientists in the application of science to warfare. In this significant article he holds up an incentive for scientists when the fighting has ceased. He urges that men of science should then turn to the massive task of making more accessible our bewildering store of knowledge. For years inventions have extended man's physical powers rather than the powers of his mind. Trip hammers that multiply the fists, microscopes that sharpen the eye, and engines of destruction and detection are new results, but not the end results, of modern science. Now, says Dr. Bush, instruments are at hand which, if properly developed, will give man access to and command over the inherited knowledge of the ages. The perfection of these pacific instruments should be the first objective of our scientists as they emerge from their war work. Like Emerson's famous address of 1837 on "The American Scholar," this paper by Dr. Bush calls for a new relationship between thinking man and the sum of our knowledge.},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\FAG9UYLP\Bush - 1979 - As we may think.pdf}
}

@article{caliskanNATURALLANGUAGEPROCESSING,
  title = {A {{NATURAL LANGUAGE PROCESSING AIDED RELATIONAL INFORMATION MANAGEMENT APPROACH FOR ARCHITECTURAL KNOWLEDGE FABRICATION}}},
  author = {{\c C}ali{\c s}kan, {\c S}eyma Nur},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\P2YGSTJ9\Çalişkan - A NATURAL LANGUAGE PROCESSING AIDED RELATIONAL INFORMATION MANAGEMENT APPROACH FOR ARCHITECTURAL KNO.pdf}
}

@misc{cartaIterativeZeroShotLLM2023,
  title = {Iterative {{Zero-Shot LLM Prompting}} for {{Knowledge Graph Construction}}},
  author = {Carta, Salvatore and Giuliani, Alessandro and Piano, Leonardo and Podda, Alessandro Sebastian and Pompianu, Livio and Tiddia, Sandro Gabriele},
  year = {2023},
  month = jul,
  number = {arXiv:2307.01128},
  eprint = {2307.01128},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.01128},
  urldate = {2025-05-15},
  abstract = {In the current digitalization era, capturing and effectively representing knowledge is crucial in most real-world scenarios. In this context, knowledge graphs represent a potent tool for retrieving and organizing a vast amount of information in a properly interconnected and interpretable structure. However, their generation is still challenging and often requires considerable human effort and domain expertise, hampering the scalability and flexibility across different application fields. This paper proposes an innovative knowledge graph generation approach that leverages the potential of the latest generative large language models, such as GPT-3.5, that can address all the main critical issues in knowledge graph building. The approach is conveyed in a pipeline that comprises novel iterative zero-shot and external knowledge-agnostic strategies in the main stages of the generation process. Our unique manifold approach may encompass significant benefits to the scientific community. In particular, the main contribution can be summarized by: (i) an innovative strategy for iteratively prompting large language models to extract relevant components of the final graph; (ii) a zero-shot strategy for each prompt, meaning that there is no need for providing examples for "guiding" the prompt result; (iii) a scalable solution, as the adoption of LLMs avoids the need for any external resources or human expertise. To assess the effectiveness of our proposed model, we performed experiments on a dataset that covered a specific domain. We claim that our proposal is a suitable solution for scalable and versatile knowledge graph construction and may be applied to different and novel contexts.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\LDN6G8LS\\Carta et al. - 2023 - Iterative Zero-Shot LLM Prompting for Knowledge Graph Construction.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\K4UEBZ48\\2307.html}
}

@misc{chelbaInformationExtractionUsing2001,
  title = {Information {{Extraction Using}} the {{Structured Language Model}}},
  author = {Chelba, Ciprian and Mahajan, Milind},
  year = {2001},
  month = aug,
  number = {arXiv:cs/0108023},
  eprint = {cs/0108023},
  publisher = {arXiv},
  doi = {10.48550/arXiv.cs/0108023},
  urldate = {2025-05-15},
  abstract = {The paper presents a data-driven approach to information extraction (viewed as template filling) using the structured language model (SLM) as a statistical parser. The task of template filling is cast as constrained parsing using the SLM. The model is automatically trained from a set of sentences annotated with frame/slot labels and spans. Training proceeds in stages: first a constrained syntactic parser is trained such that the parses on training data meet the specified semantic spans, then the non-terminal labels are enriched to contain semantic information and finally a constrained syntactic+semantic parser is trained on the parse trees resulting from the previous stage. Despite the small amount of training data used, the model is shown to outperform the slot level accuracy of a simple semantic grammar authored manually for the MiPad --- personal information management --- task.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\EKITHAWU\\Chelba and Mahajan - 2001 - Information Extraction Using the Structured Language Model.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\5BXJZGVF\\0108023.html}
}

@inproceedings{chenDenseRetrievalWhat2024,
  title = {Dense {{X Retrieval}}: {{What Retrieval Granularity Should We Use}}?},
  shorttitle = {Dense {{X Retrieval}}},
  booktitle = {Proceedings of the 2024 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Chen, Tong and Wang, Hongwei and Chen, Sihao and Yu, Wenhao and Ma, Kaixin and Zhao, Xinran and Zhang, Hongming and Yu, Dong},
  editor = {{Al-Onaizan}, Yaser and Bansal, Mohit and Chen, Yun-Nung},
  year = {2024},
  month = nov,
  pages = {15159--15177},
  publisher = {Association for Computational Linguistics},
  address = {Miami, Florida, USA},
  doi = {10.18653/v1/2024.emnlp-main.845},
  urldate = {2025-04-12},
  abstract = {Dense retrieval has become a prominent method to obtain relevant context or world knowledge in open-domain NLP tasks. When we use a learned dense retriever on a retrieval corpus at inference time, an often-overlooked design choice is the retrieval unit in which the corpus is indexed, e.g. document, passage, or sentence. We discover that the retrieval unit choice significantly impacts the performance of both retrieval and downstream tasks. Distinct from the typical approach of using passages or sentences, we introduce a novel retrieval unit, proposition, for dense retrieval. Propositions are defined as atomic expressions within text, each encapsulating a distinct factoid and presented in a concise, self-contained natural language format. We conduct an empirical comparison of different retrieval granularity. Our experiments reveal that indexing a corpus by fine-grained units such as propositions significantly outperforms passage-level units in retrieval tasks. Moreover, constructing prompts with fine-grained retrieved units for retrieval-augmented language models improves the performance of downstream QA tasks given a specific computation budget.},
  file = {C:\Users\zahdehv\Zotero\storage\GBCDZAL6\Chen et al. - 2024 - Dense X Retrieval What Retrieval Granularity Should We Use.pdf}
}

@misc{chenReverseThinkingMakes2024,
  title = {Reverse {{Thinking Makes LLMs Stronger Reasoners}}},
  author = {Chen, Justin Chih-Yao and Wang, Zifeng and Palangi, Hamid and Han, Rujun and Ebrahimi, Sayna and Le, Long and Perot, Vincent and Mishra, Swaroop and Bansal, Mohit and Lee, Chen-Yu and Pfister, Tomas},
  year = {2024},
  month = nov,
  number = {arXiv:2411.19865},
  eprint = {2411.19865},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2411.19865},
  urldate = {2025-02-28},
  abstract = {Reverse thinking plays a crucial role in human reasoning. Humans can reason not only from a problem to a solution but also in reverse, i.e., start from the solution and reason towards the problem. This often enhances overall reasoning performance as it enables consistency checks between their forward and backward thinking. To enable Large Language Models (LLMs) to perform reverse thinking, we introduce Reverse-Enhanced Thinking (REVTHINK), a framework composed of data augmentation and learning objectives. In REVTHINK, we augment the dataset by collecting structured forward-backward reasoning from a teacher model, consisting of: (1) the original question, (2) forward reasoning, (3) backward question, and (4) backward reasoning. We then employ three objectives to train a smaller student model in a multi-task learning fashion: (a) generate forward reasoning from a question, (b) generate a backward question from a question, and (c) generate backward reasoning from the backward question. Experiments across 12 datasets covering commonsense, math, and logical reasoning show an average 13.53\% improvement over the student model's zero-shot performance and a 6.84\% improvement over the strongest knowledge distillation baselines. Moreover, our method demonstrates sample efficiency -- using only 10\% of the correct forward reasoning from the training data, it outperforms a standard fine-tuning method trained on 10{\texttimes} more forward reasoning. REVTHINK also exhibits strong generalization to out-of-distribution held-out datasets.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C:\Users\zahdehv\Zotero\storage\UP9S6X29\Chen et al. - 2024 - Reverse Thinking Makes LLMs Stronger Reasoners.pdf}
}

@misc{CognitiveInterfacesTranscendental,
  title = {From {{Cognitive Interfaces}} to {{Transcendental Protocols}}},
  journal = {Nodus Labs: Ecological Thinking through Network Analysis},
  urldate = {2025-05-09},
  abstract = {Anything can be an interface, as long as it is in between and as everything is in between, everything is an interface. Interfaces create affordances or possibilities for action. They affect our perception and cognition. How can the interfaces with such transformative potential be designed? Moreover, if interface create a set of actions, what if we go beyond the notion of interfaces and think in terms of the protocols? Not the kind of protocols that say to do this and not to do that. The kind of protocols that transcend reality, that lie in the realm of practices, such as meditation, artistic practices, version-control systems, BitCoin, chaotic itinerancy, and other polysingular approaches.},
  howpublished = {https://noduslabs.com/research/cognitive-interfaces-transcendental-protocols/},
  langid = {american},
  file = {C:\Users\zahdehv\Zotero\storage\NV8DM7DX\cognitive-interfaces-transcendental-protocols.html}
}

@article{ComparisonNotetakingSoftware2025,
  title = {Comparison of Note-Taking Software},
  year = {2025},
  month = mar,
  journal = {Wikipedia},
  urldate = {2025-05-02},
  abstract = {The tables below compare features of notable note-taking software.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1280246329},
  file = {C:\Users\zahdehv\Zotero\storage\AHIS2Y6X\Comparison_of_note-taking_software.html}
}

@article{daviesBuildingMemexSixty2005,
  title = {Building the {{Memex Sixty Years Later}}: {{Trends}} and {{Directions}} in {{Personal Knowledge Bases}}},
  author = {Davies, Stephen and {Velez-Morales}, Javier and King, Roger},
  year = {2005},
  abstract = {Software tools abound for managing documents and other information sources, but are rarely used for managing the personal, subjective knowledge an individual gleans from them. Yet for at least sixty years there has been a thread of interest in building a system to support a personalized repository of knowledge. This survey defines such systems as ``personal knowledge bases,'' describes a number of important historical and recent examples, and gives a taxonomy of their principal characteristics. It concludes by broadly analyzing the design choices involved and sketching out an ideal solution.},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\KZX57C5W\Davies et al. - Building the Memex Sixty Years Later Trends and Directions in Personal Knowledge Bases.pdf}
}

@article{daviesStillBuildingMemex2011,
  title = {Still Building the Memex},
  author = {Davies, Stephen},
  year = {2011},
  month = feb,
  journal = {Communications of the ACM},
  volume = {54},
  number = {2},
  pages = {80--88},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/1897816.1897840},
  urldate = {2025-05-08},
  abstract = {What would it take for a true personal knowledge base to generate the benefits envisioned by Vannevar Bush?},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\AWKYS6TB\Davies - 2011 - Still building the memex.pdf}
}

@misc{deepseek-aiDeepSeekV3TechnicalReport2024,
  title = {{{DeepSeek-V3 Technical Report}}},
  author = {{DeepSeek-AI} and Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai, Damai and Guo, Daya and Yang, Dejian and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin, Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and Chen, Guanting and Li, Guowei and Zhang, H. and Bao, Han and Xu, Hanwei and Wang, Haocheng and Zhang, Haowei and Ding, Honghui and Xin, Huajian and Gao, Huazuo and Li, Hui and Qu, Hui and Cai, J. L. and Liang, Jian and Guo, Jianzhong and Ni, Jiaqi and Li, Jiashi and Wang, Jiawei and Chen, Jin and Chen, Jingchang and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Song, Junxiao and Dong, Kai and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin and Yu, Kuai and Wang, Lean and Zhang, Lecong and Xu, Lei and Xia, Leyi and Zhao, Liang and Wang, Litong and Zhang, Liyue and Li, Meng and Wang, Miaojun and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and Li, Mingming and Tian, Ning and Huang, Panpan and Wang, Peiyi and Zhang, Peng and Wang, Qiancheng and Zhu, Qihao and Chen, Qinyu and Du, Qiushi and Chen, R. J. and Jin, R. L. and Ge, Ruiqi and Zhang, Ruisong and Pan, Ruizhe and Wang, Runji and Xu, Runxin and Zhang, Ruoyu and Chen, Ruyi and Li, S. S. and Lu, Shanghao and Zhou, Shangyan and Chen, Shanhuang and Wu, Shaoqing and Ye, Shengfeng and Ye, Shengfeng and Ma, Shirong and Wang, Shiyu and Zhou, Shuang and Yu, Shuiping and Zhou, Shunfeng and Pan, Shuting and Wang, T. and Yun, Tao and Pei, Tian and Sun, Tianyu and Xiao, W. L. and Zeng, Wangding and Zhao, Wanjia and An, Wei and Liu, Wen and Liang, Wenfeng and Gao, Wenjun and Yu, Wenqin and Zhang, Wentao and Li, X. Q. and Jin, Xiangyue and Wang, Xianzu and Bi, Xiao and Liu, Xiaodong and Wang, Xiaohan and Shen, Xiaojin and Chen, Xiaokang and Zhang, Xiaokang and Chen, Xiaosha and Nie, Xiaotao and Sun, Xiaowen and Wang, Xiaoxiang and Cheng, Xin and Liu, Xin and Xie, Xin and Liu, Xingchao and Yu, Xingkai and Song, Xinnan and Shan, Xinxia and Zhou, Xinyi and Yang, Xinyu and Li, Xinyuan and Su, Xuecheng and Lin, Xuheng and Li, Y. K. and Wang, Y. Q. and Wei, Y. X. and Zhu, Y. X. and Zhang, Yang and Xu, Yanhong and Xu, Yanhong and Huang, Yanping and Li, Yao and Zhao, Yao and Sun, Yaofeng and Li, Yaohui and Wang, Yaohui and Yu, Yi and Zheng, Yi and Zhang, Yichao and Shi, Yifan and Xiong, Yiliang and He, Ying and Tang, Ying and Piao, Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and Liu, Yiyuan and Guo, Yongqiang and Wu, Yu and Ou, Yuan and Zhu, Yuchen and Wang, Yuduan and Gong, Yue and Zou, Yuheng and He, Yujia and Zha, Yukun and Xiong, Yunfan and Ma, Yunxian and Yan, Yuting and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou, Yuyang and Wu, Z. F. and Ren, Z. Z. and Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and Huang, Zhen and Zhang, Zhen and Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Gou, Zhibin and Ma, Zhicheng and Yan, Zhigang and Shao, Zhihong and Xu, Zhipeng and Wu, Zhiyu and Zhang, Zhongyu and Li, Zhuoshu and Gu, Zihui and Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and Song, Ziyang and Gao, Ziyi and Pan, Zizheng},
  year = {2024},
  month = dec,
  number = {arXiv:2412.19437},
  eprint = {2412.19437},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.19437},
  urldate = {2025-02-28},
  abstract = {We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. To achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training. In addition, its training process is remarkably stable. Throughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks. The model checkpoints are available at https://github.com/deepseek-ai/DeepSeek-V3.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\D4QVNUTT\\DeepSeek-AI et al. - 2024 - DeepSeek-V3 Technical Report.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\TYT2T42E\\2412.html}
}

@misc{dengDocumentlevelClaimExtraction2024,
  title = {Document-Level {{Claim Extraction}} and {{Decontextualisation}} for {{Fact-Checking}}},
  author = {Deng, Zhenyun and Schlichtkrul, Michael and Vlachos, Andreas},
  year = {2024},
  month = jun,
  number = {arXiv:2406.03239},
  eprint = {2406.03239},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.03239},
  urldate = {2025-05-14},
  abstract = {Selecting which claims to check is a time-consuming task for human fact-checkers, especially from documents consisting of multiple sentences and containing multiple claims. However, existing claim extraction approaches focus more on identifying and extracting claims from individual sentences, e.g., identifying whether a sentence contains a claim or the exact boundaries of the claim within a sentence. In this paper, we propose a method for document-level claim extraction for fact-checking, which aims to extract check-worthy claims from documents and decontextualise them so that they can be understood out of context. Specifically, we first recast claim extraction as extractive summarization in order to identify central sentences from documents, then rewrite them to include necessary context from the originating document through sentence decontextualisation. Evaluation with both automatic metrics and a fact-checking professional shows that our method is able to extract check-worthy claims from documents more accurately than previous work, while also improving evidence retrieval.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\PFRY8WPJ\\Deng et al. - 2024 - Document-level Claim Extraction and Decontextualisation for Fact-Checking.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\2T7IYU7M\\2406.html}
}

@inproceedings{dengInformationExtractionLowResource2024,
  title = {Information {{Extraction}} in {{Low-Resource Scenarios}}: {{Survey}} and {{Perspective}}},
  shorttitle = {Information {{Extraction}} in {{Low-Resource Scenarios}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Knowledge Graph}} ({{ICKG}})},
  author = {Deng, Shumin and Ma, Yubo and Zhang, Ningyu and Cao, Yixin and Hooi, Bryan},
  year = {2024},
  month = dec,
  pages = {33--49},
  doi = {10.1109/ICKG63256.2024.00013},
  urldate = {2025-05-15},
  abstract = {Information Extraction (IE) seeks to derive structured information from unstructured texts, often encountering obstacles in low-resource scenarios due to data scarcity and unseen classes. This paper presents a review of neural approaches to low-resource IE from traditional and LLM-based perspectives, systematically organizing them into a fine-grained taxonomy. Our empirical studies compare LLM-based methods with prior leading models, revealing that: (1) well-tuned LMs perform relatively best; (2) tuning open-resource LLMs and in-context learning with GPT family are generally effective; (3) LLMs struggle to tackle complex tasks with intricate schema. Furthermore, we compare traditional methods and discuss LLM-based approaches, spotlighting promising applications and delineating future research directions. This survey aims to foster understanding of this field, inspire new ideas, and encourage widespread applications in both academia and industry.},
  keywords = {Benchmark testing,Data models,Industries,Inference algorithms,Knowledge graphs,Surveys,Systematic literature review,Taxonomy,Tuning},
  file = {C:\Users\zahdehv\Zotero\storage\ITNUB3AF\10884152.html}
}

@misc{dengRephraseRespondLet2024,
  title = {Rephrase and {{Respond}}: {{Let Large Language Models Ask Better Questions}} for {{Themselves}}},
  shorttitle = {Rephrase and {{Respond}}},
  author = {Deng, Yihe and Zhang, Weitong and Chen, Zixiang and Gu, Quanquan},
  year = {2024},
  month = apr,
  number = {arXiv:2311.04205},
  eprint = {2311.04205},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.04205},
  urldate = {2025-05-02},
  abstract = {Misunderstandings arise not only in interpersonal communication but also between humans and Large Language Models (LLMs). Such discrepancies can make LLMs interpret seemingly unambiguous questions in unexpected ways, yielding incorrect responses. While it is widely acknowledged that the quality of a prompt, such as a question, significantly impacts the quality of the response provided by LLMs, a systematic method for crafting questions that LLMs can better comprehend is still underdeveloped. In this paper, we present a method named `Rephrase and Respond' (RaR), which allows LLMs to rephrase and expand questions posed by humans and provide responses in a single prompt. This approach serves as a simple yet effective prompting method for improving performance. We also introduce a two-step variant of RaR, where a rephrasing LLM first rephrases the question and then passes the original and rephrased questions together to a different responding LLM. This facilitates the effective utilization of rephrased questions generated by one LLM with another. Our experiments demonstrate that our methods significantly improve the performance of different models across a wide range to tasks. We further provide a comprehensive comparison between RaR and the popular Chain-of-Thought (CoT) methods, both theoretically and empirically. We show that RaR is complementary to CoT and can be combined with CoT to achieve even better performance. Our work not only contributes to enhancing LLM performance efficiently and effectively but also sheds light on a fair evaluation of LLM capabilities. Data and codes are available at https://github.com/uclaml/Rephrase-and-Respond.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\PGIYXKWG\\Deng et al. - 2024 - Rephrase and Respond Let Large Language Models Ask Better Questions for Themselves.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\UABF26JA\\2311.html}
}

@article{dominguezAcotacionEspacioBusqueda,
  title = {{Acotaci{\'o}n del espacio de b{\'u}squeda de la regresi{\'o}n simb{\'o}lica para ecuaciones diferenciales ordinarias lineales en los par{\'a}metros mediante redes neuronales}},
  author = {Dom{\'i}nguez, David Guaty},
  langid = {spanish},
  file = {C:\Users\zahdehv\Zotero\storage\AX69QEBK\Domínguez - Acotación del espacio de búsqueda de la regresión simbólica para ecuaciones diferenciales ordinarias.pdf}
}

@inproceedings{durantiLLMDrivenKnowledgeExtraction2025,
  title = {{{LLM-Driven Knowledge Extraction}} in~{{Temporal}} and~{{Description Logics}}},
  booktitle = {Knowledge {{Engineering}} and {{Knowledge Management}}},
  author = {Duranti, Damiano and Giorgini, Paolo and Mazzullo, Andrea and Robol, Marco and Roveri, Marco},
  editor = {Alam, Mehwish and Rospocher, Marco and {van Erp}, Marieke and Hollink, Laura and Gesese, Genet Asefa},
  year = {2025},
  pages = {190--208},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-77792-9_12},
  abstract = {Trustworthy knowledge extraction represents a bottleneck in the development of autonomous AI agents capable of integrating learning and reasoning capabilities. As a foundational framework of neuro-symbolic knowledge acquisition systems from semi-structured data, we introduce an approach that combines Large Language Model (LLM) functionalities with symbolic verification modules. In a process mining context, we propose to leverage LLMs to generate linear temporal logic specifications starting from sets of finite traces that represent event logs. In a knowledge representation setting, we focus instead on LLM-based extraction of description logic concepts to obtain human-readable conceptualizations that separate positive and negative labeled data instances. We integrate chat interfaces based on state-of-the-art LLMs with formal verification modules: in the process mining case, we employ model checking tools for linear temporal logic on finite traces; and, for description logic concept learning, we perform entailment checks using dedicated reasoning engines. First, we conduct a proof-of-concept evaluation of these architectures, comparing the performance of the LLMs on each task. We then provide an implementation of a GPT-based toolchain to automate the candidate generation and verification steps.},
  isbn = {978-3-031-77792-9},
  langid = {english}
}

@book{ecoHowWriteThesis2015,
  title = {How to Write a Thesis},
  author = {Eco, Umberto and Mongiat Farina, Caterina},
  year = {2015},
  publisher = {MIT Press},
  address = {Cambridge (Mass.) London},
  abstract = {"Eco's approach is anything but dry and academic. He not only offers practical advice but also considers larger questions about the value of the thesis-writing exercise. How to Write a Thesis is unlike any other writing manual. It reads like a novel. It is opinionated. It is frequently irreverent, sometimes polemical, and often hilarious. Eco advises students how to avoid "thesis neurosis" and he answers the important question "Must You Read Books?" He reminds students "You are not Proust" and "Write everything that comes into your head, but only in the first draft." Of course, there was no Internet in 1977, but Eco's index card research system offers important lessons about critical thinking and information curating for students of today who may be burdened by Big Data."--Publisher's description},
  isbn = {978-0-262-52713-2},
  langid = {english},
  lccn = {378.242},
  file = {C:\Users\zahdehv\Zotero\storage\NCI3T9U4\Eco and Mongiat Farina - 2015 - How to write a thesis.pdf}
}

@misc{ELPGPTLargeLanguage,
  title = {{{ELPGPT}}: {{Large Language Models Enhancing Link Prediction}} in {{Electrical Knowledge Graph}} {\textbar} {{International Journal}} of {{High Speed Electronics}} and {{Systems}}},
  urldate = {2025-05-15},
  howpublished = {https://www.worldscientific.com/doi/abs/10.1142/S0129156425401159},
  file = {C:\Users\zahdehv\Zotero\storage\DUD5L87E\S0129156425401159.html}
}

@misc{fengOntologygroundedAutomaticKnowledge2024,
  title = {Ontology-Grounded {{Automatic Knowledge Graph Construction}} by {{LLM}} under {{Wikidata}} Schema},
  author = {Feng, Xiaohan and Wu, Xixin and Meng, Helen},
  year = {2024},
  month = dec,
  number = {arXiv:2412.20942},
  eprint = {2412.20942},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.20942},
  urldate = {2025-05-15},
  abstract = {We propose an ontology-grounded approach to Knowledge Graph (KG) construction using Large Language Models (LLMs) on a knowledge base. An ontology is authored by generating Competency Questions (CQ) on knowledge base to discover knowledge scope, extracting relations from CQs, and attempt to replace equivalent relations by their counterpart in Wikidata. To ensure consistency and interpretability in the resulting KG, we ground generation of KG with the authored ontology based on extracted relations. Evaluation on benchmark datasets demonstrates competitive performance in knowledge graph construction task. Our work presents a promising direction for scalable KG construction pipeline with minimal human intervention, that yields high quality and human-interpretable KGs, which are interoperable with Wikidata semantics for potential knowledge base expansion.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\UZ3YQE7A\\Feng et al. - 2024 - Ontology-grounded Automatic Knowledge Graph Construction by LLM under Wikidata schema.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\KSEWC6BQ\\2412.html}
}

@misc{fernandoPromptbreederSelfReferentialSelfImprovement2023,
  title = {Promptbreeder: {{Self-Referential Self-Improvement Via Prompt Evolution}}},
  shorttitle = {Promptbreeder},
  author = {Fernando, Chrisantha and Banarse, Dylan and Michalewski, Henryk and Osindero, Simon and Rockt{\"a}schel, Tim},
  year = {2023},
  month = sep,
  number = {arXiv:2309.16797},
  eprint = {2309.16797},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.16797},
  urldate = {2025-05-01},
  abstract = {Popular prompt strategies like Chain-of-Thought Prompting can dramatically improve the reasoning abilities of Large Language Models (LLMs) in various domains. However, such hand-crafted prompt-strategies are often sub-optimal. In this paper, we present Promptbreeder, a general-purpose self-referential self-improvement mechanism that evolves and adapts prompts for a given domain. Driven by an LLM, Promptbreeder mutates a population of task-prompts, and subsequently evaluates them for fitness on a training set. Crucially, the mutation of these task-prompts is governed by mutation-prompts that the LLM generates and improves throughout evolution in a self-referential way. That is, Promptbreeder is not just improving task-prompts, but it is also improving the mutationprompts that improve these task-prompts. Promptbreeder outperforms state-of-the-art prompt strategies such as Chain-of-Thought and Plan-and-Solve Prompting on commonly used arithmetic and commonsense reasoning benchmarks. Furthermore, Promptbreeder is able to evolve intricate task-prompts for the challenging problem of hate speech classification.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\VZTZCK3C\\Fernando et al. - 2023 - Promptbreeder Self-Referential Self-Improvement Via Prompt Evolution.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\9S63IK6Q\\2309.html}
}

@misc{FileBuildingTheMemexSixtyYearsLaterTrendsAndDirectionsInPepdfID,
  title = {File {\textbar} {{buildingTheMemexSixtyYearsLaterTrendsAndDirectionsInPe}}.Pdf {\textbar} {{ID}}: 7h149q765 {\textbar} {{CU Scholar}}},
  urldate = {2025-05-08},
  howpublished = {https://scholar.colorado.edu/concern/parent/t722h9830/file\_sets/7h149q765},
  file = {C:\Users\zahdehv\Zotero\storage\2MZXH3BN\7h149q765.html}
}

@book{forteBuildingSecondBrain2022,
  title = {Building a {{Second Brain}}},
  author = {Forte, Tiago},
  year = {2022},
  month = jun,
  publisher = {Profile},
  langid = {english},
  annotation = {Item ID: \_:n0},
  file = {C:\Users\zahdehv\Zotero\storage\KXB5ATLF\Forte - 2022 - Building a Second Brain.epub}
}

@inproceedings{fragaAutomaticGenerationKnowledge2023,
  title = {On the {{Automatic Generation}} of {{Knowledge Connections}}:},
  shorttitle = {On the {{Automatic Generation}} of {{Knowledge Connections}}},
  booktitle = {Proceedings of the 25th {{International Conference}} on {{Enterprise Information Systems}}},
  author = {Fraga, Felipe and Poggi, Marcus and Casanova, Marco and Leme, Luiz},
  year = {2023},
  pages = {43--54},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  address = {Prague, Czech Republic},
  doi = {10.5220/0011781100003467},
  urldate = {2025-05-05},
  abstract = {Recently, the topic of Personal Knowledge Management (PKM) has seen a surge in popularity. This is illustrated by the accelerated growth of apps such as Notion, Obsidian, and Roam Research, as well as the appearance of books like ``How to Take Smart Notes'' and ``Building a Second Brain.'' However, the area of PKM has not seen much integration with Natural Language Processing (NLP). This opens up an interesting opportunity to apply NLP techniques to operating with knowledge. This paper proposes a methodology that uses NLP and networked note-taking apps to transform a siloed text collection into an interconnected and inter-navigable text collection. The navigation mechanisms are based on shared concepts and semantic relatedness between texts. The paper proposes a methodology, presents demonstrations using examples, and describes an evaluation to determine if the system functions correctly and whether the proposed connections are coherent.},
  isbn = {978-989-758-648-4},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\RJBGZGWE\Fraga et al. - 2023 - On the Automatic Generation of Knowledge Connections.pdf}
}

@misc{fuComplexityBasedPromptingMultiStep2023,
  title = {Complexity-{{Based Prompting}} for {{Multi-Step Reasoning}}},
  author = {Fu, Yao and Peng, Hao and Sabharwal, Ashish and Clark, Peter and Khot, Tushar},
  year = {2023},
  month = jan,
  number = {arXiv:2210.00720},
  eprint = {2210.00720},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2210.00720},
  urldate = {2025-05-01},
  abstract = {We study the task of prompting large-scale language models to perform multi-step reasoning. Existing work shows that when prompted with a chain of thoughts (CoT), sequences of short sentences describing intermediate reasoning steps towards a final answer, large language models can generate new reasoning chains and predict answers for new inputs. A central question is which reasoning examples make the most effective prompts. In this work, we propose complexity-based prompting, a simple and effective example selection scheme for multi-step reasoning. We show that prompts with higher reasoning complexity, i.e., chains with more reasoning steps, achieve substantially better performance on multi-step reasoning tasks over strong baselines. We further extend our complexity-based criteria from prompting (selecting inputs) to decoding (selecting outputs), where we sample multiple reasoning chains from the model, then choose the majority of generated answers from complex reasoning chains (over simple chains). When used to prompt GPT-3 and Codex, our approach substantially improves multi-step reasoning accuracy and achieves new state-of-the-art (SOTA) performance on three math benchmarks (GSM8K, MultiArith, and MathQA) and two BigBenchHard tasks (Date Understanding and Penguins), with an average +5.3 and up to +18 accuracy improvements. Compared with existing example selection schemes like manual tuning or retrieval-based selection, selection based on reasoning complexity is intuitive, easy to implement, and annotation-efficient. Further results demonstrate the robustness of performance gains from complex prompts under format perturbation and distribution shift.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\G5SFYR8I\\Fu et al. - 2023 - Complexity-Based Prompting for Multi-Step Reasoning.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\E7CZVMYB\\2210.html}
}

@misc{gaoMetaReasoningLarge2024,
  title = {Meta {{Reasoning}} for {{Large Language Models}}},
  author = {Gao, Peizhong and Xie, Ao and Mao, Shaoguang and Wu, Wenshan and Xia, Yan and Mi, Haipeng and Wei, Furu},
  year = {2024},
  month = jun,
  number = {arXiv:2406.11698},
  eprint = {2406.11698},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.11698},
  urldate = {2025-02-28},
  abstract = {We introduce Meta-Reasoning Prompting (MRP), a novel and efficient system prompting method for large language models (LLMs) inspired by human metareasoning. Traditional in-context learning-based reasoning techniques, such as Tree-of-Thoughts, show promise but lack consistent state-of-the-art performance across diverse tasks due to their specialized nature. MRP addresses this limitation by guiding LLMs to dynamically select and apply different reasoning methods based on the specific requirements of each task, optimizing both performance and computational efficiency. With MRP, LLM reasoning operates in two phases. Initially, the LLM identifies the most appropriate reasoning method using task input cues and objective descriptions of available methods. Subsequently, it applies the chosen method to complete the task. This dynamic strategy mirrors human meta-reasoning, allowing the model to excel in a wide range of problem domains. We evaluate the effectiveness of MRP through comprehensive benchmarks. The results demonstrate that MRP achieves or approaches state-of-the-art performance across diverse tasks. MRP represents a significant advancement in enabling LLMs to identify cognitive challenges across problems and leverage benefits across different reasoning approaches, enhancing their ability to handle diverse and complex problem domains efficiently. Every LLM deserves a Meta-Reasoning Prompting to unlock its full potential and ensure adaptability in an ever-evolving landscape of challenges and applications.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {C:\Users\zahdehv\Zotero\storage\B4UKAFK6\Gao et al. - 2024 - Meta Reasoning for Large Language Models.pdf}
}

@misc{gaoPALProgramaidedLanguage2023,
  title = {{{PAL}}: {{Program-aided Language Models}}},
  shorttitle = {{{PAL}}},
  author = {Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  year = {2023},
  month = jan,
  number = {arXiv:2211.10435},
  eprint = {2211.10435},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2211.10435},
  urldate = {2025-05-07},
  abstract = {Large language models (LLMs) have recently demonstrated an impressive ability to perform arithmetic and symbolic reasoning tasks, when provided with a few examples at test time ("few-shot prompting"). Much of this success can be attributed to prompting methods such as "chain-of-thought'', which employ LLMs for both understanding the problem description by decomposing it into steps, as well as solving each step of the problem. While LLMs seem to be adept at this sort of step-by-step decomposition, LLMs often make logical and arithmetic mistakes in the solution part, even when the problem is decomposed correctly. In this paper, we present Program-Aided Language models (PAL): a novel approach that uses the LLM to read natural language problems and generate programs as the intermediate reasoning steps, but offloads the solution step to a runtime such as a Python interpreter. With PAL, decomposing the natural language problem into runnable steps remains the only learning task for the LLM, while solving is delegated to the interpreter. We demonstrate this synergy between a neural LLM and a symbolic interpreter across 13 mathematical, symbolic, and algorithmic reasoning tasks from BIG-Bench Hard and other benchmarks. In all these natural language reasoning tasks, generating code using an LLM and reasoning using a Python interpreter leads to more accurate results than much larger models. For example, PAL using Codex achieves state-of-the-art few-shot accuracy on the GSM8K benchmark of math word problems, surpassing PaLM-540B which uses chain-of-thought by absolute 15\% top-1. Our code and data are publicly available at http://reasonwithpal.com/ .},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\6CY2G545\\Gao et al. - 2023 - PAL Program-aided Language Models.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\8MRJL4K4\\2211.html}
}

@misc{gautamFactGeniusCombiningZeroShot2024,
  title = {{{FactGenius}}: {{Combining Zero-Shot Prompting}} and {{Fuzzy Relation Mining}} to {{Improve Fact Verification}} with {{Knowledge Graphs}}},
  shorttitle = {{{FactGenius}}},
  author = {Gautam, Sushant},
  year = {2024},
  month = jun,
  number = {arXiv:2406.01311},
  eprint = {2406.01311},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.01311},
  urldate = {2025-04-11},
  abstract = {Fact-checking is a crucial natural language processing (NLP) task that verifies the truthfulness of claims by considering reliable evidence. Traditional methods are often limited by labour-intensive data curation and rule-based approaches. In this paper, we present FactGenius, a novel method that enhances fact-checking by combining zero-shot prompting of large language models (LLMs) with fuzzy text matching on knowledge graphs (KGs). Leveraging DBpedia, a structured linked data dataset derived from Wikipedia, FactGenius refines LLM-generated connections using similarity measures to ensure accuracy. The evaluation of FactGenius on the FactKG, a benchmark dataset for fact verification, demonstrates that it significantly outperforms existing baselines, particularly when fine-tuning RoBERTa as a classifier. The two-stage approach of filtering and validating connections proves crucial, achieving superior performance across various reasoning types and establishing FactGenius as a promising tool for robust fact-checking. The code and materials are available at https://github.com/SushantGautam/FactGenius.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\S6SBXJMH\\Gautam - 2024 - FactGenius Combining Zero-Shot Prompting and Fuzzy Relation Mining to Improve Fact Verification wit.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\GNFPHMCN\\2406.html}
}

@misc{gengGrammarConstrainedDecodingStructured2024,
  title = {Grammar-{{Constrained Decoding}} for {{Structured NLP Tasks}} without {{Finetuning}}},
  author = {Geng, Saibo and Josifoski, Martin and Peyrard, Maxime and West, Robert},
  year = {2024},
  month = jan,
  number = {arXiv:2305.13971},
  eprint = {2305.13971},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.13971},
  urldate = {2025-06-01},
  abstract = {Despite their impressive performance, large language models (LMs) still struggle with reliably generating complex output structures when not finetuned to follow the required output format exactly. To address this issue, grammarconstrained decoding (GCD) can be used to control the generation of LMs, guaranteeing that the output follows a given structure. Most existing GCD methods are, however, limited to specific tasks, such as parsing or code generation. In this work, we demonstrate that formal grammars can describe the output space for a much wider range of tasks and argue that GCD can serve as a unified framework for structured NLP tasks in general. For increased flexibility, we introduce input-dependent grammars, which allow the grammar to depend on the input and thus enable the generation of different output structures for different inputs. We then empirically demonstrate the power and flexibility of GCD-enhanced LMs on (1) information extraction, (2) entity disambiguation, and (3) constituency parsing. Our results indicate that grammar-constrained LMs substantially outperform unconstrained LMs or even beat task-specific finetuned models. Grammar constraints thus hold great promise for harnessing off-the-shelf LMs for a wide range of structured NLP tasks, especially where training data is scarce or finetuning is expensive. Code and data: https://github.com/epfl-dlab/GCD.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C:\Users\zahdehv\Zotero\storage\DBPU8DBN\Geng et al. - 2024 - Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning.pdf}
}

@misc{gouToRAToolIntegratedReasoning2024,
  title = {{{ToRA}}: {{A Tool-Integrated Reasoning Agent}} for {{Mathematical Problem Solving}}},
  shorttitle = {{{ToRA}}},
  author = {Gou, Zhibin and Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Yang, Yujiu and Huang, Minlie and Duan, Nan and Chen, Weizhu},
  year = {2024},
  month = feb,
  number = {arXiv:2309.17452},
  eprint = {2309.17452},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.17452},
  urldate = {2025-05-07},
  abstract = {Large language models have made significant progress in various language tasks, yet they still struggle with complex mathematics. In this paper, we propose ToRA a series of Tool-integrated Reasoning Agents designed to solve challenging mathematical problems by seamlessly integrating natural language reasoning with the utilization of external tools (e.g., computation libraries and symbolic solvers), thereby amalgamating the analytical prowess of language and the computational efficiency of tools. To train ToRA, we curate interactive tool-use trajectories on mathematical datasets, apply imitation learning on the annotations, and propose output space shaping to further refine models' reasoning behavior. As a result, ToRA models significantly outperform open-source models on 10 mathematical reasoning datasets across all scales with 13\%-19\% absolute improvements on average. Notably, ToRA-7B reaches 44.6\% on the competition-level dataset MATH, surpassing the best open-source model WizardMath-70B by 22\% absolute. ToRA-Code-34B is also the first open-source model that achieves an accuracy exceeding 50\% on MATH, which significantly outperforms GPT-4's CoT result, and is competitive with GPT-4 solving problems with programs. Additionally, we conduct a comprehensive analysis of the benefits and remaining challenges of tool interaction for mathematical reasoning, providing valuable insights for future research.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\5HXNEMCK\\Gou et al. - 2024 - ToRA A Tool-Integrated Reasoning Agent for Mathematical Problem Solving.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\RWKB4FEQ\\2309.html}
}

@misc{grattafioriLlama3Herd2024,
  title = {The {{Llama}} 3 {{Herd}} of {{Models}}},
  author = {Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and {Al-Dahle}, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and Yang, Amy and Fan, Angela and Goyal, Anirudh and Hartshorn, Anthony and Yang, Aobo and Mitra, Archi and Sravankumar, Archie and Korenev, Artem and Hinsvark, Arthur and Rao, Arun and Zhang, Aston and Rodriguez, Aurelien and Gregerson, Austen and Spataru, Ava and Roziere, Baptiste and Biron, Bethany and Tang, Binh and Chern, Bobbie and Caucheteux, Charlotte and Nayak, Chaya and Bi, Chloe and Marra, Chris and McConnell, Chris and Keller, Christian and Touret, Christophe and Wu, Chunyang and Wong, Corinne and Ferrer, Cristian Canton and Nikolaidis, Cyrus and Allonsius, Damien and Song, Daniel and Pintz, Danielle and Livshits, Danny and Wyatt, Danny and Esiobu, David and Choudhary, Dhruv and Mahajan, Dhruv and {Garcia-Olano}, Diego and Perino, Diego and Hupkes, Dieuwke and Lakomkin, Egor and AlBadawy, Ehab and Lobanova, Elina and Dinan, Emily and Smith, Eric Michael and Radenovic, Filip and Guzm{\'a}n, Francisco and Zhang, Frank and Synnaeve, Gabriel and Lee, Gabrielle and Anderson, Georgia Lewis and Thattai, Govind and Nail, Graeme and Mialon, Gregoire and Pang, Guan and Cucurell, Guillem and Nguyen, Hailey and Korevaar, Hannah and Xu, Hu and Touvron, Hugo and Zarov, Iliyan and Ibarra, Imanol Arrieta and Kloumann, Isabel and Misra, Ishan and Evtimov, Ivan and Zhang, Jack and Copet, Jade and Lee, Jaewon and Geffert, Jan and Vranes, Jana and Park, Jason and Mahadeokar, Jay and Shah, Jeet and van der Linde, Jelmer and Billock, Jennifer and Hong, Jenny and Lee, Jenya and Fu, Jeremy and Chi, Jianfeng and Huang, Jianyu and Liu, Jiawen and Wang, Jie and Yu, Jiecao and Bitton, Joanna and Spisak, Joe and Park, Jongsoo and Rocca, Joseph and Johnstun, Joshua and Saxe, Joshua and Jia, Junteng and Alwala, Kalyan Vasuden and Prasad, Karthik and Upasani, Kartikeya and Plawiak, Kate and Li, Ke and Heafield, Kenneth and Stone, Kevin and {El-Arini}, Khalid and Iyer, Krithika and Malik, Kshitiz and Chiu, Kuenley and Bhalla, Kunal and Lakhotia, Kushal and {Rantala-Yeary}, Lauren and van der Maaten, Laurens and Chen, Lawrence and Tan, Liang and Jenkins, Liz and Martin, Louis and Madaan, Lovish and Malo, Lubo and Blecher, Lukas and Landzaat, Lukas and de Oliveira, Luke and Muzzi, Madeline and Pasupuleti, Mahesh and Singh, Mannat and Paluri, Manohar and Kardas, Marcin and Tsimpoukelli, Maria and Oldham, Mathew and Rita, Mathieu and Pavlova, Maya and Kambadur, Melanie and Lewis, Mike and Si, Min and Singh, Mitesh Kumar and Hassan, Mona and Goyal, Naman and Torabi, Narjes and Bashlykov, Nikolay and Bogoychev, Nikolay and Chatterji, Niladri and Zhang, Ning and Duchenne, Olivier and {\c C}elebi, Onur and Alrassy, Patrick and Zhang, Pengchuan and Li, Pengwei and Vasic, Petar and Weng, Peter and Bhargava, Prajjwal and Dubal, Pratik and Krishnan, Praveen and Koura, Punit Singh and Xu, Puxin and He, Qing and Dong, Qingxiao and Srinivasan, Ragavan and Ganapathy, Raj and Calderer, Ramon and Cabral, Ricardo Silveira and Stojnic, Robert and Raileanu, Roberta and Maheswari, Rohan and Girdhar, Rohit and Patel, Rohit and Sauvestre, Romain and Polidoro, Ronnie and Sumbaly, Roshan and Taylor, Ross and Silva, Ruan and Hou, Rui and Wang, Rui and Hosseini, Saghar and Chennabasappa, Sahana and Singh, Sanjay and Bell, Sean and Kim, Seohyun Sonia and Edunov, Sergey and Nie, Shaoliang and Narang, Sharan and Raparthy, Sharath and Shen, Sheng and Wan, Shengye and Bhosale, Shruti and Zhang, Shun and Vandenhende, Simon and Batra, Soumya and Whitman, Spencer and Sootla, Sten and Collot, Stephane and Gururangan, Suchin and Borodinsky, Sydney and Herman, Tamar and Fowler, Tara and Sheasha, Tarek and Georgiou, Thomas and Scialom, Thomas and Speckbacher, Tobias and Mihaylov, Todor and Xiao, Tong and Karn, Ujjwal and Goswami, Vedanuj and Gupta, Vibhor and Ramanathan, Vignesh and Kerkez, Viktor and Gonguet, Vincent and Do, Virginie and Vogeti, Vish and Albiero, V{\'i}tor and Petrovic, Vladan and Chu, Weiwei and Xiong, Wenhan and Fu, Wenyin and Meers, Whitney and Martinet, Xavier and Wang, Xiaodong and Wang, Xiaofang and Tan, Xiaoqing Ellen and Xia, Xide and Xie, Xinfeng and Jia, Xuchao and Wang, Xuewei and Goldschlag, Yaelle and Gaur, Yashesh and Babaei, Yasmine and Wen, Yi and Song, Yiwen and Zhang, Yuchen and Li, Yue and Mao, Yuning and Coudert, Zacharie Delpierre and Yan, Zheng and Chen, Zhengxing and Papakipos, Zoe and Singh, Aaditya and Srivastava, Aayushi and Jain, Abha and Kelsey, Adam and Shajnfeld, Adam and Gangidi, Adithya and Victoria, Adolfo and Goldstand, Ahuva and Menon, Ajay and Sharma, Ajay and Boesenberg, Alex and Baevski, Alexei and Feinstein, Allie and Kallet, Amanda and Sangani, Amit and Teo, Amos and Yunus, Anam and Lupu, Andrei and Alvarado, Andres and Caples, Andrew and Gu, Andrew and Ho, Andrew and Poulton, Andrew and Ryan, Andrew and Ramchandani, Ankit and Dong, Annie and Franco, Annie and Goyal, Anuj and Saraf, Aparajita and Chowdhury, Arkabandhu and Gabriel, Ashley and Bharambe, Ashwin and Eisenman, Assaf and Yazdan, Azadeh and James, Beau and Maurer, Ben and Leonhardi, Benjamin and Huang, Bernie and Loyd, Beth and Paola, Beto De and Paranjape, Bhargavi and Liu, Bing and Wu, Bo and Ni, Boyu and Hancock, Braden and Wasti, Bram and Spence, Brandon and Stojkovic, Brani and Gamido, Brian and Montalvo, Britt and Parker, Carl and Burton, Carly and Mejia, Catalina and Liu, Ce and Wang, Changhan and Kim, Changkyu and Zhou, Chao and Hu, Chester and Chu, Ching-Hsiang and Cai, Chris and Tindal, Chris and Feichtenhofer, Christoph and Gao, Cynthia and Civin, Damon and Beaty, Dana and Kreymer, Daniel and Li, Daniel and Adkins, David and Xu, David and Testuggine, Davide and David, Delia and Parikh, Devi and Liskovich, Diana and Foss, Didem and Wang, Dingkang and Le, Duc and Holland, Dustin and Dowling, Edward and Jamil, Eissa and Montgomery, Elaine and Presani, Eleonora and Hahn, Emily and Wood, Emily and Le, Eric-Tuan and Brinkman, Erik and Arcaute, Esteban and Dunbar, Evan and Smothers, Evan and Sun, Fei and Kreuk, Felix and Tian, Feng and Kokkinos, Filippos and Ozgenel, Firat and Caggioni, Francesco and Kanayet, Frank and Seide, Frank and Florez, Gabriela Medina and Schwarz, Gabriella and Badeer, Gada and Swee, Georgia and Halpern, Gil and Herman, Grant and Sizov, Grigory and Guangyi and Zhang and Lakshminarayanan, Guna and Inan, Hakan and Shojanazeri, Hamid and Zou, Han and Wang, Hannah and Zha, Hanwen and Habeeb, Haroun and Rudolph, Harrison and Suk, Helen and Aspegren, Henry and Goldman, Hunter and Zhan, Hongyuan and Damlaj, Ibrahim and Molybog, Igor and Tufanov, Igor and Leontiadis, Ilias and Veliche, Irina-Elena and Gat, Itai and Weissman, Jake and Geboski, James and Kohli, James and Lam, Janice and Asher, Japhet and Gaya, Jean-Baptiste and Marcus, Jeff and Tang, Jeff and Chan, Jennifer and Zhen, Jenny and Reizenstein, Jeremy and Teboul, Jeremy and Zhong, Jessica and Jin, Jian and Yang, Jingyi and Cummings, Joe and Carvill, Jon and Shepard, Jon and McPhie, Jonathan and Torres, Jonathan and Ginsburg, Josh and Wang, Junjie and Wu, Kai and U, Kam Hou and Saxena, Karan and Khandelwal, Kartikay and Zand, Katayoun and Matosich, Kathy and Veeraraghavan, Kaushik and Michelena, Kelly and Li, Keqian and Jagadeesh, Kiran and Huang, Kun and Chawla, Kunal and Huang, Kyle and Chen, Lailin and Garg, Lakshya and A, Lavender and Silva, Leandro and Bell, Lee and Zhang, Lei and Guo, Liangpeng and Yu, Licheng and Moshkovich, Liron and Wehrstedt, Luca and Khabsa, Madian and Avalani, Manav and Bhatt, Manish and Mankus, Martynas and Hasson, Matan and Lennie, Matthew and Reso, Matthias and Groshev, Maxim and Naumov, Maxim and Lathi, Maya and Keneally, Meghan and Liu, Miao and Seltzer, Michael L. and Valko, Michal and Restrepo, Michelle and Patel, Mihir and Vyatskov, Mik and Samvelyan, Mikayel and Clark, Mike and Macey, Mike and Wang, Mike and Hermoso, Miquel Jubert and Metanat, Mo and Rastegari, Mohammad and Bansal, Munish and Santhanam, Nandhini and Parks, Natascha and White, Natasha and Bawa, Navyata and Singhal, Nayan and Egebo, Nick and Usunier, Nicolas and Mehta, Nikhil and Laptev, Nikolay Pavlovich and Dong, Ning and Cheng, Norman and Chernoguz, Oleg and Hart, Olivia and Salpekar, Omkar and Kalinli, Ozlem and Kent, Parkin and Parekh, Parth and Saab, Paul and Balaji, Pavan and Rittner, Pedro and Bontrager, Philip and Roux, Pierre and Dollar, Piotr and Zvyagina, Polina and Ratanchandani, Prashant and Yuvraj, Pritish and Liang, Qian and Alao, Rachad and Rodriguez, Rachel and Ayub, Rafi and Murthy, Raghotham and Nayani, Raghu and Mitra, Rahul and Parthasarathy, Rangaprabhu and Li, Raymond and Hogan, Rebekkah and Battey, Robin and Wang, Rocky and Howes, Russ and Rinott, Ruty and Mehta, Sachin and Siby, Sachin and Bondu, Sai Jayesh and Datta, Samyak and Chugh, Sara and Hunt, Sara and Dhillon, Sargun and Sidorov, Sasha and Pan, Satadru and Mahajan, Saurabh and Verma, Saurabh and Yamamoto, Seiji and Ramaswamy, Sharadh and Lindsay, Shaun and Lindsay, Shaun and Feng, Sheng and Lin, Shenghao and Zha, Shengxin Cindy and Patil, Shishir and Shankar, Shiva and Zhang, Shuqiang and Zhang, Shuqiang and Wang, Sinong and Agarwal, Sneha and Sajuyigbe, Soji and Chintala, Soumith and Max, Stephanie and Chen, Stephen and Kehoe, Steve and Satterfield, Steve and Govindaprasad, Sudarshan and Gupta, Sumit and Deng, Summer and Cho, Sungmin and Virk, Sunny and Subramanian, Suraj and Choudhury, Sy and Goldman, Sydney and Remez, Tal and Glaser, Tamar and Best, Tamara and Koehler, Thilo and Robinson, Thomas and Li, Tianhe and Zhang, Tianjun and Matthews, Tim and Chou, Timothy and Shaked, Tzook and Vontimitta, Varun and Ajayi, Victoria and Montanez, Victoria and Mohan, Vijai and Kumar, Vinay Satish and Mangla, Vishal and Ionescu, Vlad and Poenaru, Vlad and Mihailescu, Vlad Tiberiu and Ivanov, Vladimir and Li, Wei and Wang, Wenchen and Jiang, Wenwen and Bouaziz, Wes and Constable, Will and Tang, Xiaocheng and Wu, Xiaojian and Wang, Xiaolan and Wu, Xilun and Gao, Xinbo and Kleinman, Yaniv and Chen, Yanjun and Hu, Ye and Jia, Ye and Qi, Ye and Li, Yenda and Zhang, Yilin and Zhang, Ying and Adi, Yossi and Nam, Youngjin and Yu and Wang and Zhao, Yu and Hao, Yuchen and Qian, Yundi and Li, Yunlu and He, Yuzi and Rait, Zach and DeVito, Zachary and Rosnbrick, Zef and Wen, Zhaoduo and Yang, Zhenyu and Zhao, Zhiwei and Ma, Zhiyu},
  year = {2024},
  month = nov,
  number = {arXiv:2407.21783},
  eprint = {2407.21783},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.21783},
  urldate = {2025-05-07},
  abstract = {Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\7YWZZI5R\\Grattafiori et al. - 2024 - The Llama 3 Herd of Models.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\3QLKWUWL\\2407.html}
}

@article{grundspenkisAgentBasedApproach2007,
  title = {Agent Based Approach for Organization and Personal Knowledge Modelling: Knowledge Management Perspective},
  shorttitle = {Agent Based Approach for Organization and Personal Knowledge Modelling},
  author = {Grundspenkis, Janis},
  year = {2007},
  month = jul,
  journal = {Journal of Intelligent Manufacturing},
  volume = {18},
  number = {4},
  pages = {451--457},
  issn = {0956-5515, 1572-8145},
  doi = {10.1007/s10845-007-0052-6},
  urldate = {2025-05-08},
  abstract = {The paper tries to bridge gap between knowledge management and artificial intelligence approaches proposing agent-based framework for modelling organization and personal knowledge. The perspective of knowledge management is chosen to develop two conceptual models---one describes the intelligent enterprise memory, another models an intelligent organization's knowledge management system. The concept of an agent-based environment of the knowledge worker for personal and organizational knowledge management support is introduced.},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\WUSLX2WJ\Grundspenkis - 2007 - Agent based approach for organization and personal knowledge modelling knowledge management perspec.pdf}
}

@inproceedings{hamannExpandingKnowledgeGraphs2024,
  title = {Expanding {{Knowledge Graphs Through Text}}: {{Leveraging Large Language Models}} for {{Inductive Link Prediction}}},
  shorttitle = {Expanding {{Knowledge Graphs Through Text}}},
  booktitle = {{{INFORMATIK}} 2024},
  author = {Hamann, Felix and Falk, Maurice and Walker, Lukas},
  year = {2024},
  pages = {1407--1417},
  publisher = {Gesellschaft f{\"u}r Informatik e.V.},
  issn = {2944-7682},
  urldate = {2025-05-15},
  abstract = {Knowledge graphs (KG) play a crucial role for knowledge modeling in various domains such as web search, medical applications, or technical support, yet they are often incomplete. To mitigate this problem, knowledge graph completion (KGC) may be used to infer missing links of the graph. Taking it a step further, in an automated knowledge acquisition process, links for entirely new, unseen entities may be incorporated. This process is known as inductive link prediction (I-LP). Optionally, text as an external source of information is leveraged to infer the correct linkage of such entities. Depending on the context, this text either provides a comprehensive singular description of the entity or includes numerous incidental references to it. This paper presents a study that explores the application of LLAMA3 as a representative of the current generation of large language models (LLM) to I-LP. Through experimentation on popular benchmark datasets such as Wikidata5m, FB15k-237, WN18-RR, and IRT2, we evaluate the performance of LLMs for inserting new facts into a knowledge base, given textual references to the target object. These benchmarks, by design, exhibit significant variations in the quality of the associated text, as well as in the number of entities and links included. This paper explores several prompt formulations and studies whether pre-emptive retrieval of text helps. For automated link prediction, we implement the full cycle of prompt generation, answer processing, entity candidate lookup, and finally link prediction. Our results show that LLM-based inductive link prediction is outperformed by previously suggested models which fine-tune task-specific LM encoders.},
  isbn = {978-3-88579-746-3},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\AJ2WXX65\Hamann et al. - 2024 - Expanding Knowledge Graphs Through Text Leveraging Large Language Models for Inductive Link Predict.pdf}
}

@misc{heLinkGPTTeachingLarge2024,
  title = {{{LinkGPT}}: {{Teaching Large Language Models To Predict Missing Links}}},
  shorttitle = {{{LinkGPT}}},
  author = {He, Zhongmou and Zhu, Jing and Qian, Shengyi and Chai, Joyce and Koutra, Danai},
  year = {2024},
  month = jun,
  number = {arXiv:2406.04640},
  eprint = {2406.04640},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.04640},
  urldate = {2025-05-15},
  abstract = {Large Language Models (LLMs) have shown promising results on various language and vision tasks. Recently, there has been growing interest in applying LLMs to graph-based tasks, particularly on Text-Attributed Graphs (TAGs). However, most studies have focused on node classification, while the use of LLMs for link prediction (LP) remains understudied. In this work, we propose a new task on LLMs, where the objective is to leverage LLMs to predict missing links between nodes in a graph. This task evaluates an LLM's ability to reason over structured data and infer new facts based on learned patterns. This new task poses two key challenges: (1) How to effectively integrate pairwise structural information into the LLMs, which is known to be crucial for LP performance, and (2) how to solve the computational bottleneck when teaching LLMs to perform LP. To address these challenges, we propose LinkGPT, the first end-to-end trained LLM for LP tasks. To effectively enhance the LLM's ability to understand the underlying structure, we design a two-stage instruction tuning approach where the first stage fine-tunes the pairwise encoder, projector, and node projector, and the second stage further fine-tunes the LLMs to predict links. To address the efficiency challenges at inference time, we introduce a retrieval-reranking scheme. Experiments show that LinkGPT can achieve state-of-the-art performance on real-world graphs as well as superior generalization in zero-shot and few-shot learning, surpassing existing benchmarks. At inference time, it can achieve \$10{\textbackslash}times\$ speedup while maintaining high LP accuracy.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\FLECEHIJ\\He et al. - 2024 - LinkGPT Teaching Large Language Models To Predict Missing Links.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\4YTSMK83\\2406.html}
}

@misc{hewingPromptCanvasLiteratureBased2024,
  title = {The {{Prompt Canvas}}: {{A Literature-Based Practitioner Guide}} for {{Creating Effective Prompts}} in {{Large Language Models}}},
  shorttitle = {The {{Prompt Canvas}}},
  author = {Hewing, Michael and Leinhos, Vincent},
  year = {2024},
  month = dec,
  number = {arXiv:2412.05127},
  eprint = {2412.05127},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.05127},
  urldate = {2025-02-28},
  abstract = {The rise of large language models (LLMs) has highlighted the importance of prompt engineering as a crucial technique for optimizing model outputs. While experimentation with various prompting methods, such as Few-shot, Chain-of-Thought, and role-based techniques, has yielded promising results, these advancements remain fragmented across academic papers, blog posts and anecdotal experimentation. The lack of a single, unified resource to consolidate the field's knowledge impedes the progress of both research and practical application. This paper argues for the creation of an overarching framework that synthesizes existing methodologies into a cohesive overview for practitioners. Using a design-based research approach, we present the Prompt Canvas (Figure 1), a structured framework resulting from an extensive literature review on prompt engineering that captures current knowledge and expertise. By combining the conceptual foundations and practical strategies identified in prompt engineering, the Prompt Canvas provides a practical approach for leveraging the potential of Large Language Models. It is primarily designed as a learning resource for pupils, students and employees, offering a structured introduction to prompt engineering. This work aims to contribute to the growing discourse on prompt engineering by establishing a unified methodology for researchers and providing guidance for practitioners.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence},
  file = {C:\Users\zahdehv\Zotero\storage\GVRBUX3S\Hewing and Leinhos - 2024 - The Prompt Canvas A Literature-Based Practitioner Guide for Creating Effective Prompts in Large Lan.pdf}
}

@misc{huGPTKBComprehensivelyMaterializing2024,
  title = {{{GPTKB}}: {{Comprehensively Materializing Factual LLM Knowledge}}},
  shorttitle = {{{GPTKB}}},
  author = {Hu, Yujia and Nguyen, Tuan-Phong and Ghosh, Shrestha and Razniewski, Simon},
  year = {2024},
  month = dec,
  number = {arXiv:2411.04920},
  eprint = {2411.04920},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2411.04920},
  urldate = {2025-05-15},
  abstract = {LLMs have majorly advanced NLP and AI, and next to their ability to perform a wide range of procedural tasks, a major success factor is their internalized factual knowledge. Since (Petroni et al., 2019), analyzing this knowledge has gained attention. However, most approaches investigate one question at a time via modest-sized pre-defined samples, introducing an availability bias (Tversky and Kahnemann, 1973) that prevents the discovery of knowledge (or beliefs) of LLMs beyond the experimenter's predisposition. To address this challenge, we propose a novel methodology to comprehensively materializing an LLM's factual knowledge through recursive querying and result consolidation. As a prototype, we employ GPT-4o-mini to construct GPTKB, a large-scale knowledge base (KB) comprising 105 million triples for over 2.9 million entities - achieved at 1\% of the cost of previous KB projects. This work marks a milestone in two areas: For LLM research, for the first time, it provides constructive insights into the scope and structure of LLMs' knowledge (or beliefs). For KB construction, it pioneers new pathways for the long-standing challenge of general-domain KB construction. GPTKB is accessible at https://gptkb.org.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Databases},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\SZWAQ4PM\\Hu et al. - 2024 - GPTKB Comprehensively Materializing Factual LLM Knowledge.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\C745WPMN\\2411.html}
}

@misc{ingalaApproximationAlgorithmsRectangle2017,
  title = {Approximation {{Algorithms}} for {{Rectangle Packing Problems}} ({{PhD Thesis}})},
  author = {Ingala, Salvatore},
  year = {2017},
  month = nov,
  number = {arXiv:1711.07851},
  eprint = {1711.07851},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1711.07851},
  urldate = {2025-02-28},
  abstract = {In rectangle packing problems we are given the task of placing axis-aligned rectangles in a given plane region, so that they do not overlap with each other. In Maximum Weight Independent Set of Rectangles (MWISR), their position is given and we can only select which rectangles to choose, while trying to maximize their total weight. In Strip Packing (SP), we have to pack all the given rectangles in a rectangular region of fixed width, while minimizing its height. In 2-Dimensional Geometric Knapsack (2DGK), the target region is a square of a given size, and our goal is to select and pack a subset of the given rectangles of maximum weight. We study a generalization of MWISR and use it to improve the approximation for a resource allocation problem called bagUFP. We revisit some classical results on SP and 2DGK, by proposing a framework based on smaller containers that are packed with simpler rules; while variations of this scheme are indeed a standard technique in this area, we abstract away some of the problem-specific differences, obtaining simpler algorithms that work for different problems. We obtain improved approximations for SP in pseudo-polynomial time, and for a variant of 2DGK where one can to rotate the rectangles by 90\{{\textbackslash}deg\}. For the latter, we propose the first algorithms with approximation factor better than 2. For the main variant of 2DGK (without rotations), a container-based approach seems to face a natural barrier of 2 in the approximation factor. Thus, we consider a generalized kind of packing that combines container packings with another packing problem that we call L-packing problem, where we have to pack rectangles in an L-shaped region of the plane. By finding a (1 + \{{\textbackslash}epsilon\})-approximation for this problem and exploiting the combinatorial structure of 2DGK, we obtain the first algorithms that break the barrier of 2 for the approximation factor of this problem.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Data Structures and Algorithms},
  file = {C:\Users\zahdehv\Zotero\storage\ED86ALGF\Ingala - 2017 - Approximation Algorithms for Rectangle Packing Problems (PhD Thesis).pdf}
}

@article{jansenIntegrativeReviewCognitive2017,
  title = {An Integrative Review of the Cognitive Costs and Benefits of Note-Taking},
  author = {Jansen, Ren{\'e}e S. and Lakens, Daniel and IJsselsteijn, Wijnand A.},
  year = {2017},
  month = nov,
  journal = {Educational Research Review},
  volume = {22},
  pages = {223--233},
  issn = {1747938X},
  doi = {10.1016/j.edurev.2017.10.001},
  urldate = {2025-05-08},
  abstract = {Students frequently engage in note-taking to improve the amount of information they remember from lectures. One beneficial effect of note-taking is known as the encoding effect, which refers to deeper processing of information as a consequence of taking notes. This review consists of two parts. In the first part, four lines of research on the encoding effect are summarized: 1) manipulation of the lecture material, 2) manipulation of the method of note-taking, 3) the importance of individual differences, and 4) the testing procedure used in the empirical studies. This review highlights the fragmented nature of the current literature. In the second part of this review five forms of cognitive load that are induced by note-taking are distinguished. Cognitive load theory is used to integrate the divergent results in the literature. Based on the review, it is concluded that cognitive load theory provides a useful framework for future theory development and experimental work.},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\94ZUU296\Jansen et al. - 2017 - An integrative review of the cognitive costs and benefits of note-taking.pdf}
}

@misc{jaykdoeJaykdoeInfranodus2025,
  title = {Jaykdoe/Infranodus},
  author = {{jaykdoe}},
  year = {2025},
  month = may,
  urldate = {2025-05-09}
}

@inproceedings{jungMaieuticPromptingLogically2022,
  title = {Maieutic {{Prompting}}: {{Logically Consistent Reasoning}} with {{Recursive Explanations}}},
  shorttitle = {Maieutic {{Prompting}}},
  booktitle = {Proceedings of the 2022 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Jung, Jaehun and Qin, Lianhui and Welleck, Sean and Brahman, Faeze and Bhagavatula, Chandra and Le Bras, Ronan and Choi, Yejin},
  editor = {Goldberg, Yoav and Kozareva, Zornitsa and Zhang, Yue},
  year = {2022},
  month = dec,
  pages = {1266--1279},
  publisher = {Association for Computational Linguistics},
  address = {Abu Dhabi, United Arab Emirates},
  doi = {10.18653/v1/2022.emnlp-main.82},
  urldate = {2025-05-01},
  abstract = {Pre-trained language models (LMs) struggle with consistent reasoning; recently, prompting LMs to generate explanations that self-guide the inference has emerged as a promising direction to amend this. However, these approaches are fundamentally bounded by the correctness of explanations, which themselves are often noisy and inconsistent. In this work, we develop Maieutic Prompting, which aims to infer a correct answer to a question even from the unreliable generations of LM. Maieutic Prompting induces a tree of explanations abductively (e.g. X is true, because ...) and recursively, then frames the inference as a satisfiability problem over these explanations and their logical relations. We test Maieutic Prompting for true/false QA on three challenging benchmarks that require complex commonsense reasoning. Maieutic Prompting achieves up to 20\% better accuracy than state-of-the-art prompting methods, and as a fully unsupervised approach, performs competitively with supervised models. We also show that Maieutic Prompting improves robustness in inference while providing interpretable rationales.},
  file = {C:\Users\zahdehv\Zotero\storage\MYWWDH32\Jung et al. - 2022 - Maieutic Prompting Logically Consistent Reasoning with Recursive Explanations.pdf}
}

@misc{karpasMRKLSystemsModular2022,
  title = {{{MRKL Systems}}: {{A}} Modular, Neuro-Symbolic Architecture That Combines Large Language Models, External Knowledge Sources and Discrete Reasoning},
  shorttitle = {{{MRKL Systems}}},
  author = {Karpas, Ehud and Abend, Omri and Belinkov, Yonatan and Lenz, Barak and Lieber, Opher and Ratner, Nir and Shoham, Yoav and Bata, Hofit and Levine, Yoav and {Leyton-Brown}, Kevin and Muhlgay, Dor and Rozen, Noam and Schwartz, Erez and Shachaf, Gal and {Shalev-Shwartz}, Shai and Shashua, Amnon and Tenenholtz, Moshe},
  year = {2022},
  month = may,
  number = {arXiv:2205.00445},
  eprint = {2205.00445},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2205.00445},
  urldate = {2025-05-01},
  abstract = {Huge language models (LMs) have ushered in a new era for AI, serving as a gateway to natural-language-based knowledge tasks. Although an essential element of modern AI, LMs are also inherently limited in a number of ways. We discuss these limitations and how they can be avoided by adopting a systems approach. Conceptualizing the challenge as one that involves knowledge and reasoning in addition to linguistic processing, we define a flexible architecture with multiple neural models, complemented by discrete knowledge and reasoning modules. We describe this neuro-symbolic architecture, dubbed the Modular Reasoning, Knowledge and Language (MRKL, pronounced "miracle") system, some of the technical challenges in implementing it, and Jurassic-X, AI21 Labs' MRKL system implementation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\HB58GB8B\\Karpas et al. - 2022 - MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external k.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\JEZYEM45\\2205.html}
}

@misc{keraghelRecentAdvancesNamed2024,
  title = {Recent {{Advances}} in {{Named Entity Recognition}}: {{A Comprehensive Survey}} and {{Comparative Study}}},
  shorttitle = {Recent {{Advances}} in {{Named Entity Recognition}}},
  author = {Keraghel, Imed and Morbieu, Stanislas and Nadif, Mohamed},
  year = {2024},
  month = dec,
  number = {arXiv:2401.10825},
  eprint = {2401.10825},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.10825},
  urldate = {2025-05-14},
  abstract = {Named Entity Recognition seeks to extract substrings within a text that name real-world objects and to determine their type (for example, whether they refer to persons or organizations). In this survey, we first present an overview of recent popular approaches, including advancements in Transformer-based methods and Large Language Models (LLMs) that have not had much coverage in other surveys. In addition, we discuss reinforcement learning and graph-based approaches, highlighting their role in enhancing NER performance. Second, we focus on methods designed for datasets with scarce annotations. Third, we evaluate the performance of the main NER implementations on a variety of datasets with differing characteristics (as regards their domain, their size, and their number of classes). We thus provide a deep comparison of algorithms that have never been considered together. Our experiments shed some light on how the characteristics of datasets affect the behavior of the methods we compare.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\EGWNH3VT\\Keraghel et al. - 2024 - Recent Advances in Named Entity Recognition A Comprehensive Survey and Comparative Study.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\YPSPLM5Y\\2401.html}
}

@article{KnowledgeWorker2025,
  title = {Knowledge Worker},
  year = {2025},
  month = mar,
  journal = {Wikipedia},
  urldate = {2025-05-08},
  abstract = {Knowledge workers are workers whose main capital is knowledge. Examples include ICT professionals, physicians, pharmacists, architects, engineers, scientists, design thinkers, public accountants, lawyers, librarians, archivists, editors, and academics, whose job is to "think for a living".},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1282971341},
  file = {C:\Users\zahdehv\Zotero\storage\LEKCYB72\Knowledge_worker.html}
}

@misc{kojimaLargeLanguageModels2023,
  title = {Large {{Language Models}} Are {{Zero-Shot Reasoners}}},
  author = {Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  year = {2023},
  month = jan,
  number = {arXiv:2205.11916},
  eprint = {2205.11916},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2205.11916},
  urldate = {2025-05-02},
  abstract = {Pretrained large language models (LLMs) are widely used in many sub-fields of natural language processing (NLP) and generally known as excellent few-shot learners with task-specific exemplars. Notably, chain of thought (CoT) prompting, a recent technique for eliciting complex multi-step reasoning through step-by-step answer examples, achieved the state-of-the-art performances in arithmetics and symbolic reasoning, difficult system-2 tasks that do not follow the standard scaling laws for LLMs. While these successes are often attributed to LLMs' ability for few-shot learning, we show that LLMs are decent zero-shot reasoners by simply adding "Let's think step by step" before each answer. Experimental results demonstrate that our Zero-shot-CoT, using the same single prompt template, significantly outperforms zero-shot LLM performances on diverse benchmark reasoning tasks including arithmetics (MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin Flip), and other logical reasoning tasks (Date Understanding, Tracking Shuffled Objects), without any hand-crafted few-shot examples, e.g. increasing the accuracy on MultiArith from 17.7\% to 78.7\% and GSM8K from 10.4\% to 40.7\% with large InstructGPT model (text-davinci-002), as well as similar magnitudes of improvements with another off-the-shelf large model, 540B parameter PaLM. The versatility of this single prompt across very diverse reasoning tasks hints at untapped and understudied fundamental zero-shot capabilities of LLMs, suggesting high-level, multi-task broad cognitive capabilities may be extracted by simple prompting. We hope our work not only serves as the minimal strongest zero-shot baseline for the challenging reasoning benchmarks, but also highlights the importance of carefully exploring and analyzing the enormous zero-shot knowledge hidden inside LLMs before crafting finetuning datasets or few-shot exemplars.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\VHKC25TU\\Kojima et al. - 2023 - Large Language Models are Zero-Shot Reasoners.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\V6ANAGHX\\2205.html}
}

@misc{kommineniHumanExpertsMachines2024,
  title = {From Human Experts to Machines: {{An LLM}} Supported Approach to Ontology and Knowledge Graph Construction},
  shorttitle = {From Human Experts to Machines},
  author = {Kommineni, Vamsi Krishna and {K{\"o}nig-Ries}, Birgitta and Samuel, Sheeba},
  year = {2024},
  month = mar,
  number = {arXiv:2403.08345},
  eprint = {2403.08345},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.08345},
  urldate = {2025-05-15},
  abstract = {The conventional process of building Ontologies and Knowledge Graphs (KGs) heavily relies on human domain experts to define entities and relationship types, establish hierarchies, maintain relevance to the domain, fill the ABox (or populate with instances), and ensure data quality (including amongst others accuracy and completeness). On the other hand, Large Language Models (LLMs) have recently gained popularity for their ability to understand and generate human-like natural language, offering promising ways to automate aspects of this process. This work explores the (semi-)automatic construction of KGs facilitated by open-source LLMs. Our pipeline involves formulating competency questions (CQs), developing an ontology (TBox) based on these CQs, constructing KGs using the developed ontology, and evaluating the resultant KG with minimal to no involvement of human experts. We showcase the feasibility of our semi-automated pipeline by creating a KG on deep learning methodologies by exploiting scholarly publications. To evaluate the answers generated via Retrieval-Augmented-Generation (RAG) as well as the KG concepts automatically extracted using LLMs, we design a judge LLM, which rates the generated content based on ground truth. Our findings suggest that employing LLMs could potentially reduce the human effort involved in the construction of KGs, although a human-in-the-loop approach is recommended to evaluate automatically generated KGs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\ASPPNVND\\Kommineni et al. - 2024 - From human experts to machines An LLM supported approach to ontology and knowledge graph constructi.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\H7E2E43E\\2403.html}
}

@misc{kongBetterZeroShotReasoning2024,
  title = {Better {{Zero-Shot Reasoning}} with {{Role-Play Prompting}}},
  author = {Kong, Aobo and Zhao, Shiwan and Chen, Hao and Li, Qicheng and Qin, Yong and Sun, Ruiqi and Zhou, Xin and Wang, Enzhi and Dong, Xiaohang},
  year = {2024},
  month = mar,
  number = {arXiv:2308.07702},
  eprint = {2308.07702},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2308.07702},
  urldate = {2025-05-06},
  abstract = {Modern large language models (LLMs) exhibit a remarkable capacity for role-playing, enabling them to embody not only human characters but also non-human entities. This versatility allows them to simulate complex human-like interactions and behaviors within various contexts, as well as to emulate specific objects or systems. While these capabilities have enhanced user engagement and introduced novel modes of interaction, the influence of role-playing on LLMs' reasoning abilities remains underexplored. In this study, we introduce a strategically designed role-play prompting methodology and assess its performance under the zero-shot setting across twelve diverse reasoning benchmarks. Our empirical results illustrate that role-play prompting consistently surpasses the standard zero-shot approach across most datasets. Notably, in experiments conducted using ChatGPT, accuracy on AQuA rises from 53.5\% to 63.8\%, and on Last Letter from 23.8\% to 84.2\%.Upon further comparison with the Zero-Shot-CoT technique, which prompts the model to "think step by step", our study demonstrates that role-play prompting acts as a more effective trigger for the CoT process. This highlights its potential to augment the reasoning capabilities of LLMs. We release our code at https://github.com/NKU-HLT/Role-Play-Prompting.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\XTF86G6Y\\Kong et al. - 2024 - Better Zero-Shot Reasoning with Role-Play Prompting.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\TZWTG54Q\\2308.html}
}

@misc{lewisRetrievalAugmentedGenerationKnowledgeIntensive2021,
  title = {Retrieval-{{Augmented Generation}} for {{Knowledge-Intensive NLP Tasks}}},
  author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
  year = {2021},
  month = apr,
  number = {arXiv:2005.11401},
  eprint = {2005.11401},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2005.11401},
  urldate = {2025-04-19},
  abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\CG4RUVEQ\\Lewis et al. - 2021 - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\KDMKQVR9\\2005.html}
}

@misc{liAutomatedClinicalData2024,
  title = {Automated {{Clinical Data Extraction}} with {{Knowledge Conditioned LLMs}}},
  author = {Li, Diya and Kadav, Asim and Gao, Aijing and Li, Rui and Bourgon, Richard},
  year = {2024},
  month = nov,
  number = {arXiv:2406.18027},
  eprint = {2406.18027},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.18027},
  urldate = {2025-05-15},
  abstract = {The extraction of lung lesion information from clinical and medical imaging reports is crucial for research on and clinical care of lung-related diseases. Large language models (LLMs) can be effective at interpreting unstructured text in reports, but they often hallucinate due to a lack of domain-specific knowledge, leading to reduced accuracy and posing challenges for use in clinical settings. To address this, we propose a novel framework that aligns generated internal knowledge with external knowledge through in-context learning (ICL). Our framework employs a retriever to identify relevant units of internal or external knowledge and a grader to evaluate the truthfulness and helpfulness of the retrieved internal-knowledge rules, to align and update the knowledge bases. Experiments with expert-curated test datasets demonstrate that this ICL approach can increase the F1 score for key fields (lesion size, margin and solidity) by an average of 12.9\% over existing ICL methods.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\VKFBIQIS\\Li et al. - 2024 - Automated Clinical Data Extraction with Knowledge Conditioned LLMs.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\VPXBIMQT\\2406.html}
}

@misc{liCondensedTransitionGraph2024,
  title = {A {{Condensed Transition Graph Framework}} for {{Zero-shot Link Prediction}} with {{Large Language Models}}},
  author = {Li, Mingchen and Ling, Chen and Zhang, Rui and Zhao, Liang},
  year = {2024},
  month = nov,
  number = {arXiv:2402.10779},
  eprint = {2402.10779},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.10779},
  urldate = {2025-05-15},
  abstract = {Zero-shot link prediction (ZSLP) on knowledge graphs aims at automatically identifying relations between given entities. Existing methods primarily employ auxiliary information to predict tail entity given head entity and its relation, yet face challenges due to the occasional unavailability of such detailed information and the inherent simplicity of predicting tail entities based on semantic similarities. Even though Large Language Models (LLMs) offer a promising solution to predict unobserved relations between the head and tail entity in a zero-shot manner, their performance is still restricted due to the inability to leverage all the (exponentially many) paths' information between two entities, which are critical in collectively indicating their relation types. To address this, in this work, we introduce a Condensed Transition Graph Framework for Zero-Shot Link Prediction (CTLP), which encodes all the paths' information in linear time complexity to predict unseen relations between entities, attaining both efficiency and information preservation. Specifically, we design a condensed transition graph encoder with theoretical guarantees on its coverage, expressiveness, and efficiency. It is learned by a transition graph contrastive learning strategy. Subsequently, we design a soft instruction tuning to learn and map the all-path embedding to the input of LLMs. Experimental results show that our proposed CTLP method achieves state-of-the-art performance on three standard ZSLP datasets},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\MU9XFMV2\\Li et al. - 2024 - A Condensed Transition Graph Framework for Zero-shot Link Prediction with Large Language Models.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\9WAS4WZM\\2402.html}
}

@misc{liKnowCoderCodingStructured2024,
  title = {{{KnowCoder}}: {{Coding Structured Knowledge}} into {{LLMs}} for {{Universal Information Extraction}}},
  shorttitle = {{{KnowCoder}}},
  author = {Li, Zixuan and Zeng, Yutao and Zuo, Yuxin and Ren, Weicheng and Liu, Wenxuan and Su, Miao and Guo, Yucan and Liu, Yantao and Li, Xiang and Hu, Zhilei and Bai, Long and Li, Wei and Liu, Yidan and Yang, Pan and Jin, Xiaolong and Guo, Jiafeng and Cheng, Xueqi},
  year = {2024},
  month = mar,
  number = {arXiv:2403.07969},
  eprint = {2403.07969},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.07969},
  urldate = {2025-05-15},
  abstract = {In this paper, we propose KnowCoder, a Large Language Model (LLM) to conduct Universal Information Extraction (UIE) via code generation. KnowCoder aims to develop a kind of unified schema representation that LLMs can easily understand and an effective learning framework that encourages LLMs to follow schemas and extract structured knowledge accurately. To achieve these, KnowCoder introduces a code-style schema representation method to uniformly transform different schemas into Python classes, with which complex schema information, such as constraints among tasks in UIE, can be captured in an LLM-friendly manner. We further construct a code-style schema library covering over \${\textbackslash}textbf\{30,000\}\$ types of knowledge, which is the largest one for UIE, to the best of our knowledge. To ease the learning process of LLMs, KnowCoder contains a two-phase learning framework that enhances its schema understanding ability via code pretraining and its schema following ability via instruction tuning. After code pretraining on around \$1.5\$B automatically constructed data, KnowCoder already attains remarkable generalization ability and achieves relative improvements by \${\textbackslash}textbf\{49.8\%\}\$ F1, compared to LLaMA2, under the few-shot setting. After instruction tuning, KnowCoder further exhibits strong generalization ability on unseen schemas and achieves up to \${\textbackslash}textbf\{12.5\%\}\$ and \${\textbackslash}textbf\{21.9\%\}\$, compared to sota baselines, under the zero-shot setting and the low resource setting, respectively. Additionally, based on our unified schema representations, various human-annotated datasets can simultaneously be utilized to refine KnowCoder, which achieves significant improvements up to \${\textbackslash}textbf\{7.5\%\}\$ under the supervised setting.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\YC44FFL3\\Li et al. - 2024 - KnowCoder Coding Structured Knowledge into LLMs for Universal Information Extraction.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\3SAKNV97\\2403.html}
}

@misc{lingImprovingOpenInformation2023,
  title = {Improving {{Open Information Extraction}} with {{Large Language Models}}: {{A Study}} on {{Demonstration Uncertainty}}},
  shorttitle = {Improving {{Open Information Extraction}} with {{Large Language Models}}},
  author = {Ling, Chen and Zhao, Xujiang and Zhang, Xuchao and Liu, Yanchi and Cheng, Wei and Wang, Haoyu and Chen, Zhengzhang and Osaki, Takao and Matsuda, Katsushi and Chen, Haifeng and Zhao, Liang},
  year = {2023},
  month = sep,
  number = {arXiv:2309.03433},
  eprint = {2309.03433},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.03433},
  urldate = {2025-05-15},
  abstract = {Open Information Extraction (OIE) task aims at extracting structured facts from unstructured text, typically in the form of (subject, relation, object) triples. Despite the potential of large language models (LLMs) like ChatGPT as a general task solver, they lag behind state-of-the-art (supervised) methods in OIE tasks due to two key issues. First, LLMs struggle to distinguish irrelevant context from relevant relations and generate structured output due to the restrictions on fine-tuning the model. Second, LLMs generates responses autoregressively based on probability, which makes the predicted relations lack confidence. In this paper, we assess the capabilities of LLMs in improving the OIE task. Particularly, we propose various in-context learning strategies to enhance LLM's instruction-following ability and a demonstration uncertainty quantification module to enhance the confidence of the generated relations. Our experiments on three OIE benchmark datasets show that our approach holds its own against established supervised methods, both quantitatively and qualitatively.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\SHR7PX7N\\Ling et al. - 2023 - Improving Open Information Extraction with Large Language Models A Study on Demonstration Uncertain.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\YL5SCBR2\\2309.html}
}

@misc{liSearcho1AgenticSearchEnhanced2025,
  title = {Search-O1: {{Agentic Search-Enhanced Large Reasoning Models}}},
  shorttitle = {Search-O1},
  author = {Li, Xiaoxi and Dong, Guanting and Jin, Jiajie and Zhang, Yuyao and Zhou, Yujia and Zhu, Yutao and Zhang, Peitian and Dou, Zhicheng},
  year = {2025},
  month = jan,
  number = {arXiv:2501.05366},
  eprint = {2501.05366},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.05366},
  urldate = {2025-02-28},
  abstract = {Large reasoning models (LRMs) like OpenAI-o1 have demonstrated impressive long stepwise reasoning capabilities through large-scale reinforcement learning. However, their extended reasoning processes often suffer from knowledge insufficiency, leading to frequent uncertainties and potential errors. To address this limitation, we introduce Search-o1, a framework that enhances LRMs with an agentic retrieval-augmented generation (RAG) mechanism and a Reason-inDocuments module for refining retrieved documents. Search-o1 integrates an agentic search workflow into the reasoning process, enabling dynamic retrieval of external knowledge when LRMs encounter uncertain knowledge points. Additionally, due to the verbose nature of retrieved documents, we design a separate Reason-in-Documents module to deeply analyze the retrieved information before injecting it into the reasoning chain, minimizing noise and preserving coherent reasoning flow. Extensive experiments on complex reasoning tasks in science, mathematics, and coding, as well as six open-domain QA benchmarks, demonstrate the strong performance of Search-o1. This approach enhances the trustworthiness and applicability of LRMs in complex reasoning tasks, paving the way for more reliable and versatile intelligent systems. The code is available at https://github.com/sunnynexus/Search-o1.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval},
  file = {C:\Users\zahdehv\Zotero\storage\CVFSSQBF\Li et al. - 2025 - Search-o1 Agentic Search-Enhanced Large Reasoning Models.pdf}
}

@article{liuLostMiddleHow2024,
  title = {Lost in the {{Middle}}: {{How Language Models Use Long Contexts}}},
  author = {Liu, Nelson F and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  year = {2024},
  abstract = {While recent language models have the ability to take long contexts as input, relatively little is known about how well they use longer context. We analyze the performance of language models on two tasks that require identifying relevant information in their input contexts: multi-document question answering and key-value retrieval. We find that performance can degrade significantly when changing the position of relevant information, indicating that current language models do not robustly make use of information in long input contexts. In particular, we observe that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context language models.},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\MC6N5GC9\Liu et al. - Lost in the Middle How Language Models Use Long Contexts.pdf}
}

@misc{LLMsKnowledgeGraph,
  title = {{{LLMs}} for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities {\textbar} {{World Wide Web}}},
  urldate = {2025-05-15},
  howpublished = {https://link.springer.com/article/10.1007/s11280-024-01297-w},
  file = {C:\Users\zahdehv\Zotero\storage\IXW2WANL\s11280-024-01297-w.html}
}

@misc{longLargeLanguageModel2023,
  title = {Large {{Language Model Guided Tree-of-Thought}}},
  author = {Long, Jieyi},
  year = {2023},
  month = may,
  number = {arXiv:2305.08291},
  eprint = {2305.08291},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.08291},
  urldate = {2025-02-28},
  abstract = {In this paper, we introduce the Tree-of-Thought (ToT) framework, a novel approach aimed at improving the problem-solving capabilities of auto-regressive large language models (LLMs). The ToT technique is inspired by the human mind's approach for solving complex reasoning tasks through trial and error. In this process, the human mind explores the solution space through a tree-like thought process, allowing for backtracking when necessary. To implement ToT as a software system, we augment an LLM with additional modules including a prompter agent, a checker module, a memory module, and a ToT controller. In order to solve a given problem, these modules engage in a multi-round conversation with the LLM. The memory module records the conversation and state history of the problem solving process, which allows the system to backtrack to the previous steps of the thought-process and explore other directions from there. To verify the effectiveness of the proposed technique, we implemented a ToT-based solver for the Sudoku Puzzle. Experimental results show that the ToT framework can significantly increase the success rate of Sudoku puzzle solving. Our implementation of the ToT-based Sudoku solver is available on GitHub: https://github.com/jieyilong/tree-of-thought-puzzle-solver.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {C:\Users\zahdehv\Zotero\storage\VICY279N\Long - 2023 - Large Language Model Guided Tree-of-Thought.pdf}
}

@misc{lotfiVisualScratchpadsEnabling2024,
  title = {Visual {{Scratchpads}}: {{Enabling Global Reasoning}} in {{Vision}}},
  shorttitle = {Visual {{Scratchpads}}},
  author = {Lotfi, Aryo and Fini, Enrico and Bengio, Samy and Nabi, Moin and Abbe, Emmanuel},
  year = {2024},
  month = oct,
  number = {arXiv:2410.08165},
  eprint = {2410.08165},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.08165},
  urldate = {2025-04-04},
  abstract = {Modern vision models have achieved remarkable success in benchmarks where local features provide critical information about the target. There is now a growing interest in solving tasks that require more global reasoning, where local features offer no significant information. These tasks are reminiscent of the connectivity tasks discussed by Minsky and Papert in 1969, which exposed the limitations of the perceptron model and contributed to the first AI winter. In this paper, we revisit such tasks by introducing four global visual benchmarks involving path findings and mazes. We show that: (1) although today's large vision models largely surpass the expressivity limitations of the early models, they still struggle with the learning efficiency; we put forward the "globality degree" notion to understand this limitation; (2) we then demonstrate that the picture changes and global reasoning becomes feasible with the introduction of "visual scratchpads"; similarly to the text scratchpads and chain-of-thoughts used in language models, visual scratchpads help break down global tasks into simpler ones; (3) we finally show that some scratchpads are better than others, in particular, "inductive scratchpads" that take steps relying on less information afford better out-of-distribution generalization and succeed for smaller model sizes.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\Z7BDZKHU\\Lotfi et al. - 2024 - Visual Scratchpads Enabling Global Reasoning in Vision.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\LPRDLHSE\\2410.html}
}

@misc{luBoundingCapabilitiesLarge2023,
  title = {Bounding the {{Capabilities}} of {{Large Language Models}} in {{Open Text Generation}} with {{Prompt Constraints}}},
  author = {Lu, Albert and Zhang, Hongxin and Zhang, Yanzhe and Wang, Xuezhi and Yang, Diyi},
  year = {2023},
  month = feb,
  number = {arXiv:2302.09185},
  eprint = {2302.09185},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2302.09185},
  urldate = {2025-05-06},
  abstract = {The limits of open-ended generative models are unclear, yet increasingly important. What causes them to succeed and what causes them to fail? In this paper, we take a prompt-centric approach to analyzing and bounding the abilities of open-ended generative models. We present a generic methodology of analysis with two challenging prompt constraint types: structural and stylistic. These constraint types are categorized into a set of well-defined constraints that are analyzable by a single prompt. We then systematically create a diverse set of simple, natural, and useful prompts to robustly analyze each individual constraint. Using the GPT-3 text-davinci-002 model as a case study, we generate outputs from our collection of prompts and analyze the model's generative failures. We also show the generalizability of our proposed method on other large models like BLOOM and OPT. Our results and our in-context mitigation strategies reveal open challenges for future research. We have publicly released our code at https://github.com/SALT-NLP/Bound-Cap-LLM.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\ZH2R5SZ3\\Lu et al. - 2023 - Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\59R6ATLA\\2302.html}
}

@misc{luoOneKEDockerizedSchemaGuided2025,
  title = {{{OneKE}}: {{A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction System}}},
  shorttitle = {{{OneKE}}},
  author = {Luo, Yujie and Ru, Xiangyuan and Liu, Kangwei and Yuan, Lin and Sun, Mengshu and Zhang, Ningyu and Liang, Lei and Zhang, Zhiqiang and Zhou, Jun and Wei, Lanning and Zheng, Da and Wang, Haofen and Chen, Huajun},
  year = {2025},
  month = feb,
  number = {arXiv:2412.20005},
  eprint = {2412.20005},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.20005},
  urldate = {2025-05-15},
  abstract = {We introduce OneKE, a dockerized schema-guided knowledge extraction system, which can extract knowledge from the Web and raw PDF Books, and support various domains (science, news, etc.). Specifically, we design OneKE with multiple agents and a configure knowledge base. Different agents perform their respective roles, enabling support for various extraction scenarios. The configure knowledge base facilitates schema configuration, error case debugging and correction, further improving the performance. Empirical evaluations on benchmark datasets demonstrate OneKE's efficacy, while case studies further elucidate its adaptability to diverse tasks across multiple domains, highlighting its potential for broad applications. We have open-sourced the Code at https://github.com/zjunlp/OneKE and released a Video at http://oneke.openkg.cn/demo.mp4.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Databases,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\WWUPS34P\\Luo et al. - 2025 - OneKE A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction System.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\I9XEBWIB\\2412.html}
}

@misc{lyuFaithfulChainofThoughtReasoning2023,
  title = {Faithful {{Chain-of-Thought Reasoning}}},
  author = {Lyu, Qing and Havaldar, Shreya and Stein, Adam and Zhang, Li and Rao, Delip and Wong, Eric and Apidianaki, Marianna and {Callison-Burch}, Chris},
  year = {2023},
  month = sep,
  number = {arXiv:2301.13379},
  eprint = {2301.13379},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2301.13379},
  urldate = {2025-02-28},
  abstract = {While Chain-of-Thought (CoT) prompting boosts Language Models' (LM) performance on a gamut of complex reasoning tasks, the generated reasoning chain does not necessarily reflect how the model arrives at the answer (aka. faithfulness). We propose Faithful CoT, a reasoning framework involving two stages: Translation (Natural Language query \${\textbackslash}rightarrow\$ symbolic reasoning chain) and Problem Solving (reasoning chain \${\textbackslash}rightarrow\$ answer), using an LM and a deterministic solver respectively. This guarantees that the reasoning chain provides a faithful explanation of the final answer. Aside from interpretability, Faithful CoT also improves empirical performance: it outperforms standard CoT on 9 of 10 benchmarks from 4 diverse domains, with a relative accuracy gain of 6.3\% on Math Word Problems (MWP), 3.4\% on Planning, 5.5\% on Multi-hop Question Answering (QA), and 21.4\% on Relational Inference. Furthermore, with GPT-4 and Codex, it sets the new state-of-the-art few-shot performance on 7 datasets (with 95.0+ accuracy on 6 of them), showing a strong synergy between faithfulness and accuracy.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {C:\Users\zahdehv\Zotero\storage\SDT2CES7\Lyu et al. - 2023 - Faithful Chain-of-Thought Reasoning.pdf}
}

@article{machadoLLMStoreLeveraging2024,
  title = {\{\vphantom\}{{LLM Store}}\vphantom\{\}: {{Leveraging Large Language Models}} as {{Sources}} of \{\vphantom\}{{Wikidata}}\vphantom\{\}-{{Structured Knowledge}}},
  author = {Machado, Marcelo and Rodrigues, Jo{\~a}o M B and Lima, Guilherme and Fiorini, Sandro Rama},
  year = {2024},
  abstract = {Knowledge Integration Framework (KIF) is a Wikidata-based framework for integrating heterogeneous knowledge sources. These can be SPARQL endpoints, SQL endpoints, RDF files, CSV files, etc., and are represented in KIF as knowledge ``stores''. A KIF store exposes a Wikidata view of the underlying knowledge source by interpreting its content as a set of Wikidata-like statements and allowing it to be queried through a simple but expressive pattern-matching interface. In this paper, we present LLM Store, a KIF store implementation that uses language models (LLMs) as knowledge sources. Instead of consulting a static knowledge base, when queried, the LLM Store uses the underlying LLM to synthesize Wikidata-like statements on-the-fly. The knowledge completion pipeline used by LLM Store can be fully customized and supports strategies that range from simple zero-shot prompts to retrieval-augment generation (RAG). This paper discusses the design and implementation of LLM Store and presents an evaluation using the test and validation datasets of LM-KBC Challenge @ ISWC 2024. We analyze the results of the evaluation in light of the results obtained by our submission to the same challenge, which was based on LLM Store and achieved a macro averaged F1-score of 91\%. LLM Store is released as open-source and its code is available at https://github.com/IBM/kif-llm-store.},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\56QCB6DV\Machado et al. - LLM Store Leveraging Large Language Models as Sources of Wikidata -Structured Knowledge.pdf}
}

@misc{madaanSelfRefineIterativeRefinement2023,
  title = {Self-{{Refine}}: {{Iterative Refinement}} with {{Self-Feedback}}},
  shorttitle = {Self-{{Refine}}},
  author = {Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and Gupta, Shashank and Majumder, Bodhisattwa Prasad and Hermann, Katherine and Welleck, Sean and Yazdanbakhsh, Amir and Clark, Peter},
  year = {2023},
  month = may,
  number = {arXiv:2303.17651},
  eprint = {2303.17651},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2303.17651},
  urldate = {2025-05-01},
  abstract = {Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. Across all evaluated tasks, outputs generated with Self-Refine are preferred by humans and automatic metrics over those generated with the same LLM using conventional one-step generation, improving by {\textasciitilde}20\% absolute on average in task performance. Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using our simple, standalone approach.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\4Z67JCMG\\Madaan et al. - 2023 - Self-Refine Iterative Refinement with Self-Feedback.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\5X3LCKDX\\2303.html}
}

@article{makanyOptimisingUseNotetaking2009,
  title = {Optimising the Use of Note-taking as an External Cognitive Aid for Increasing Learning},
  author = {Makany, Tamas and Kemp, Jonathan and Dror, Itiel E.},
  year = {2009},
  month = jul,
  journal = {British Journal of Educational Technology},
  volume = {40},
  number = {4},
  pages = {619--635},
  issn = {0007-1013, 1467-8535},
  doi = {10.1111/j.1467-8535.2008.00906.x},
  urldate = {2025-05-08},
  abstract = {Taking notes is of uttermost importance in academic and commercial use and success. Different techniques for note-taking utilise different cognitive processes and strategies. This experimental study examined ways to enhance cognitive performance via different note-taking techniques. By comparing performances of traditional, linear style note-taking with alternative nonlinear technique, we aimed to examine the efficiency and importance of different ways of taking notes. Twenty-six volunteer adult learners from an information management course participated in this study. Cognitive performance scores from a traditional linear note-taking group were compared with another group by using a commercially available non-linear note-taking technique. Both groups were tested in two settings: after a classroom lecture and a panel forum discussion. Tasks included measures on story comprehension, memory, complexity of mental representations and metacognitive skills. Data analysis revealed that the non-linear note-takers were significantly better than the linear group both in terms of the quantity and the quality of the learned material. This study demonstrates the importance of using cognitively compatible note-taking techniques. It identifies the cognitive mechanisms behind effective note-taking and knowledge representation. Using such techniques enables deeper understanding and more integrated knowledge management.},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\KYQKGEJ2\Makany et al. - 2009 - Optimising the use of note‐taking as an external cognitive aid for increasing learning.pdf}
}

@article{martinez-rodriguezMiningInformationSentences2022,
  title = {Mining Information from Sentences through {{Semantic Web}} Data and {{Information Extraction}} Tasks},
  author = {{Martinez-Rodriguez}, Jose L. and {Lopez-Arevalo}, Ivan and {Rios-Alvarado}, Ana B.},
  year = {2022},
  month = feb,
  journal = {Journal of Information Science},
  volume = {48},
  number = {1},
  pages = {3--20},
  issn = {0165-5515, 1741-6485},
  doi = {10.1177/0165551520934387},
  urldate = {2025-05-15},
  abstract = {The Semantic Web provides guidelines for the representation of information about real-world objects (entities) and their relations (properties). This is helpful for the dissemination and consumption of information by people and applications. However, the information is mainly contained within natural language sentences, which do not have a structure or linguistic descriptions ready to be directly processed by computers. Thus, the challenge is to identify and extract the elements of information that can be represented. Hence, this article presents a strategy to extract information from sentences and its representation with Semantic Web standards. Our strategy involves Information Extraction tasks and a hybrid semantic similarity measure to get entities and relations that are later associated with individuals and properties from a Knowledge Base to create RDF triples (Subject--Predicate--Object structures). The experiments demonstrate the feasibility of our method and that it outperforms the accuracy provided by a pattern-based method from the literature.},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\7PJX8YVA\Martinez-Rodriguez et al. - 2022 - Mining information from sentences through Semantic Web data and Information Extraction tasks.pdf}
}

@article{martinez-rodriguezOpenIEbasedApproachKnowledge2018,
  title = {{{OpenIE-based}} Approach for {{Knowledge Graph}} Construction from Text},
  author = {{Martinez-Rodriguez}, Jose L. and {Lopez-Arevalo}, Ivan and {Rios-Alvarado}, Ana B.},
  year = {2018},
  month = dec,
  journal = {Expert Systems with Applications},
  volume = {113},
  pages = {339--355},
  issn = {09574174},
  doi = {10.1016/j.eswa.2018.07.017},
  urldate = {2025-05-15},
  abstract = {Transforming unstructured text into a formal representation is an important goal of the Semantic Web in order to facilitate the integration and retrieval of information. The construction of Knowledge Graphs (KGs) pursues such an idea, where named entities (real world things) and their relations are extracted from text. In recent years, many approaches for the construction of KGs have been proposed by exploiting Discourse Analysis, Semantic Frames, or Machine Learning algorithms with existing Semantic Web data. Although such approaches are useful for processing taxonomies and connecting beliefs, they provide several linguistic descriptions, which lead to semantic data heterogeneity and thus, complicating data consumption. Moreover, Open Information Extraction (OpenIE) approaches have been slightly explored for the construction of KGs, which provide binary relations representing atomic units of information that could simplify the querying and representation of data. In this paper, we propose an approach to generate KGs using binary relations produced by an OpenIE approach. For such purpose, we present strategies for favoring the extraction and linking of named entities with KG individuals, and additionally, their association with grammatical units that lead to producing more coherent facts. We also provide decisions for selecting the extracted information elements for creating potentially useful RDF triples for the KG. Our results demonstrate that the integration of information extraction units with grammatical structures provides a better understanding of proposition-based representations provided by OpenIE for supporting the construction of KGs.},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\5HBCSCIU\Martinez-Rodriguez et al. - 2018 - OpenIE-based approach for Knowledge Graph construction from text.pdf}
}

@misc{mccuskerLOKELinkedOpen2023,
  title = {{{LOKE}}: {{Linked Open Knowledge Extraction}} for {{Automated Knowledge Graph Construction}}},
  shorttitle = {{{LOKE}}},
  author = {McCusker, Jamie},
  year = {2023},
  month = nov,
  number = {arXiv:2311.09366},
  eprint = {2311.09366},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.09366},
  urldate = {2025-04-18},
  abstract = {While the potential of Open Information Extraction (Open IE) for Knowledge Graph Construction (KGC) may seem promising, we find that the alignment of Open IE extraction results with existing knowledge graphs to be inadequate. The advent of Large Language Models (LLMs), especially the commercially available OpenAI models, have reset expectations for what is possible with deep learning models and have created a new field called prompt engineering. We investigate the use of GPT models and prompt engineering for knowledge graph construction with the Wikidata knowledge graph to address a similar problem to Open IE, which we call Open Knowledge Extraction (OKE) using an approach we call the Linked Open Knowledge Extractor (LOKE, pronounced like "Loki"). We consider the entity linking task essential to construction of real world knowledge graphs. We merge the CaRB benchmark scoring approach with data from the TekGen dataset for the LOKE task. We then show that a well engineered prompt, paired with a naive entity linking approach (which we call LOKE-GPT), outperforms AllenAI's OpenIE 4 implementation on the OKE task, although it over-generates triples compared to the reference set due to overall triple scarcity in the TekGen set. Through an analysis of entity linkability in the CaRB dataset, as well as outputs from OpenIE 4 and LOKE-GPT, we see that LOKE-GPT and the "silver" TekGen triples show that the task is significantly different in content from OIE, if not structure. Through this analysis and a qualitative analysis of sentence extractions via all methods, we found that LOKE-GPT extractions are of high utility for the KGC task and suitable for use in semi-automated extraction settings.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\GSCLP8TK\\McCusker - 2023 - LOKE Linked Open Knowledge Extraction for Automated Knowledge Graph Construction.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\G3BU8WIY\\2311.html}
}

@misc{MeetNewNotion,
  title = {Meet the New {{Notion AI}}},
  journal = {Notion},
  urldate = {2025-05-09},
  abstract = {One tool that does it all. Search, generate, analyze, and chat---right inside Notion.},
  howpublished = {https://www.notion.com/product/ai},
  langid = {american},
  file = {C:\Users\zahdehv\Zotero\storage\3LLJ3QKF\ai.html}
}

@misc{MemAINotes,
  title = {Mem -- {{The AI Notes App That Keeps You Organized}}},
  urldate = {2025-05-09},
  abstract = {The future of note taking. Designed to keep busy professionals organized with AI. Offline mode, iOS app, markdown editing, and GPT-4 built-in. Start building your second brain.},
  howpublished = {https://get.mem.ai/},
  langid = {american},
  file = {C:\Users\zahdehv\Zotero\storage\L72ZX2DU\get.mem.ai.html}
}

@article{Memex2025,
  title = {Memex},
  year = {2025},
  month = mar,
  journal = {Wikipedia},
  urldate = {2025-05-02},
  abstract = {A memex (from "memory expansion") is a hypothetical electromechanical device for interacting with microform documents and described in Vannevar Bush's 1945 article "As We May Think". Bush envisioned the memex as a device in which individuals would compress and store all of their books, records, and communications, "mechanized so that it may be consulted with exceeding speed and flexibility". The individual was supposed to use the memex as an automatic personal filing system, making the memex "an enlarged intimate supplement to his memory". The concept of the memex influenced the development of early hypertext systems, eventually leading to the creation of the World Wide Web, and personal knowledge base software. The hypothetical implementation depicted by Bush for the purpose of concrete illustration was based upon a document bookmark list of static microfilm pages and lacked a true hypertext system, where parts of pages would have internal structure beyond the common textual format.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1281526011},
  file = {C:\Users\zahdehv\Zotero\storage\227NSNX6\Memex.html}
}

@misc{metropolitanskyEffectiveExtractionEvaluation2025,
  title = {Towards {{Effective Extraction}} and {{Evaluation}} of {{Factual Claims}}},
  author = {Metropolitansky, Dasha and Larson, Jonathan},
  year = {2025},
  month = feb,
  number = {arXiv:2502.10855},
  eprint = {2502.10855},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2502.10855},
  urldate = {2025-03-28},
  abstract = {A common strategy for fact-checking long-form content generated by Large Language Models (LLMs) is extracting simple claims that can be verified independently. Since inaccurate or incomplete claims compromise fact-checking results, ensuring claim quality is critical. However, the lack of a standardized evaluation framework impedes assessment and comparison of claim extraction methods. To address this gap, we propose a framework for evaluating claim extraction in the context of fact-checking along with automated, scalable, and replicable methods for applying this framework, including novel approaches for measuring coverage and decontextualization. We also introduce Claimify, an LLM-based claim extraction method, and demonstrate that it outperforms existing methods under our evaluation framework. A key feature of Claimify is its ability to handle ambiguity and extract claims only when there is high confidence in the correct interpretation of the source text.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\UIZ8CI9C\\Metropolitansky and Larson - 2025 - Towards Effective Extraction and Evaluation of Factual Claims.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\8HRKURKH\\2502.html}
}

@article{millerMagicalNumberSeven1956,
  title = {The {{Magical Number Seven}}, {{Plus}} or {{Minus Two}}: {{Some Limits}} on Our {{Capacity}} for {{Processing Information}}[1]},
  author = {Miller, George A},
  year = {1956},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\G46UYFMY\Miller - The Magical Number Seven, Plus or Minus Two Some Limits on our Capacity for Processing Information[.pdf}
}

@inproceedings{minRethinkingRoleDemonstrations2022,
  title = {Rethinking the {{Role}} of {{Demonstrations}}: {{What Makes In-Context Learning Work}}?},
  shorttitle = {Rethinking the {{Role}} of {{Demonstrations}}},
  booktitle = {Proceedings of the 2022 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
  editor = {Goldberg, Yoav and Kozareva, Zornitsa and Zhang, Yue},
  year = {2022},
  month = dec,
  pages = {11048--11064},
  publisher = {Association for Computational Linguistics},
  address = {Abu Dhabi, United Arab Emirates},
  doi = {10.18653/v1/2022.emnlp-main.759},
  urldate = {2025-05-01},
  abstract = {Large language models (LMs) are able to in-context learn---perform a new task via inference alone by conditioning on a few input-label pairs (demonstrations) and making predictions for new inputs. However, there has been little understanding of how the model learns and which aspects of the demonstrations contribute to end task performance. In this paper, we show that ground truth demonstrations are in fact not required---randomly replacing labels in the demonstrations barely hurts performance on a range of classification and multi-choce tasks, consistently over 12 different models including GPT-3. Instead, we find that other aspects of the demonstrations are the key drivers of endtask performance, including the fact that they provide a few examples of (1) the label space, (2) the distribution of the input text, and (3) the overall format of the sequence. Together, our analysis provides a new way of understanding how and why in-context learning works, while opening up new questions about how much can be learned from large language models through inference alone.},
  file = {C:\Users\zahdehv\Zotero\storage\R682XKKR\Min et al. - 2022 - Rethinking the Role of Demonstrations What Makes In-Context Learning Work.pdf}
}

@inproceedings{mishraReframingInstructionalPrompts2022,
  title = {Reframing {{Instructional Prompts}} to {{GPTk}}`s {{Language}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{ACL}} 2022},
  author = {Mishra, Swaroop and Khashabi, Daniel and Baral, Chitta and Choi, Yejin and Hajishirzi, Hannaneh},
  editor = {Muresan, Smaranda and Nakov, Preslav and Villavicencio, Aline},
  year = {2022},
  month = may,
  pages = {589--612},
  publisher = {Association for Computational Linguistics},
  address = {Dublin, Ireland},
  doi = {10.18653/v1/2022.findings-acl.50},
  urldate = {2025-05-01},
  abstract = {What kinds of instructional prompts are easier to follow for Language Models (LMs)? We study this question by conducting extensive empirical analysis that shed light on important features of successful instructional prompts. Specifically, we study several classes of reframing techniques for manual reformulation of prompts into more effective ones. Some examples include decomposing a complex task instruction into multiple simpler tasks or itemizing instructions into sequential steps. Our experiments compare the zero-shot and few-shot performance of LMs prompted with reframed instructions on 12 NLP tasks across 6 categories. Compared with original instructions, our reframed instructions lead to significant improvements across LMs with different sizes. For example, the same reframed prompts boost few-shot performance of GPT3-series and GPT2-series by 12.5\% and 6.7\% respectively averaged over all tasks. Furthermore, reframed instructions reduce the number of examples required to prompt LMs in the few-shot setting. We hope these empirically-driven techniques will pave the way towards more effective future prompting algorithms.},
  file = {C:\Users\zahdehv\Zotero\storage\T29UEPG8\Mishra et al. - 2022 - Reframing Instructional Prompts to GPTk`s Language.pdf}
}

@misc{nelsonNeedleHaystackMemory2024,
  title = {Needle in the {{Haystack}} for {{Memory Based Large Language Models}}},
  author = {Nelson, Elliot and Kollias, Georgios and Das, Payel and Chaudhury, Subhajit and Dan, Soham},
  year = {2024},
  month = jul,
  number = {arXiv:2407.01437},
  eprint = {2407.01437},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.01437},
  urldate = {2025-06-13},
  abstract = {Current large language models (LLMs) often perform poorly on simple fact retrieval tasks. Here we investigate if coupling a dynamically adaptable external memory to a LLM can alleviate this problem. For this purpose, we test Larimar, a recently proposed language model architecture which uses an external associative memory, on long-context recall tasks including passkey and needle-in-the-haystack tests. We demonstrate that the external memory of Larimar, which allows fast write and read of an episode of text samples, can be used at test time to handle contexts much longer than those seen during training. We further show that the latent readouts from the memory (to which long contexts are written) control the decoder towards generating correct outputs, with the memory stored off of the GPU. Compared to existing transformer-based LLM architectures for long-context recall tasks that use larger parameter counts or modified attention mechanisms, a relatively smaller size Larimar is able to maintain strong performance without any task-specific training or training on longer contexts.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\JJ5JRURI\\Nelson et al. - 2024 - Needle in the Haystack for Memory Based Large Language Models.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\GXXIYRUY\\2407.html}
}

@article{Notetaking2025,
  title = {Note-Taking},
  year = {2025},
  month = apr,
  journal = {Wikipedia},
  urldate = {2025-05-02},
  abstract = {Note-taking (sometimes written as notetaking or note taking) is the practice of recording information from different sources and platforms. By taking notes, the writer records the essence of the information, freeing their mind from having to recall everything. Notes are commonly drawn from a transient source, such as an oral discussion at a meeting, or a lecture (notes of a meeting are usually called minutes), in which case the notes may be the only record of the event. Since the advent of writing and literacy, notes traditionally were almost always handwritten (often in notebooks), but the introduction of notetaking software has made digital notetaking possible and widespread. Note-taking is a foundational skill in personal knowledge management.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1284010580},
  file = {C:\Users\zahdehv\Zotero\storage\K5HDE4SU\Note-taking.html}
}

@article{Notion2025,
  title = {{Notion}},
  year = {2025},
  month = may,
  journal = {Wikipedia, la enciclopedia libre},
  urldate = {2025-05-08},
  abstract = {Notion es un software de gesti{\'o}n de proyectos y para tomar notas. Est{\'a} dise{\~n}ado para ayudar a los miembros de una empresa u organizaci{\'o}n a corto plazo, objetivos y tareas en {\'a}reas de la eficiencia y la productividad. A la fecha de marzo de 2023, est{\'a} disponible en ingl{\'e}s, coreano y chino; y franc{\'e}s, alem{\'a}n, portugu{\'e}s y espa{\~n}ol en fase beta.[1]\hspace{0pt}},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {spanish},
  annotation = {Page Version ID: 167199861},
  file = {C:\Users\zahdehv\Zotero\storage\3C8IYRLC\Notion.html}
}

@article{nuzzoleseOpenKnowledgeExtraction,
  title = {Open {{Knowledge Extraction Challenge}}},
  author = {Nuzzolese, Andrea Giovanni and Gentile, Anna Lisa and Presutti, Valentina and Gangemi, Aldo and Garigliotti, Dar{\i}o and Navigli, Roberto},
  abstract = {The Open Knowledge Extraction (OKE) challenge is aimed at promoting research in the automatic extraction of structured content from textual data and its representation and publication as Linked Data. We designed two extraction tasks: (1) Entity Recognition, Linking and Typing and (2) Class Induction and entity typing. The challenge saw the participations of four systems: CETUS-FOX and FRED participating to both tasks, Adel participating to Task 1 and OAK@She eld participating to Task 2. In this paper we describe the OKE challenge, the tasks, the datasets used for training and evaluating the systems, the evaluation method, and obtained results.},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\RKPB5HGK\Nuzzolese et al. - Open Knowledge Extraction Challenge.pdf}
}

@misc{nyeShowYourWork2021,
  title = {Show {{Your Work}}: {{Scratchpads}} for {{Intermediate Computation}} with {{Language Models}}},
  shorttitle = {Show {{Your Work}}},
  author = {Nye, Maxwell and Andreassen, Anders Johan and {Gur-Ari}, Guy and Michalewski, Henryk and Austin, Jacob and Bieber, David and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and Luan, David and Sutton, Charles and Odena, Augustus},
  year = {2021},
  month = nov,
  number = {arXiv:2112.00114},
  eprint = {2112.00114},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2112.00114},
  urldate = {2025-04-04},
  abstract = {Large pre-trained language models perform remarkably well on tasks that can be done "in one pass", such as generating realistic text or synthesizing computer programs. However, they struggle with tasks that require unbounded multi-step computation, such as adding integers or executing programs. Surprisingly, we find that these same models are able to perform complex multi-step computations -- even in the few-shot regime -- when asked to perform the operation "step by step", showing the results of intermediate computations. In particular, we train transformers to perform multi-step computations by asking them to emit intermediate computation steps into a "scratchpad". On a series of increasingly complex tasks ranging from long addition to the execution of arbitrary programs, we show that scratchpads dramatically improve the ability of language models to perform multi-step computations.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\GEKSUMX8\\Nye et al. - 2021 - Show Your Work Scratchpads for Intermediate Computation with Language Models.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\PBN2GP6L\\2112.html}
}

@article{ObsidianSoftware2025,
  title = {{Obsidian (software)}},
  year = {2025},
  month = feb,
  journal = {Wikipedia, la enciclopedia libre},
  urldate = {2025-05-08},
  abstract = {Obsidian es una base de conocimientos personales y una aplicaci{\'o}n para tomar notas que opera con archivos Markdown, gestion{\'a}ndolos de forma local con opci{\'o}n de sincronizaci{\'o}n.[1]\hspace{0pt}[2]\hspace{0pt}[3]\hspace{0pt}Permite a los usuarios crear enlaces internos para las notas y luego visualizar las conexiones como un grafo.[4]\hspace{0pt} [5]\hspace{0pt} Est{\'a} dise{\~n}ada para ayudar a los usuarios a organizar y estructurar sus pensamientos y conocimientos de una manera flexible y no lineal. El software es gratuito para uso personal, con licencias comerciales de pago disponibles.[2]\hspace{0pt} [6]\hspace{0pt}},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {spanish},
  annotation = {Page Version ID: 165603354},
  file = {C:\Users\zahdehv\Zotero\storage\VUU99KHY\Obsidian_(software).html}
}

@misc{openaiGPT4TechnicalReport2024,
  title = {{{GPT-4 Technical Report}}},
  author = {OpenAI and Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and Avila, Red and Babuschkin, Igor and Balaji, Suchir and Balcom, Valerie and Baltescu, Paul and Bao, Haiming and Bavarian, Mohammad and Belgum, Jeff and Bello, Irwan and Berdine, Jake and {Bernadett-Shapiro}, Gabriel and Berner, Christopher and Bogdonoff, Lenny and Boiko, Oleg and Boyd, Madelaine and Brakman, Anna-Luisa and Brockman, Greg and Brooks, Tim and Brundage, Miles and Button, Kevin and Cai, Trevor and Campbell, Rosie and Cann, Andrew and Carey, Brittany and Carlson, Chelsea and Carmichael, Rory and Chan, Brooke and Chang, Che and Chantzis, Fotis and Chen, Derek and Chen, Sully and Chen, Ruby and Chen, Jason and Chen, Mark and Chess, Ben and Cho, Chester and Chu, Casey and Chung, Hyung Won and Cummings, Dave and Currier, Jeremiah and Dai, Yunxing and Decareaux, Cory and Degry, Thomas and Deutsch, Noah and Deville, Damien and Dhar, Arka and Dohan, David and Dowling, Steve and Dunning, Sheila and Ecoffet, Adrien and Eleti, Atty and Eloundou, Tyna and Farhi, David and Fedus, Liam and Felix, Niko and Fishman, Sim{\'o}n Posada and Forte, Juston and Fulford, Isabella and Gao, Leo and Georges, Elie and Gibson, Christian and Goel, Vik and Gogineni, Tarun and Goh, Gabriel and {Gontijo-Lopes}, Rapha and Gordon, Jonathan and Grafstein, Morgan and Gray, Scott and Greene, Ryan and Gross, Joshua and Gu, Shixiang Shane and Guo, Yufei and Hallacy, Chris and Han, Jesse and Harris, Jeff and He, Yuchen and Heaton, Mike and Heidecke, Johannes and Hesse, Chris and Hickey, Alan and Hickey, Wade and Hoeschele, Peter and Houghton, Brandon and Hsu, Kenny and Hu, Shengli and Hu, Xin and Huizinga, Joost and Jain, Shantanu and Jain, Shawn and Jang, Joanne and Jiang, Angela and Jiang, Roger and Jin, Haozhun and Jin, Denny and Jomoto, Shino and Jonn, Billie and Jun, Heewoo and Kaftan, Tomer and Kaiser, {\L}ukasz and Kamali, Ali and Kanitscheider, Ingmar and Keskar, Nitish Shirish and Khan, Tabarak and Kilpatrick, Logan and Kim, Jong Wook and Kim, Christina and Kim, Yongjik and Kirchner, Jan Hendrik and Kiros, Jamie and Knight, Matt and Kokotajlo, Daniel and Kondraciuk, {\L}ukasz and Kondrich, Andrew and Konstantinidis, Aris and Kosic, Kyle and Krueger, Gretchen and Kuo, Vishal and Lampe, Michael and Lan, Ikai and Lee, Teddy and Leike, Jan and Leung, Jade and Levy, Daniel and Li, Chak Ming and Lim, Rachel and Lin, Molly and Lin, Stephanie and Litwin, Mateusz and Lopez, Theresa and Lowe, Ryan and Lue, Patricia and Makanju, Anna and Malfacini, Kim and Manning, Sam and Markov, Todor and Markovski, Yaniv and Martin, Bianca and Mayer, Katie and Mayne, Andrew and McGrew, Bob and McKinney, Scott Mayer and McLeavey, Christine and McMillan, Paul and McNeil, Jake and Medina, David and Mehta, Aalok and Menick, Jacob and Metz, Luke and Mishchenko, Andrey and Mishkin, Pamela and Monaco, Vinnie and Morikawa, Evan and Mossing, Daniel and Mu, Tong and Murati, Mira and Murk, Oleg and M{\'e}ly, David and Nair, Ashvin and Nakano, Reiichiro and Nayak, Rajeev and Neelakantan, Arvind and Ngo, Richard and Noh, Hyeonwoo and Ouyang, Long and O'Keefe, Cullen and Pachocki, Jakub and Paino, Alex and Palermo, Joe and Pantuliano, Ashley and Parascandolo, Giambattista and Parish, Joel and Parparita, Emy and Passos, Alex and Pavlov, Mikhail and Peng, Andrew and Perelman, Adam and Peres, Filipe de Avila Belbute and Petrov, Michael and Pinto, Henrique Ponde de Oliveira and Michael and Pokorny and Pokrass, Michelle and Pong, Vitchyr H. and Powell, Tolly and Power, Alethea and Power, Boris and Proehl, Elizabeth and Puri, Raul and Radford, Alec and Rae, Jack and Ramesh, Aditya and Raymond, Cameron and Real, Francis and Rimbach, Kendra and Ross, Carl and Rotsted, Bob and Roussez, Henri and Ryder, Nick and Saltarelli, Mario and Sanders, Ted and Santurkar, Shibani and Sastry, Girish and Schmidt, Heather and Schnurr, David and Schulman, John and Selsam, Daniel and Sheppard, Kyla and Sherbakov, Toki and Shieh, Jessica and Shoker, Sarah and Shyam, Pranav and Sidor, Szymon and Sigler, Eric and Simens, Maddie and Sitkin, Jordan and Slama, Katarina and Sohl, Ian and Sokolowsky, Benjamin and Song, Yang and Staudacher, Natalie and Such, Felipe Petroski and Summers, Natalie and Sutskever, Ilya and Tang, Jie and Tezak, Nikolas and Thompson, Madeleine B. and Tillet, Phil and Tootoonchian, Amin and Tseng, Elizabeth and Tuggle, Preston and Turley, Nick and Tworek, Jerry and Uribe, Juan Felipe Cer{\'o}n and Vallone, Andrea and Vijayvergiya, Arun and Voss, Chelsea and Wainwright, Carroll and Wang, Justin Jay and Wang, Alvin and Wang, Ben and Ward, Jonathan and Wei, Jason and Weinmann, C. J. and Welihinda, Akila and Welinder, Peter and Weng, Jiayi and Weng, Lilian and Wiethoff, Matt and Willner, Dave and Winter, Clemens and Wolrich, Samuel and Wong, Hannah and Workman, Lauren and Wu, Sherwin and Wu, Jeff and Wu, Michael and Xiao, Kai and Xu, Tao and Yoo, Sarah and Yu, Kevin and Yuan, Qiming and Zaremba, Wojciech and Zellers, Rowan and Zhang, Chong and Zhang, Marvin and Zhao, Shengjia and Zheng, Tianhao and Zhuang, Juntang and Zhuk, William and Zoph, Barret},
  year = {2024},
  month = mar,
  number = {arXiv:2303.08774},
  eprint = {2303.08774},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2303.08774},
  urldate = {2025-05-07},
  abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\9HTRTB89\\OpenAI et al. - 2024 - GPT-4 Technical Report.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\8WUVX8K2\\2303.html}
}

@misc{parkEnhancingFutureLink2024,
  title = {Enhancing {{Future Link Prediction}} in {{Quantum Computing Semantic Networks}} through {{LLM-Initiated Node Features}}},
  author = {Park, Gilchan and Baity, Paul and Yoon, Byung-Jun and Hoisie, Adolfy},
  year = {2024},
  month = oct,
  number = {arXiv:2410.04251},
  eprint = {2410.04251},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.04251},
  urldate = {2025-05-15},
  abstract = {Quantum computing is rapidly evolving in both physics and computer science, offering the potential to solve complex problems and accelerate computational processes. The development of quantum chips necessitates understanding the correlations among diverse experimental conditions. Semantic networks built on scientific literature, representing meaningful relationships between concepts, have been used across various domains to identify knowledge gaps and novel concept combinations. Neural network-based approaches have shown promise in link prediction within these networks. This study proposes initializing node features using LLMs to enhance node representations for link prediction tasks in graph neural networks. LLMs can provide rich descriptions, reducing the need for manual feature creation and lowering costs. Our method, evaluated using various link prediction models on a quantum computing semantic network, demonstrated efficacy compared to traditional node embedding techniques.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Quantum Physics},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\TCHASPP4\\Park et al. - 2024 - Enhancing Future Link Prediction in Quantum Computing Semantic Networks through LLM-Initiated Node F.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\9Z5FF3EB\\2410.html}
}

@book{paukHowStudyCollege2010,
  title = {How to Study in College},
  author = {Pauk, Walter and Owens, Ross J. Q.},
  year = {2010},
  edition = {10th Ed},
  publisher = {Cengage Learning},
  address = {Boston, MA},
  isbn = {978-1-4390-8446-5 978-0-495-90302-4},
  lccn = {LB2395 .P3 2010},
  keywords = {College student orientation,Study skills},
  file = {C:\Users\zahdehv\Zotero\storage\HHB26VYR\Pauk and Owens - 2010 - How to study in college.epub}
}

@article{PersonalKnowledgeBase2024,
  title = {Personal Knowledge Base},
  year = {2024},
  month = nov,
  journal = {Wikipedia},
  urldate = {2025-05-02},
  abstract = {A personal knowledge base (PKB) is an electronic tool used by an individual to express, capture, and later retrieve personal knowledge. It differs from a traditional database in that it contains subjective material particular to the owner, that others may not agree with nor care about. Importantly, a PKB consists primarily of knowledge, rather than information; in other words, it is not a collection of documents or other sources an individual has encountered, but rather an expression of the distilled knowledge the owner has extracted from those sources or from elsewhere. The term personal knowledge base was mentioned as early as the 1980s, but the term came to prominence in the 2000s when it was described at length in publications by computer scientist Stephen Davies and colleagues, who compared PKBs on a number of different dimensions, the most important of which is the data model that each PKB uses to organize knowledge.:{$\mkern1mu$}18},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1255208991},
  file = {C:\Users\zahdehv\Zotero\storage\52KAFV44\Personal_knowledge_base.html}
}

@article{PersonalKnowledgeManagement2025,
  title = {Personal Knowledge Management},
  year = {2025},
  month = may,
  journal = {Wikipedia},
  urldate = {2025-05-02},
  abstract = {Personal knowledge management (PKM) is a process of collecting information that a person uses to gather, classify, store, search, retrieve and share knowledge in their daily activities (Grundspenkis 2007) and the way in which these processes support work activities (Wright 2005). It is a response to the idea that knowledge workers need to be responsible for their own growth and learning (Smedley 2009). It is a bottom-up approach to knowledge management (KM) (Pollard 2008).},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1288445324},
  file = {C:\Users\zahdehv\Zotero\storage\DAT9RUZE\Personal_knowledge_management.html}
}

@article{piolatCognitiveEffortNote2005,
  title = {Cognitive Effort during Note Taking},
  author = {Piolat, Annie and Olive, Thierry and Kellogg, Ronald T.},
  year = {2005},
  month = apr,
  journal = {Applied Cognitive Psychology},
  volume = {19},
  number = {3},
  pages = {291--312},
  issn = {0888-4080, 1099-0720},
  doi = {10.1002/acp.1086},
  urldate = {2025-05-08},
  abstract = {Note taking is a complex activity that requires comprehension and selection of information and written production processes. Here we review the functions, abbreviation procedures, strategies, and working memory constraints of note taking with the aim of improving theoretical and practical understanding of the activity. The time urgency of selecting key points and recording them while comprehending new information at the same time places significant demands on the central executive and other components of working memory. Dual- and triple-task procedures allow the measurement of the momentary cognitive effort or executive attention allocated to note taking. Comparative data show that note taking demands more effort than reading or learning. However, it requires less effort than the creative written composition of an original text. Copyright \# 2004 John Wiley \& Sons, Ltd.},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\FCFZX667\Piolat et al. - 2005 - Cognitive effort during note taking.pdf}
}

@misc{plaatReasoningLargeLanguage2024,
  title = {Reasoning with {{Large Language Models}}, a {{Survey}}},
  author = {Plaat, Aske and Wong, Annie and Verberne, Suzan and Broekens, Joost and van Stein, Niki and Back, Thomas},
  year = {2024},
  month = jul,
  number = {arXiv:2407.11511},
  eprint = {2407.11511},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.11511},
  urldate = {2025-02-28},
  abstract = {Scaling up language models to billions of parameters has opened up possibilities for in-context learning, allowing instruction tuning and few-shot learning on tasks that the model was not specifically trained for. This has achieved breakthrough performance on language tasks such as translation, summarization, and question-answering. Furthermore, in addition to these associative ``System 1'' tasks, recent advances in Chain-of-thought prompt learning have demonstrated strong ``System 2'' reasoning abilities, answering a question in the field of artificial general intelligence whether LLMs can reason.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C:\Users\zahdehv\Zotero\storage\SVEX5JVF\Plaat et al. - 2024 - Reasoning with Large Language Models, a Survey.pdf}
}

@misc{pressMeasuringNarrowingCompositionality2023,
  title = {Measuring and {{Narrowing}} the {{Compositionality Gap}} in {{Language Models}}},
  author = {Press, Ofir and Zhang, Muru and Min, Sewon and Schmidt, Ludwig and Smith, Noah A. and Lewis, Mike},
  year = {2023},
  month = oct,
  number = {arXiv:2210.03350},
  eprint = {2210.03350},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2210.03350},
  urldate = {2025-05-06},
  abstract = {We investigate the ability of language models to perform compositional reasoning tasks where the overall solution depends on correctly composing the answers to sub-problems. We measure how often models can correctly answer all sub-problems but not generate the overall solution, a ratio we call the compositionality gap. We evaluate this ratio by asking multi-hop questions with answers that require composing multiple facts unlikely to have been observed together during pretraining. In the GPT-3 family of models, as model size increases we show that the single-hop question answering performance improves faster than the multi-hop performance does, therefore the compositionality gap does not decrease. This surprising result suggests that while more powerful models memorize and recall more factual knowledge, they show no corresponding improvement in their ability to perform this kind of compositional reasoning. We then demonstrate how elicitive prompting (such as chain of thought) narrows the compositionality gap by reasoning explicitly. We present a new method, self-ask, that further improves on chain of thought. In our method, the model explicitly asks itself (and answers) follow-up questions before answering the initial question. We finally show that self-ask's structured prompting lets us easily plug in a search engine to answer the follow-up questions, which additionally improves accuracy.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\FB9K2X5S\\Press et al. - 2023 - Measuring and Narrowing the Compositionality Gap in Language Models.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\DUG3QUR4\\2210.html}
}

@article{pyneMetaworkHowWe2022,
  title = {Meta-Work: How We Research Is as Important as What We Research},
  shorttitle = {Meta-Work},
  author = {Pyne, Yvette and Stewart, Stuart},
  year = {2022},
  month = feb,
  journal = {The British Journal of General Practice},
  volume = {72},
  number = {716},
  pages = {130--131},
  issn = {0960-1643},
  doi = {10.3399/bjgp22X718757},
  urldate = {2025-05-05},
  pmcid = {PMC8884432},
  pmid = {35210247},
  file = {C:\Users\zahdehv\Zotero\storage\E7NSYHPA\Pyne and Stewart - 2022 - Meta-work how we research is as important as what we research.pdf}
}

@misc{qianOpenDomainKnowledge2023,
  title = {Open {{Domain Knowledge Extraction}} for {{Knowledge Graphs}}},
  author = {Qian, Kun and Belyi, Anton and Wu, Fei and Khorshidi, Samira and Nikfarjam, Azadeh and Khot, Rahul and Sang, Yisi and Luna, Katherine and Chu, Xianqi and Choi, Eric and Govind, Yash and Seivwright, Chloe and Sun, Yiwen and Fakhry, Ahmed and Rekatsinas, Theo and Ilyas, Ihab and Qi, Xiaoguang and Li, Yunyao},
  year = {2023},
  month = oct,
  number = {arXiv:2312.09424},
  eprint = {2312.09424},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.09424},
  urldate = {2025-04-18},
  abstract = {The quality of a knowledge graph directly impacts the quality of downstream applications (e.g. the number of answerable questions using the graph). One ongoing challenge when building a knowledge graph is to ensure completeness and freshness of the graph's entities and facts. In this paper, we introduce ODKE, a scalable and extensible framework that sources high-quality entities and facts from open web at scale. ODKE utilizes a wide range of extraction models and supports both streaming and batch processing at different latency. We reflect on the challenges and design decisions made and share lessons learned when building and deploying ODKE to grow an industry-scale open domain knowledge graph.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\W5UX2BQA\\Qian et al. - 2023 - Open Domain Knowledge Extraction for Knowledge Graphs.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\NRNMUNUT\\2312.html}
}

@article{RoamSoftware2024,
  title = {Roam (Software)},
  year = {2024},
  month = sep,
  journal = {Wikipedia},
  urldate = {2025-05-08},
  abstract = {Roam is a California-based productivity and note-taking application developed by Roam Research Inc. The system is built on a directed graph, which frees it from the constraints of the classic filesystem tree. It is viewed as a competitor to Notion.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1244332343},
  file = {C:\Users\zahdehv\Zotero\storage\WPPJWCLH\Roam_(software).html}
}

@article{rodriguezAprendizajeAutomaticoOrientado,
  title = {{Aprendizaje autom{\'a}tico orientado a la clasificaci{\'o}n de c{\'a}ncer de piel: un enfoque basado en EfficientNetB}},
  author = {Rodr{\'i}guez, Deborah Famadas and Ramos, Reinaldo Rodr{\'i}guez and Cruz, Dr Yudivian Almeida},
  langid = {spanish},
  file = {C:\Users\zahdehv\Zotero\storage\TKJUMIW2\Rodríguez et al. - Aprendizaje automático orientado a la clasificación de cáncer de piel un enfoque basado en Efficien.pdf}
}

@misc{sandilyaCanLLMsCompute2024,
  title = {Can {{LLMs Compute}} with {{Reasons}}?},
  author = {Sandilya, Harshit and Raj, Peehu and Bafna, Jainit Sushil and Mukhopadhyay, Srija and Sharma, Shivansh and Sharma, Ellwil and Sharma, Arastu and Trivedi, Neeta and Shrivastava, Manish and Kumar, Rajesh},
  year = {2024},
  month = feb,
  number = {arXiv:2402.12080},
  eprint = {2402.12080},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.12080},
  urldate = {2025-02-28},
  abstract = {Large language models (LLMs) often struggle with complex mathematical tasks, prone to ''hallucinating'' incorrect answers due to their reliance on statistical patterns. This limitation is further amplified in average Small LangSLMs with limited context and training data. To address this challenge, we propose an ''Inductive Learning'' approach utilizing a distributed network of SLMs. This network leverages error-based learning and hint incorporation to refine the reasoning capabilities of SLMs. Our goal is to provide a framework that empowers SLMs to approach the level of logic-based applications achieved by high-parameter models, potentially benefiting any language model. Ultimately, this novel concept paves the way for bridging the logical gap between humans and LLMs across various fields.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {C:\Users\zahdehv\Zotero\storage\PSHBSGJN\Sandilya et al. - 2024 - Can LLMs Compute with Reasons.pdf}
}

@misc{schickToolformerLanguageModels2023,
  title = {Toolformer: {{Language Models Can Teach Themselves}} to {{Use Tools}}},
  shorttitle = {Toolformer},
  author = {Schick, Timo and {Dwivedi-Yu}, Jane and Dess{\`i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  year = {2023},
  month = feb,
  number = {arXiv:2302.04761},
  eprint = {2302.04761},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2302.04761},
  urldate = {2025-05-01},
  abstract = {Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale. They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller models excel. In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction. This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API. We incorporate a range of tools, including a calculator, a Q{\textbackslash}\&A system, two different search engines, a translation system, and a calendar. Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\AT7P3SDS\\Schick et al. - 2023 - Toolformer Language Models Can Teach Themselves to Use Tools.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\7JYEUBLB\\2302.html}
}

@misc{schmidgallAgentRxivCollaborativeAutonomous2025,
  title = {{{AgentRxiv}}: {{Towards Collaborative Autonomous Research}}},
  shorttitle = {{{AgentRxiv}}},
  author = {Schmidgall, Samuel and Moor, Michael},
  year = {2025},
  month = mar,
  number = {arXiv:2503.18102},
  eprint = {2503.18102},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2503.18102},
  urldate = {2025-04-25},
  abstract = {Progress in scientific discovery is rarely the result of a single "Eureka" moment, but is rather the product of hundreds of scientists incrementally working together toward a common goal. While existing agent workflows are capable of producing research autonomously, they do so in isolation, without the ability to continuously improve upon prior research results. To address these challenges, we introduce AgentRxiv-a framework that lets LLM agent laboratories upload and retrieve reports from a shared preprint server in order to collaborate, share insights, and iteratively build on each other's research. We task agent laboratories to develop new reasoning and prompting techniques and find that agents with access to their prior research achieve higher performance improvements compared to agents operating in isolation (11.4\% relative improvement over baseline on MATH-500). We find that the best performing strategy generalizes to benchmarks in other domains (improving on average by 3.3\%). Multiple agent laboratories sharing research through AgentRxiv are able to work together towards a common goal, progressing more rapidly than isolated laboratories, achieving higher overall accuracy (13.7\% relative improvement over baseline on MATH-500). These findings suggest that autonomous agents may play a role in designing future AI systems alongside humans. We hope that AgentRxiv allows agents to collaborate toward research goals and enables researchers to accelerate discovery.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C:\Users\zahdehv\Zotero\storage\BB3XA7SY\Schmidgall and Moor - 2025 - AgentRxiv Towards Collaborative Autonomous Research.pdf}
}

@misc{schulhoffLearnPromptingCited,
  title = {Learn {{Prompting}}: {{Cited Papers}} on {{AI}} and {{Prompt Engineering}}},
  shorttitle = {Learn {{Prompting}}},
  author = {Schulhoff", "Sander},
  urldate = {2025-05-01},
  abstract = {Explore an organized list of research papers cited in the Learn Prompting course, covering topics like agents, automated prompts, datasets, detection, and more.},
  howpublished = {https://learnprompting.org/docs/bibliography},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\L3PV75AA\bibliography.html}
}

@misc{schulhoffPromptReportSystematic2025,
  title = {The {{Prompt Report}}: {{A Systematic Survey}} of {{Prompt Engineering Techniques}}},
  shorttitle = {The {{Prompt Report}}},
  author = {Schulhoff, Sander and Ilie, Michael and Balepur, Nishant and Kahadze, Konstantine and Liu, Amanda and Si, Chenglei and Li, Yinheng and Gupta, Aayush and Han, HyoJung and Schulhoff, Sevien and Dulepet, Pranav Sandeep and Vidyadhara, Saurav and Ki, Dayeon and Agrawal, Sweta and Pham, Chau and Kroiz, Gerson and Li, Feileen and Tao, Hudson and Srivastava, Ashay and Costa, Hevander Da and Gupta, Saloni and Rogers, Megan L. and Goncearenco, Inna and Sarli, Giuseppe and Galynker, Igor and Peskoff, Denis and Carpuat, Marine and White, Jules and Anadkat, Shyamal and Hoyle, Alexander and Resnik, Philip},
  year = {2025},
  month = feb,
  number = {arXiv:2406.06608},
  eprint = {2406.06608},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.06608},
  urldate = {2025-05-01},
  abstract = {Generative Artificial Intelligence (GenAI) systems are increasingly being deployed across diverse industries and research domains. Developers and end-users interact with these systems through the use of prompting and prompt engineering. Although prompt engineering is a widely adopted and extensively researched area, it suffers from conflicting terminology and a fragmented ontological understanding of what constitutes an effective prompt due to its relatively recent emergence. We establish a structured understanding of prompt engineering by assembling a taxonomy of prompting techniques and analyzing their applications. We present a detailed vocabulary of 33 vocabulary terms, a taxonomy of 58 LLM prompting techniques, and 40 techniques for other modalities. Additionally, we provide best practices and guidelines for prompt engineering, including advice for prompting state-of-the-art (SOTA) LLMs such as ChatGPT. We further present a meta-analysis of the entire literature on natural language prefix-prompting. As a culmination of these efforts, this paper presents the most comprehensive survey on prompt engineering to date.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\SL573B6J\\Schulhoff et al. - 2025 - The Prompt Report A Systematic Survey of Prompt Engineering Techniques.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\GJEBBKXL\\2406.html}
}

@misc{schuurmansMemoryAugmentedLarge2023,
  title = {Memory {{Augmented Large Language Models}} Are {{Computationally Universal}}},
  author = {Schuurmans, Dale},
  year = {2023},
  month = jan,
  number = {arXiv:2301.04589},
  eprint = {2301.04589},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2301.04589},
  urldate = {2025-06-11},
  abstract = {We show that transformer-based large language models are computationally universal when augmented with an external memory. Any deterministic language model that conditions on strings of bounded length is equivalent to a finite automaton, hence computationally limited. However, augmenting such models with a read-write memory creates the possibility of processing arbitrarily large inputs and, potentially, simulating any algorithm. We establish that an existing large language model, Flan-U-PaLM 540B, can be combined with an associative read-write memory to exactly simulate the execution of a universal Turing machine, U15,2. A key aspect of the finding is that it does not require any modification of the language model weights. Instead, the construction relies solely on designing a form of stored instruction computer that can subsequently be programmed with a specific set of prompts.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Formal Languages and Automata Theory},
  file = {C:\Users\zahdehv\Zotero\storage\SC6PG2XR\Schuurmans - 2023 - Memory Augmented Large Language Models are Computationally Universal.pdf}
}

@misc{sensayImplementingWisdomEngine2025,
  title = {Implementing a `{{Wisdom Engine}}' for {{Personal Knowledge Management}}},
  author = {Sensay},
  year = {2025},
  month = feb,
  journal = {Medium},
  urldate = {2025-05-07},
  abstract = {Building a wisdom engine means creating an AI-enhanced personal knowledge management system that not only stores information but helps{\dots}},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\JJTZE4XP\implementing-a-wisdom-engine-for-personal-knowledge-management-3c76b8d8f760.html}
}

@article{shanahanRolePlayLarge2023,
  title = {Role Play with Large Language Models},
  author = {Shanahan, Murray and McDonell, Kyle and Reynolds, Laria},
  year = {2023},
  month = nov,
  journal = {Nature},
  volume = {623},
  number = {7987},
  pages = {493--498},
  issn = {1476-4687},
  doi = {10.1038/s41586-023-06647-8},
  abstract = {As dialogue agents become increasingly human-like in their performance, we must develop effective ways to describe their behaviour in high-level terms without falling into the trap of anthropomorphism. Here we foreground the concept of role play. Casting dialogue-agent behaviour in terms of role play allows us to draw on familiar folk psychological terms, without ascribing human characteristics to language models that they in fact lack. Two important cases of dialogue-agent behaviour are addressed this way, namely, (apparent) deception and (apparent) self-awareness.},
  langid = {english},
  pmid = {37938776},
  keywords = {Deception,Humans,Imitative Behavior,Natural Language Processing,Self-Assessment,Terminology as Topic},
  file = {C:\Users\zahdehv\Zotero\storage\3MUCU3DJ\Shanahan et al. - 2023 - Role play with large language models.pdf}
}

@misc{shenQwenLongCPRS$infty$LLMsDynamic2025,
  title = {{{QwenLong-CPRS}}: {{Towards}} \${\textbackslash}infty\$-{{LLMs}} with {{Dynamic Context Optimization}}},
  shorttitle = {{{QwenLong-CPRS}}},
  author = {Shen, Weizhou and Li, Chenliang and Wan, Fanqi and Liao, Shengyi and Lai, Shaopeng and Zhang, Bo and Shi, Yingcheng and Wu, Yuning and Fu, Gang and Li, Zhansheng and Yang, Bin and Zhang, Ji and Huang, Fei and Zhou, Jingren and Yan, Ming},
  year = {2025},
  month = may,
  number = {arXiv:2505.18092},
  eprint = {2505.18092},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2505.18092},
  urldate = {2025-06-01},
  abstract = {This technical report presents QWENLONG-CPRS, a context compression framework designed for explicit long-context optimization, addressing prohibitive computation overhead during the prefill stage and the ``lost in the middle'' performance degradation of large language models (LLMs) during long sequence processing. Implemented through a novel dynamic context optimization mechanism, QWENLONGCPRS enables multi-granularity context compression guided by natural language instructions, achieving both efficiency gains and improved performance. Evolved from the Qwen architecture series, QWENLONG-CPRS introduces four key innovations: (1) Natural language-guided dynamic optimization, (2) Bidirectional reasoning layers for enhanced boundary awareness, (3) Token critic mechanisms with language modeling heads, and (4) Window-parallel inference. Comprehensive evaluations across five benchmarks (4K-2M word contexts) demonstrate QWENLONG-CPRS's threefold effectiveness: (1) Consistent superiority over other context management methods like RAG and sparse attention in both accuracy and efficiency. (2) Architecture-agnostic integration with all flagship LLMs, including GPT-4o, Gemini2.0-pro, Claude3.7-sonnet, DeepSeek-v3, and Qwen2.5max, achieves 21.59{\texttimes} context compression alongside 19.15-point average performance gains; (3) Deployed with Qwen2.5-32B-Instruct, QWENLONG-CPRS surpasses leading proprietary LLMs by 4.85 and 10.88 points on Ruler-128K and InfiniteBench, establishing new SOTA performance.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {C:\Users\zahdehv\Zotero\storage\WU4KPVZT\Shen et al. - 2025 - QwenLong-CPRS Towards $infty$-LLMs with Dynamic Context Optimization.pdf}
}

@misc{shinnReflexionLanguageAgents2023,
  title = {Reflexion: {{Language Agents}} with {{Verbal Reinforcement Learning}}},
  shorttitle = {Reflexion},
  author = {Shinn, Noah and Cassano, Federico and Berman, Edward and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  year = {2023},
  month = oct,
  number = {arXiv:2303.11366},
  eprint = {2303.11366},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2303.11366},
  urldate = {2025-02-28},
  abstract = {Large language models (LLMs) have been increasingly used to interact with external environments (e.g., games, compilers, APIs) as goal-driven agents. However, it remains challenging for these language agents to quickly and efficiently learn from trial-and-error as traditional reinforcement learning methods require extensive training samples and expensive model fine-tuning. We propose Reflexion, a novel framework to reinforce language agents not by updating weights, but instead through linguistic feedback. Concretely, Reflexion agents verbally reflect on task feedback signals, then maintain their own reflective text in an episodic memory buffer to induce better decision-making in subsequent trials. Reflexion is flexible enough to incorporate various types (scalar values or free-form language) and sources (external or internally simulated) of feedback signals, and obtains significant improvements over a baseline agent across diverse tasks (sequential decision-making, coding, language reasoning). For example, Reflexion achieves a 91\% pass@1 accuracy on the HumanEval coding benchmark, surpassing the previous state-of-the-art GPT-4 that achieves 80\%. We also conduct ablation and analysis studies using different feedback signals, feedback incorporation methods, and agent types, and provide insights into how they affect performance. We release all code, demos, and datasets at https://github.com/noahshinn024/reflexion.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C:\Users\zahdehv\Zotero\storage\BETRN8B3\Shinn et al. - 2023 - Reflexion Language Agents with Verbal Reinforcement Learning.pdf}
}

@misc{shuKnowledgeGraphLarge2024,
  title = {Knowledge {{Graph Large Language Model}} ({{KG-LLM}}) for {{Link Prediction}}},
  author = {Shu, Dong and Chen, Tianle and Jin, Mingyu and Zhang, Chong and Du, Mengnan and Zhang, Yongfeng},
  year = {2024},
  month = aug,
  number = {arXiv:2403.07311},
  eprint = {2403.07311},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.07311},
  urldate = {2025-05-15},
  abstract = {The task of multi-hop link prediction within knowledge graphs (KGs) stands as a challenge in the field of knowledge graph analysis, as it requires the model to reason through and understand all intermediate connections before making a prediction. In this paper, we introduce the Knowledge Graph Large Language Model (KG-LLM), a novel framework that leverages large language models (LLMs) for knowledge graph tasks. We first convert structured knowledge graph data into natural language and then use these natural language prompts to fine-tune LLMs to enhance multi-hop link prediction in KGs. By converting the KG to natural language prompts, our framework is designed to learn the latent representations of entities and their interrelations. To show the efficacy of the KG-LLM Framework, we fine-tune three leading LLMs within this framework, including Flan-T5, LLaMa2 and Gemma. Further, we explore the framework's potential to provide LLMs with zero-shot capabilities for handling previously unseen prompts. Experimental results show that KG-LLM significantly improves the models' generalization capabilities, leading to more accurate predictions in unfamiliar scenarios.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\SMX379C3\\Shu et al. - 2024 - Knowledge Graph Large Language Model (KG-LLM) for Link Prediction.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\Q8CPEI4V\\2403.html}
}

@article{songOpenFactFactualityEnhanced2023,
  title = {{{OpenFact}}: {{Factuality Enhanced Open Knowledge Extraction}}},
  shorttitle = {{{OpenFact}}},
  author = {Song, Linfeng and Wang, Ante and Pan, Xiaoman and Zhang, Hongming and Yu, Dian and Jin, Lifeng and Mi, Haitao and Su, Jinsong and Zhang, Yue and Yu, Dong},
  year = {2023},
  month = jun,
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {11},
  pages = {686--702},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00569},
  urldate = {2025-04-18},
  abstract = {We focus on the factuality property during the extraction of an OpenIE corpus named OpenFact, which contains more than 12 million high-quality knowledge triplets. We break down the factuality property into two important aspects---expressiveness and groundedness---and we propose a comprehensive framework to handle both aspects. To enhance expressiveness, we formulate each knowledge piece in OpenFact based on a semantic frame. We also design templates, extra constraints, and adopt human efforts so that most OpenFact triplets contain enough details. For groundedness, we require the main arguments of each triplet to contain linked Wikidata1 entities. A human evaluation suggests that the OpenFact triplets are much more accurate and contain denser information compared to OPIEC-Linked (Gashteovski et al., 2019), one recent high-quality OpenIE corpus grounded to Wikidata. Further experiments on knowledge base completion and knowledge base question answering show the effectiveness of OpenFact over OPIEC-Linked as supplementary knowledge to Wikidata as the major KG.},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\X9Y8MPDH\\Song et al. - 2023 - OpenFact Factuality Enhanced Open Knowledge Extraction.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\NZ7FFPC7\\OpenFact-Factuality-Enhanced-Open-Knowledge.html}
}

@misc{sriramApproximateGrammarInformation2003,
  title = {Approximate {{Grammar}} for {{Information Extraction}}},
  author = {Sriram, V. and Reddy, B. Ravi Sekar and Sangal, R.},
  year = {2003},
  month = may,
  number = {arXiv:cs/0305004},
  eprint = {cs/0305004},
  publisher = {arXiv},
  doi = {10.48550/arXiv.cs/0305004},
  urldate = {2025-05-15},
  abstract = {In this paper, we present the concept of Approximate grammar and how it can be used to extract information from a documemt. As the structure of informational strings cannot be defined well in a document, we cannot use the conventional grammar rules to represent the information. Hence, the need arises to design an approximate grammar that can be used effectively to accomplish the task of Information extraction. Approximate grammars are a novel step in this direction. The rules of an approximate grammar can be given by a user or the machine can learn the rules from an annotated document. We have performed our experiments in both the above areas and the results have been impressive.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\7SIIV3KS\\Sriram et al. - 2003 - Approximate Grammar for Information Extraction.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\65WI2R6F\\0305004.html}
}

@misc{StillBuildingMemex2011,
  title = {Still {{Building}} the {{Memex}} -- {{Communications}} of the {{ACM}}},
  year = {2011},
  month = feb,
  urldate = {2025-05-08},
  langid = {american},
  file = {C:\Users\zahdehv\Zotero\storage\UFKRPGF2\still-building-the-memex.html}
}

@misc{sumersCognitiveArchitecturesLanguage2024,
  title = {Cognitive {{Architectures}} for {{Language Agents}}},
  author = {Sumers, Theodore R. and Yao, Shunyu and Narasimhan, Karthik and Griffiths, Thomas L.},
  year = {2024},
  month = mar,
  number = {arXiv:2309.02427},
  eprint = {2309.02427},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.02427},
  urldate = {2025-02-28},
  abstract = {Recent efforts have augmented large language models (LLMs) with external resources (e.g., the Internet) or internal control flows (e.g., prompt chaining) for tasks requiring grounding or reasoning, leading to a new class of language agents. While these agents have achieved substantial empirical success, we lack a framework to organize existing agents and plan future developments. In this paper, we draw on the rich history of cognitive science and symbolic artificial intelligence to propose Cognitive Architectures for Language Agents (CoALA). CoALA describes a language agent with modular memory components, a structured action space to interact with internal memory and external environments, and a generalized decisionmaking process to choose actions. We use CoALA to retrospectively survey and organize a large body of recent work, and prospectively identify actionable directions towards more capable agents. Taken together, CoALA contextualizes today's language agents within the broader history of AI and outlines a path towards language-based general intelligence.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Symbolic Computation},
  file = {C:\Users\zahdehv\Zotero\storage\MCSQ8LMK\Sumers et al. - 2024 - Cognitive Architectures for Language Agents.pdf}
}

@misc{sunRecitationAugmentedLanguageModels2023,
  title = {Recitation-{{Augmented Language Models}}},
  author = {Sun, Zhiqing and Wang, Xuezhi and Tay, Yi and Yang, Yiming and Zhou, Denny},
  year = {2023},
  month = feb,
  number = {arXiv:2210.01296},
  eprint = {2210.01296},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2210.01296},
  urldate = {2025-05-01},
  abstract = {We propose a new paradigm to help Large Language Models (LLMs) generate more accurate factual knowledge without retrieving from an external corpus, called RECITation-augmented gEneration (RECITE). Different from retrieval-augmented language models that retrieve relevant documents before generating the outputs, given an input, RECITE first recites one or several relevant passages from LLMs' own memory via sampling, and then produces the final answers. We show that RECITE is a powerful paradigm for knowledge-intensive NLP tasks. Specifically, we show that by utilizing recitation as the intermediate step, a recite-and-answer scheme can achieve new state-of-the-art performance in various closed-book question answering (CBQA) tasks. In experiments, we verify the effectiveness of {\textbackslash}method{\textasciitilde}on four pre-trained models (PaLM, UL2, OPT, and Codex) and three CBQA tasks (Natural Questions, TriviaQA, and HotpotQA). Our code is available at "https://github.com/Edward-Sun/RECITE".},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\TAZSYTIP\\Sun et al. - 2023 - Recitation-Augmented Language Models.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\BPL8FF9Y\\2210.html}
}

@misc{sunTableThoughtExploring2025,
  title = {Table as {{Thought}}: {{Exploring Structured Thoughts}} in {{LLM Reasoning}}},
  shorttitle = {Table as {{Thought}}},
  author = {Sun, Zhenjie and Deng, Naihao and Yu, Haofei and You, Jiaxuan},
  year = {2025},
  month = jan,
  number = {arXiv:2501.02152},
  eprint = {2501.02152},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.02152},
  urldate = {2025-02-28},
  abstract = {Large language models' reasoning abilities benefit from methods that organize their thought processes, such as chain-of-thought prompting, which employs a sequential structure to guide the reasoning process step-by-step. However, existing approaches focus primarily on organizing the sequence of thoughts, leaving structure in individual thought steps underexplored. To address this gap, we propose Table as Thought, a framework inspired by cognitive neuroscience theories on human thought. Table as Thought organizes reasoning within a tabular schema, where rows represent sequential thought steps and columns capture critical constraints and contextual information to enhance reasoning. The reasoning process iteratively populates the table until self-verification ensures completeness and correctness. Our experiments show that Table as Thought excels in planning tasks and demonstrates a strong potential for enhancing LLM performance in mathematical reasoning compared to unstructured thought baselines. This work provides a novel exploration of refining thought representation within LLMs, paving the way for advancements in reasoning and AI cognition.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C:\Users\zahdehv\Zotero\storage\7NVXI49A\Sun et al. - 2025 - Table as Thought Exploring Structured Thoughts in LLM Reasoning.pdf}
}

@article{SurveyLLMaugmentedKnowledge2024,
  title = {A Survey of {{LLM-augmented}} Knowledge Graph Construction and Application in Complex Product Design},
  year = {2024},
  month = jan,
  journal = {Procedia CIRP},
  volume = {128},
  pages = {870--875},
  publisher = {Elsevier},
  issn = {2212-8271},
  doi = {10.1016/j.procir.2024.07.069},
  urldate = {2025-05-15},
  abstract = {In the field of complex product design, deploying knowledge graphs (KGs) has become a promising trend due to its strength on exploiting and applying t{\dots}},
  langid = {american},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\XRBQRH6L\\Liang et al. - 2024 - A survey of LLM-augmented knowledge graph construction and application in complex product design.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\K8I8RZJQ\\S2212827124007911.html}
}

@misc{teamGemini15Unlocking2024,
  title = {Gemini 1.5: {{Unlocking}} Multimodal Understanding across Millions of Tokens of Context},
  shorttitle = {Gemini 1.5},
  author = {Team, Gemini and Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and Mariooryad, Soroosh and Ding, Yifan and Geng, Xinyang and Alcober, Fred and Frostig, Roy and Omernick, Mark and Walker, Lexi and Paduraru, Cosmin and Sorokin, Christina and Tacchetti, Andrea and Gaffney, Colin and Daruki, Samira and Sercinoglu, Olcan and Gleicher, Zach and Love, Juliette and Voigtlaender, Paul and Jain, Rohan and Surita, Gabriela and Mohamed, Kareem and Blevins, Rory and Ahn, Junwhan and Zhu, Tao and Kawintiranon, Kornraphop and Firat, Orhan and Gu, Yiming and Zhang, Yujing and Rahtz, Matthew and Faruqui, Manaal and Clay, Natalie and Gilmer, Justin and {Co-Reyes}, J. D. and Penchev, Ivo and Zhu, Rui and Morioka, Nobuyuki and Hui, Kevin and Haridasan, Krishna and Campos, Victor and Mahdieh, Mahdis and Guo, Mandy and Hassan, Samer and Kilgour, Kevin and Vezer, Arpi and Cheng, Heng-Tze and de Liedekerke, Raoul and Goyal, Siddharth and Barham, Paul and Strouse, D. J. and Noury, Seb and Adler, Jonas and Sundararajan, Mukund and Vikram, Sharad and Lepikhin, Dmitry and Paganini, Michela and Garcia, Xavier and Yang, Fan and Valter, Dasha and Trebacz, Maja and Vodrahalli, Kiran and Asawaroengchai, Chulayuth and Ring, Roman and Kalb, Norbert and Soares, Livio Baldini and Brahma, Siddhartha and Steiner, David and Yu, Tianhe and Mentzer, Fabian and He, Antoine and Gonzalez, Lucas and Xu, Bibo and Kaufman, Raphael Lopez and Shafey, Laurent El and Oh, Junhyuk and Hennigan, Tom and van den Driessche, George and Odoom, Seth and Lucic, Mario and Roelofs, Becca and Lall, Sid and Marathe, Amit and Chan, Betty and Ontanon, Santiago and He, Luheng and Teplyashin, Denis and Lai, Jonathan and Crone, Phil and Damoc, Bogdan and Ho, Lewis and Riedel, Sebastian and Lenc, Karel and Yeh, Chih-Kuan and Chowdhery, Aakanksha and Xu, Yang and Kazemi, Mehran and Amid, Ehsan and Petrushkina, Anastasia and Swersky, Kevin and Khodaei, Ali and Chen, Gowoon and Larkin, Chris and Pinto, Mario and Yan, Geng and Badia, Adria Puigdomenech and Patil, Piyush and Hansen, Steven and Orr, Dave and Arnold, Sebastien M. R. and Grimstad, Jordan and Dai, Andrew and Douglas, Sholto and Sinha, Rishika and Yadav, Vikas and Chen, Xi and Gribovskaya, Elena and Austin, Jacob and Zhao, Jeffrey and Patel, Kaushal and Komarek, Paul and Austin, Sophia and Borgeaud, Sebastian and Friso, Linda and Goyal, Abhimanyu and Caine, Ben and Cao, Kris and Chung, Da-Woon and Lamm, Matthew and {Barth-Maron}, Gabe and Kagohara, Thais and Olszewska, Kate and Chen, Mia and Shivakumar, Kaushik and Agarwal, Rishabh and Godhia, Harshal and Rajwar, Ravi and Snaider, Javier and Dotiwalla, Xerxes and Liu, Yuan and Barua, Aditya and Ungureanu, Victor and Zhang, Yuan and Batsaikhan, Bat-Orgil and Wirth, Mateo and Qin, James and Danihelka, Ivo and Doshi, Tulsee and Chadwick, Martin and Chen, Jilin and Jain, Sanil and Le, Quoc and Kar, Arjun and Gurumurthy, Madhu and Li, Cheng and Sang, Ruoxin and Liu, Fangyu and Lamprou, Lampros and Munoz, Rich and Lintz, Nathan and Mehta, Harsh and Howard, Heidi and Reynolds, Malcolm and Aroyo, Lora and Wang, Quan and Blanco, Lorenzo and Cassirer, Albin and Griffith, Jordan and Das, Dipanjan and Lee, Stephan and Sygnowski, Jakub and Fisher, Zach and Besley, James and Powell, Richard and Ahmed, Zafarali and Paulus, Dominik and Reitter, David and Borsos, Zalan and Joshi, Rishabh and Pope, Aedan and Hand, Steven and Selo, Vittorio and Jain, Vihan and Sethi, Nikhil and Goel, Megha and Makino, Takaki and May, Rhys and Yang, Zhen and Schalkwyk, Johan and Butterfield, Christina and Hauth, Anja and Goldin, Alex and Hawkins, Will and Senter, Evan and Brin, Sergey and Woodman, Oliver and Ritter, Marvin and Noland, Eric and Giang, Minh and Bolina, Vijay and Lee, Lisa and Blyth, Tim and Mackinnon, Ian and Reid, Machel and Sarvana, Obaid and Silver, David and Chen, Alexander and Wang, Lily and Maggiore, Loren and Chang, Oscar and Attaluri, Nithya and Thornton, Gregory and Chiu, Chung-Cheng and Bunyan, Oskar and Levine, Nir and Chung, Timothy and Eltyshev, Evgenii and Si, Xiance and Lillicrap, Timothy and Brady, Demetra and Aggarwal, Vaibhav and Wu, Boxi and Xu, Yuanzhong and McIlroy, Ross and Badola, Kartikeya and Sandhu, Paramjit and Moreira, Erica and Stokowiec, Wojciech and Hemsley, Ross and Li, Dong and Tudor, Alex and Shyam, Pranav and Rahimtoroghi, Elahe and Haykal, Salem and Sprechmann, Pablo and Zhou, Xiang and Mincu, Diana and Li, Yujia and Addanki, Ravi and Krishna, Kalpesh and Wu, Xiao and Frechette, Alexandre and Eyal, Matan and Dafoe, Allan and Lacey, Dave and Whang, Jay and Avrahami, Thi and Zhang, Ye and Taropa, Emanuel and Lin, Hanzhao and Toyama, Daniel and Rutherford, Eliza and Sano, Motoki and Choe, HyunJeong and Tomala, Alex and {Safranek-Shrader}, Chalence and Kassner, Nora and Pajarskas, Mantas and Harvey, Matt and Sechrist, Sean and Fortunato, Meire and Lyu, Christina and Elsayed, Gamaleldin and Kuang, Chenkai and Lottes, James and Chu, Eric and Jia, Chao and Chen, Chih-Wei and Humphreys, Peter and Baumli, Kate and Tao, Connie and Samuel, Rajkumar and dos Santos, Cicero Nogueira and Andreassen, Anders and Raki{\'c}evi{\'c}, Nemanja and Grewe, Dominik and Kumar, Aviral and Winkler, Stephanie and Caton, Jonathan and Brock, Andrew and Dalmia, Sid and Sheahan, Hannah and Barr, Iain and Miao, Yingjie and Natsev, Paul and Devlin, Jacob and Behbahani, Feryal and Prost, Flavien and Sun, Yanhua and Myaskovsky, Artiom and Pillai, Thanumalayan Sankaranarayana and Hurt, Dan and Lazaridou, Angeliki and Xiong, Xi and Zheng, Ce and Pardo, Fabio and Li, Xiaowei and Horgan, Dan and Stanton, Joe and Ambar, Moran and Xia, Fei and Lince, Alejandro and Wang, Mingqiu and Mustafa, Basil and Webson, Albert and Lee, Hyo and Anil, Rohan and Wicke, Martin and Dozat, Timothy and Sinha, Abhishek and Piqueras, Enrique and Dabir, Elahe and Upadhyay, Shyam and Boral, Anudhyan and Hendricks, Lisa Anne and Fry, Corey and Djolonga, Josip and Su, Yi and Walker, Jake and Labanowski, Jane and Huang, Ronny and Misra, Vedant and Chen, Jeremy and {Skerry-Ryan}, R. J. and Singh, Avi and Rijhwani, Shruti and Yu, Dian and {Castro-Ros}, Alex and Changpinyo, Beer and Datta, Romina and Bagri, Sumit and Hrafnkelsson, Arnar Mar and Maggioni, Marcello and Zheng, Daniel and Sulsky, Yury and Hou, Shaobo and Paine, Tom Le and Yang, Antoine and Riesa, Jason and Rogozinska, Dominika and Marcus, Dror and Badawy, Dalia El and Zhang, Qiao and Wang, Luyu and Miller, Helen and Greer, Jeremy and Sjos, Lars Lowe and Nova, Azade and Zen, Heiga and Chaabouni, Rahma and Rosca, Mihaela and Jiang, Jiepu and Chen, Charlie and Liu, Ruibo and Sainath, Tara and Krikun, Maxim and Polozov, Alex and Lespiau, Jean-Baptiste and Newlan, Josh and Cankara, Zeyncep and Kwak, Soo and Xu, Yunhan and Chen, Phil and Coenen, Andy and Meyer, Clemens and Tsihlas, Katerina and Ma, Ada and Gottweis, Juraj and Xing, Jinwei and Gu, Chenjie and Miao, Jin and Frank, Christian and Cankara, Zeynep and Ganapathy, Sanjay and Dasgupta, Ishita and {Hughes-Fitt}, Steph and Chen, Heng and Reid, David and Rong, Keran and Fan, Hongmin and van Amersfoort, Joost and Zhuang, Vincent and Cohen, Aaron and Gu, Shixiang Shane and Mohananey, Anhad and Ilic, Anastasija and Tobin, Taylor and Wieting, John and Bortsova, Anna and Thacker, Phoebe and Wang, Emma and Caveness, Emily and Chiu, Justin and Sezener, Eren and Kaskasoli, Alex and Baker, Steven and Millican, Katie and Elhawaty, Mohamed and Aisopos, Kostas and Lebsack, Carl and Byrd, Nathan and Dai, Hanjun and Jia, Wenhao and Wiethoff, Matthew and Davoodi, Elnaz and Weston, Albert and Yagati, Lakshman and Ahuja, Arun and Gao, Isabel and Pundak, Golan and Zhang, Susan and Azzam, Michael and Sim, Khe Chai and Caelles, Sergi and Keeling, James and Sharma, Abhanshu and Swing, Andy and Li, YaGuang and Liu, Chenxi and Bostock, Carrie Grimes and Bansal, Yamini and Nado, Zachary and Anand, Ankesh and Lipschultz, Josh and Karmarkar, Abhijit and Proleev, Lev and Ittycheriah, Abe and Yeganeh, Soheil Hassas and Polovets, George and Faust, Aleksandra and Sun, Jiao and Rrustemi, Alban and Li, Pen and Shivanna, Rakesh and Liu, Jeremiah and Welty, Chris and Lebron, Federico and Baddepudi, Anirudh and Krause, Sebastian and Parisotto, Emilio and Soricut, Radu and Xu, Zheng and Bloxwich, Dawn and Johnson, Melvin and Neyshabur, Behnam and {Mao-Jones}, Justin and Wang, Renshen and Ramasesh, Vinay and Abbas, Zaheer and Guez, Arthur and Segal, Constant and Nguyen, Duc Dung and Svensson, James and Hou, Le and York, Sarah and Milan, Kieran and Bridgers, Sophie and Gworek, Wiktor and Tagliasacchi, Marco and {Lee-Thorp}, James and Chang, Michael and Guseynov, Alexey and Hartman, Ale Jakse and Kwong, Michael and Zhao, Ruizhe and Kashem, Sheleem and Cole, Elizabeth and Miech, Antoine and Tanburn, Richard and Phuong, Mary and Pavetic, Filip and Cevey, Sebastien and Comanescu, Ramona and Ives, Richard and Yang, Sherry and Du, Cosmo and Li, Bo and Zhang, Zizhao and Iinuma, Mariko and Hu, Clara Huiyi and Roy, Aurko and Bijwadia, Shaan and Zhu, Zhenkai and Martins, Danilo and Saputro, Rachel and Gergely, Anita and Zheng, Steven and Jia, Dawei and Antonoglou, Ioannis and Sadovsky, Adam and Gu, Shane and Bi, Yingying and Andreev, Alek and Samangooei, Sina and Khan, Mina and Kocisky, Tomas and Filos, Angelos and Kumar, Chintu and Bishop, Colton and Yu, Adams and Hodkinson, Sarah and Mittal, Sid and Shah, Premal and Moufarek, Alexandre and Cheng, Yong and Bloniarz, Adam and Lee, Jaehoon and Pejman, Pedram and Michel, Paul and Spencer, Stephen and Feinberg, Vladimir and Xiong, Xuehan and Savinov, Nikolay and Smith, Charlotte and Shakeri, Siamak and Tran, Dustin and Chesus, Mary and Bohnet, Bernd and Tucker, George and von Glehn, Tamara and Muir, Carrie and Mao, Yiran and Kazawa, Hideto and Slone, Ambrose and Soparkar, Kedar and Shrivastava, Disha and {Cobon-Kerr}, James and Sharman, Michael and Pavagadhi, Jay and Araya, Carlos and Misiunas, Karolis and Ghelani, Nimesh and Laskin, Michael and Barker, David and Li, Qiujia and Briukhov, Anton and Houlsby, Neil and Glaese, Mia and Lakshminarayanan, Balaji and Schucher, Nathan and Tang, Yunhao and Collins, Eli and Lim, Hyeontaek and Feng, Fangxiaoyu and Recasens, Adria and Lai, Guangda and Magni, Alberto and Cao, Nicola De and Siddhant, Aditya and Ashwood, Zoe and Orbay, Jordi and Dehghani, Mostafa and Brennan, Jenny and He, Yifan and Xu, Kelvin and Gao, Yang and Saroufim, Carl and Molloy, James and Wu, Xinyi and Arnold, Seb and Chang, Solomon and Schrittwieser, Julian and Buchatskaya, Elena and Radpour, Soroush and Polacek, Martin and Giordano, Skye and Bapna, Ankur and Tokumine, Simon and Hellendoorn, Vincent and Sottiaux, Thibault and Cogan, Sarah and Severyn, Aliaksei and Saleh, Mohammad and Thakoor, Shantanu and Shefey, Laurent and Qiao, Siyuan and Gaba, Meenu and Chang, Shuo-yiin and Swanson, Craig and Zhang, Biao and Lee, Benjamin and Rubenstein, Paul Kishan and Song, Gan and Kwiatkowski, Tom and Koop, Anna and Kannan, Ajay and Kao, David and Schuh, Parker and Stjerngren, Axel and Ghiasi, Golnaz and Gibson, Gena and Vilnis, Luke and Yuan, Ye and Ferreira, Felipe Tiengo and Kamath, Aishwarya and Klimenko, Ted and Franko, Ken and Xiao, Kefan and Bhattacharya, Indro and Patel, Miteyan and Wang, Rui and Morris, Alex and Strudel, Robin and Sharma, Vivek and Choy, Peter and Hashemi, Sayed Hadi and Landon, Jessica and Finkelstein, Mara and Jhakra, Priya and Frye, Justin and Barnes, Megan and Mauger, Matthew and Daun, Dennis and Baatarsukh, Khuslen and Tung, Matthew and Farhan, Wael and Michalewski, Henryk and Viola, Fabio and Quitry, Felix de Chaumont and Lan, Charline Le and Hudson, Tom and Wang, Qingze and Fischer, Felix and Zheng, Ivy and White, Elspeth and Dragan, Anca and Alayrac, Jean-baptiste and Ni, Eric and Pritzel, Alexander and Iwanicki, Adam and Isard, Michael and Bulanova, Anna and Zilka, Lukas and Dyer, Ethan and Sachan, Devendra and Srinivasan, Srivatsan and Muckenhirn, Hannah and Cai, Honglong and Mandhane, Amol and Tariq, Mukarram and Rae, Jack W. and Wang, Gary and Ayoub, Kareem and FitzGerald, Nicholas and Zhao, Yao and Han, Woohyun and Alberti, Chris and Garrette, Dan and Krishnakumar, Kashyap and Gimenez, Mai and Levskaya, Anselm and Sohn, Daniel and Matak, Josip and Iturrate, Inaki and Chang, Michael B. and Xiang, Jackie and Cao, Yuan and Ranka, Nishant and Brown, Geoff and Hutter, Adrian and Mirrokni, Vahab and Chen, Nanxin and Yao, Kaisheng and Egyed, Zoltan and Galilee, Francois and Liechty, Tyler and Kallakuri, Praveen and Palmer, Evan and Ghemawat, Sanjay and Liu, Jasmine and Tao, David and Thornton, Chloe and Green, Tim and Jasarevic, Mimi and Lin, Sharon and Cotruta, Victor and Tan, Yi-Xuan and Fiedel, Noah and Yu, Hongkun and Chi, Ed and Neitz, Alexander and Heitkaemper, Jens and Sinha, Anu and Zhou, Denny and Sun, Yi and Kaed, Charbel and Hulse, Brice and Mishra, Swaroop and Georgaki, Maria and Kudugunta, Sneha and Farabet, Clement and Shafran, Izhak and Vlasic, Daniel and Tsitsulin, Anton and Ananthanarayanan, Rajagopal and Carin, Alen and Su, Guolong and Sun, Pei and V, Shashank and Carvajal, Gabriel and Broder, Josef and Comsa, Iulia and Repina, Alena and Wong, William and Chen, Warren Weilun and Hawkins, Peter and Filonov, Egor and Loher, Lucia and Hirnschall, Christoph and Wang, Weiyi and Ye, Jingchen and Burns, Andrea and Cate, Hardie and Wright, Diana Gage and Piccinini, Federico and Zhang, Lei and Lin, Chu-Cheng and Gog, Ionel and Kulizhskaya, Yana and Sreevatsa, Ashwin and Song, Shuang and Cobo, Luis C. and Iyer, Anand and Tekur, Chetan and Garrido, Guillermo and Xiao, Zhuyun and Kemp, Rupert and Zheng, Huaixiu Steven and Li, Hui and Agarwal, Ananth and Ngani, Christel and Goshvadi, Kati and {Santamaria-Fernandez}, Rebeca and Fica, Wojciech and Chen, Xinyun and Gorgolewski, Chris and Sun, Sean and Garg, Roopal and Ye, Xinyu and Eslami, S. M. Ali and Hua, Nan and Simon, Jon and Joshi, Pratik and Kim, Yelin and Tenney, Ian and Potluri, Sahitya and Thiet, Lam Nguyen and Yuan, Quan and Luisier, Florian and Chronopoulou, Alexandra and Scellato, Salvatore and Srinivasan, Praveen and Chen, Minmin and Koverkathu, Vinod and Dalibard, Valentin and Xu, Yaming and Saeta, Brennan and Anderson, Keith and Sellam, Thibault and Fernando, Nick and Huot, Fantine and Jung, Junehyuk and Varadarajan, Mani and Quinn, Michael and Raul, Amit and Le, Maigo and Habalov, Ruslan and Clark, Jon and Jalan, Komal and Bullard, Kalesha and Singhal, Achintya and Luong, Thang and Wang, Boyu and Rajayogam, Sujeevan and Eisenschlos, Julian and Jia, Johnson and Finchelstein, Daniel and Yakubovich, Alex and Balle, Daniel and Fink, Michael and Agarwal, Sameer and Li, Jing and Dvijotham, Dj and Pal, Shalini and Kang, Kai and Konzelmann, Jaclyn and Beattie, Jennifer and Dousse, Olivier and Wu, Diane and Crocker, Remi and Elkind, Chen and Jonnalagadda, Siddhartha Reddy and Lee, Jong and {Holtmann-Rice}, Dan and Kallarackal, Krystal and Liu, Rosanne and Vnukov, Denis and Vats, Neera and Invernizzi, Luca and Jafari, Mohsen and Zhou, Huanjie and Taylor, Lilly and Prendki, Jennifer and Wu, Marcus and Eccles, Tom and Liu, Tianqi and Kopparapu, Kavya and Beaufays, Francoise and Angermueller, Christof and Marzoca, Andreea and Sarcar, Shourya and Dib, Hilal and Stanway, Jeff and Perbet, Frank and Trdin, Nejc and Sterneck, Rachel and Khorlin, Andrey and Li, Dinghua and Wu, Xihui and Goenka, Sonam and Madras, David and Goldshtein, Sasha and Gierke, Willi and Zhou, Tong and Liu, Yaxin and Liang, Yannie and White, Anais and Li, Yunjie and Singh, Shreya and Bahargam, Sanaz and Epstein, Mark and Basu, Sujoy and Lao, Li and Ozturel, Adnan and Crous, Carl and Zhai, Alex and Lu, Han and Tung, Zora and Gaur, Neeraj and Walton, Alanna and Dixon, Lucas and Zhang, Ming and Globerson, Amir and Uy, Grant and Bolt, Andrew and Wiles, Olivia and Nasr, Milad and Shumailov, Ilia and Selvi, Marco and Piccinno, Francesco and Aguilar, Ricardo and McCarthy, Sara and Khalman, Misha and Shukla, Mrinal and Galic, Vlado and Carpenter, John and Villela, Kevin and Zhang, Haibin and Richardson, Harry and Martens, James and Bosnjak, Matko and Belle, Shreyas Rammohan and Seibert, Jeff and Alnahlawi, Mahmoud and McWilliams, Brian and Singh, Sankalp and Louis, Annie and Ding, Wen and Popovici, Dan and Simicich, Lenin and Knight, Laura and Mehta, Pulkit and Gupta, Nishesh and Shi, Chongyang and Fatehi, Saaber and Mitrovic, Jovana and Grills, Alex and Pagadora, Joseph and Munkhdalai, Tsendsuren and Petrova, Dessie and Eisenbud, Danielle and Zhang, Zhishuai and Yates, Damion and Mittal, Bhavishya and Tripuraneni, Nilesh and Assael, Yannis and Brovelli, Thomas and Jain, Prateek and Velimirovic, Mihajlo and Akbulut, Canfer and Mu, Jiaqi and Macherey, Wolfgang and Kumar, Ravin and Xu, Jun and Qureshi, Haroon and Comanici, Gheorghe and Wiesner, Jeremy and Gong, Zhitao and Ruddock, Anton and Bauer, Matthias and Felt, Nick and GP, Anirudh and Arnab, Anurag and Zelle, Dustin and Rothfuss, Jonas and Rosgen, Bill and Shenoy, Ashish and Seybold, Bryan and Li, Xinjian and Mudigonda, Jayaram and Erdogan, Goker and Xia, Jiawei and Simsa, Jiri and Michi, Andrea and Yao, Yi and Yew, Christopher and Kan, Steven and Caswell, Isaac and Radebaugh, Carey and Elisseeff, Andre and Valenzuela, Pedro and McKinney, Kay and Paterson, Kim and Cui, Albert and {Latorre-Chimoto}, Eri and Kim, Solomon and Zeng, William and Durden, Ken and Ponnapalli, Priya and Sosea, Tiberiu and {Choquette-Choo}, Christopher A. and Manyika, James and Robenek, Brona and Vashisht, Harsha and Pereira, Sebastien and Lam, Hoi and Velic, Marko and {Owusu-Afriyie}, Denese and Lee, Katherine and Bolukbasi, Tolga and Parrish, Alicia and Lu, Shawn and Park, Jane and Venkatraman, Balaji and Talbert, Alice and Rosique, Lambert and Cheng, Yuchung and Sozanschi, Andrei and Paszke, Adam and Kumar, Praveen and Austin, Jessica and Li, Lu and Salama, Khalid and Perz, Bartek and Kim, Wooyeol and Dukkipati, Nandita and Baryshnikov, Anthony and Kaplanis, Christos and Sheng, XiangHai and Chervonyi, Yuri and Unlu, Caglar and Casas, Diego de Las and Askham, Harry and Tunyasuvunakool, Kathryn and Gimeno, Felix and Poder, Siim and Kwak, Chester and Miecnikowski, Matt and Mirrokni, Vahab and Dimitriev, Alek and Parisi, Aaron and Liu, Dangyi and Tsai, Tomy and Shevlane, Toby and Kouridi, Christina and Garmon, Drew and Goedeckemeyer, Adrian and Brown, Adam R. and Vijayakumar, Anitha and Elqursh, Ali and Jazayeri, Sadegh and Huang, Jin and Carthy, Sara Mc and Hoover, Jay and Kim, Lucy and Kumar, Sandeep and Chen, Wei and Biles, Courtney and Bingham, Garrett and Rosen, Evan and Wang, Lisa and Tan, Qijun and Engel, David and Pongetti, Francesco and de Cesare, Dario and Hwang, Dongseong and Yu, Lily and Pullman, Jennifer and Narayanan, Srini and Levin, Kyle and Gopal, Siddharth and Li, Megan and Aharoni, Asaf and Trinh, Trieu and Lo, Jessica and Casagrande, Norman and Vij, Roopali and Matthey, Loic and Ramadhana, Bramandia and Matthews, Austin and Carey, C. J. and Johnson, Matthew and Goranova, Kremena and Shah, Rohin and Ashraf, Shereen and Dasgupta, Kingshuk and Larsen, Rasmus and Wang, Yicheng and Vuyyuru, Manish Reddy and Jiang, Chong and Ijazi, Joana and Osawa, Kazuki and Smith, Celine and Boppana, Ramya Sree and Bilal, Taylan and Koizumi, Yuma and Xu, Ying and Altun, Yasemin and Shabat, Nir and Bariach, Ben and Korchemniy, Alex and Choo, Kiam and Ronneberger, Olaf and Iwuanyanwu, Chimezie and Zhao, Shubin and Soergel, David and Hsieh, Cho-Jui and Cai, Irene and Iqbal, Shariq and Sundermeyer, Martin and Chen, Zhe and Bursztein, Elie and Malaviya, Chaitanya and Biadsy, Fadi and Shroff, Prakash and Dhillon, Inderjit and Latkar, Tejasi and Dyer, Chris and Forbes, Hannah and Nicosia, Massimo and Nikolaev, Vitaly and Greene, Somer and Georgiev, Marin and Wang, Pidong and Martin, Nina and Sedghi, Hanie and Zhang, John and Banzal, Praseem and Fritz, Doug and Rao, Vikram and Wang, Xuezhi and Zhang, Jiageng and Patraucean, Viorica and Du, Dayou and Mordatch, Igor and Jurin, Ivan and Liu, Lewis and Dubey, Ayush and Mohan, Abhi and Nowakowski, Janek and Ion, Vlad-Doru and Wei, Nan and Tojo, Reiko and Raad, Maria Abi and Hudson, Drew A. and Keshava, Vaishakh and Agrawal, Shubham and Ramirez, Kevin and Wu, Zhichun and Nguyen, Hoang and Liu, Ji and Sewak, Madhavi and Petrini, Bryce and Choi, DongHyun and Philips, Ivan and Wang, Ziyue and Bica, Ioana and Garg, Ankush and Wilkiewicz, Jarek and Agrawal, Priyanka and Li, Xiaowei and Guo, Danhao and Xue, Emily and Shaik, Naseer and Leach, Andrew and Khan, Sadh MNM and Wiesinger, Julia and Jerome, Sammy and Chakladar, Abhishek and Wang, Alek Wenjiao and Ornduff, Tina and Abu, Folake and Ghaffarkhah, Alireza and Wainwright, Marcus and Cortes, Mario and Liu, Frederick and Maynez, Joshua and Terzis, Andreas and Samangouei, Pouya and Mansour, Riham and K{\k e}pa, Tomasz and Aubet, Fran{\c c}ois-Xavier and Algymr, Anton and Banica, Dan and Weisz, Agoston and Orban, Andras and Senges, Alexandre and Andrejczuk, Ewa and Geller, Mark and Santo, Niccolo Dal and Anklin, Valentin and Merey, Majd Al and Baeuml, Martin and Strohman, Trevor and Bai, Junwen and Petrov, Slav and Wu, Yonghui and Hassabis, Demis and Kavukcuoglu, Koray and Dean, Jeff and Vinyals, Oriol},
  year = {2024},
  month = dec,
  number = {arXiv:2403.05530},
  eprint = {2403.05530},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.05530},
  urldate = {2025-06-12},
  abstract = {In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval ({$>$}99\%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75\% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\KIDJNLXT\\Team et al. - 2024 - Gemini 1.5 Unlocking multimodal understanding across millions of tokens of context.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\DN7IGAEP\\2403.html}
}

@misc{teamGeminiFamilyHighly2024,
  title = {Gemini: {{A Family}} of {{Highly Capable Multimodal Models}}},
  shorttitle = {Gemini},
  author = {Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M. and Hauth, Anja and Millican, Katie and Silver, David and Johnson, Melvin and Antonoglou, Ioannis and Schrittwieser, Julian and Glaese, Amelia and Chen, Jilin and Pitler, Emily and Lillicrap, Timothy and Lazaridou, Angeliki and Firat, Orhan and Molloy, James and Isard, Michael and Barham, Paul R. and Hennigan, Tom and Lee, Benjamin and Viola, Fabio and Reynolds, Malcolm and Xu, Yuanzhong and Doherty, Ryan and Collins, Eli and Meyer, Clemens and Rutherford, Eliza and Moreira, Erica and Ayoub, Kareem and Goel, Megha and Krawczyk, Jack and Du, Cosmo and Chi, Ed and Cheng, Heng-Tze and Ni, Eric and Shah, Purvi and Kane, Patrick and Chan, Betty and Faruqui, Manaal and Severyn, Aliaksei and Lin, Hanzhao and Li, YaGuang and Cheng, Yong and Ittycheriah, Abe and Mahdieh, Mahdis and Chen, Mia and Sun, Pei and Tran, Dustin and Bagri, Sumit and Lakshminarayanan, Balaji and Liu, Jeremiah and Orban, Andras and G{\"u}ra, Fabian and Zhou, Hao and Song, Xinying and Boffy, Aurelien and Ganapathy, Harish and Zheng, Steven and Choe, HyunJeong and Weisz, {\'A}goston and Zhu, Tao and Lu, Yifeng and Gopal, Siddharth and Kahn, Jarrod and Kula, Maciej and Pitman, Jeff and Shah, Rushin and Taropa, Emanuel and Merey, Majd Al and Baeuml, Martin and Chen, Zhifeng and Shafey, Laurent El and Zhang, Yujing and Sercinoglu, Olcan and Tucker, George and Piqueras, Enrique and Krikun, Maxim and Barr, Iain and Savinov, Nikolay and Danihelka, Ivo and Roelofs, Becca and White, Ana{\"i}s and Andreassen, Anders and von Glehn, Tamara and Yagati, Lakshman and Kazemi, Mehran and Gonzalez, Lucas and Khalman, Misha and Sygnowski, Jakub and Frechette, Alexandre and Smith, Charlotte and Culp, Laura and Proleev, Lev and Luan, Yi and Chen, Xi and Lottes, James and Schucher, Nathan and Lebron, Federico and Rrustemi, Alban and Clay, Natalie and Crone, Phil and Kocisky, Tomas and Zhao, Jeffrey and Perz, Bartek and Yu, Dian and Howard, Heidi and Bloniarz, Adam and Rae, Jack W. and Lu, Han and Sifre, Laurent and Maggioni, Marcello and Alcober, Fred and Garrette, Dan and Barnes, Megan and Thakoor, Shantanu and Austin, Jacob and {Barth-Maron}, Gabriel and Wong, William and Joshi, Rishabh and Chaabouni, Rahma and Fatiha, Deeni and Ahuja, Arun and Tomar, Gaurav Singh and Senter, Evan and Chadwick, Martin and Kornakov, Ilya and Attaluri, Nithya and Iturrate, I{\~n}aki and Liu, Ruibo and Li, Yunxuan and Cogan, Sarah and Chen, Jeremy and Jia, Chao and Gu, Chenjie and Zhang, Qiao and Grimstad, Jordan and Hartman, Ale Jakse and Garcia, Xavier and Pillai, Thanumalayan Sankaranarayana and Devlin, Jacob and Laskin, Michael and Casas, Diego de Las and Valter, Dasha and Tao, Connie and Blanco, Lorenzo and Badia, Adri{\`a} Puigdom{\`e}nech and Reitter, David and Chen, Mianna and Brennan, Jenny and Rivera, Clara and Brin, Sergey and Iqbal, Shariq and Surita, Gabriela and Labanowski, Jane and Rao, Abhi and Winkler, Stephanie and Parisotto, Emilio and Gu, Yiming and Olszewska, Kate and Addanki, Ravi and Miech, Antoine and Louis, Annie and Teplyashin, Denis and Brown, Geoff and Catt, Elliot and Balaguer, Jan and Xiang, Jackie and Wang, Pidong and Ashwood, Zoe and Briukhov, Anton and Webson, Albert and Ganapathy, Sanjay and Sanghavi, Smit and Kannan, Ajay and Chang, Ming-Wei and Stjerngren, Axel and Djolonga, Josip and Sun, Yuting and Bapna, Ankur and Aitchison, Matthew and Pejman, Pedram and Michalewski, Henryk and Yu, Tianhe and Wang, Cindy and Love, Juliette and Ahn, Junwhan and Bloxwich, Dawn and Han, Kehang and Humphreys, Peter and Sellam, Thibault and Bradbury, James and Godbole, Varun and Samangooei, Sina and Damoc, Bogdan and Kaskasoli, Alex and Arnold, S{\'e}bastien M. R. and Vasudevan, Vijay and Agrawal, Shubham and Riesa, Jason and Lepikhin, Dmitry and Tanburn, Richard and Srinivasan, Srivatsan and Lim, Hyeontaek and Hodkinson, Sarah and Shyam, Pranav and Ferret, Johan and Hand, Steven and Garg, Ankush and Paine, Tom Le and Li, Jian and Li, Yujia and Giang, Minh and Neitz, Alexander and Abbas, Zaheer and York, Sarah and Reid, Machel and Cole, Elizabeth and Chowdhery, Aakanksha and Das, Dipanjan and Rogozi{\'n}ska, Dominika and Nikolaev, Vitaliy and Sprechmann, Pablo and Nado, Zachary and Zilka, Lukas and Prost, Flavien and He, Luheng and Monteiro, Marianne and Mishra, Gaurav and Welty, Chris and Newlan, Josh and Jia, Dawei and Allamanis, Miltiadis and Hu, Clara Huiyi and de Liedekerke, Raoul and Gilmer, Justin and Saroufim, Carl and Rijhwani, Shruti and Hou, Shaobo and Shrivastava, Disha and Baddepudi, Anirudh and Goldin, Alex and Ozturel, Adnan and Cassirer, Albin and Xu, Yunhan and Sohn, Daniel and Sachan, Devendra and Amplayo, Reinald Kim and Swanson, Craig and Petrova, Dessie and Narayan, Shashi and Guez, Arthur and Brahma, Siddhartha and Landon, Jessica and Patel, Miteyan and Zhao, Ruizhe and Villela, Kevin and Wang, Luyu and Jia, Wenhao and Rahtz, Matthew and Gim{\'e}nez, Mai and Yeung, Legg and Keeling, James and Georgiev, Petko and Mincu, Diana and Wu, Boxi and Haykal, Salem and Saputro, Rachel and Vodrahalli, Kiran and Qin, James and Cankara, Zeynep and Sharma, Abhanshu and Fernando, Nick and Hawkins, Will and Neyshabur, Behnam and Kim, Solomon and Hutter, Adrian and Agrawal, Priyanka and {Castro-Ros}, Alex and van den Driessche, George and Wang, Tao and Yang, Fan and Chang, Shuo-yiin and Komarek, Paul and McIlroy, Ross and Lu{\v c}i{\'c}, Mario and Zhang, Guodong and Farhan, Wael and Sharman, Michael and Natsev, Paul and Michel, Paul and Bansal, Yamini and Qiao, Siyuan and Cao, Kris and Shakeri, Siamak and Butterfield, Christina and Chung, Justin and Rubenstein, Paul Kishan and Agrawal, Shivani and Mensch, Arthur and Soparkar, Kedar and Lenc, Karel and Chung, Timothy and Pope, Aedan and Maggiore, Loren and Kay, Jackie and Jhakra, Priya and Wang, Shibo and Maynez, Joshua and Phuong, Mary and Tobin, Taylor and Tacchetti, Andrea and Trebacz, Maja and Robinson, Kevin and Katariya, Yash and Riedel, Sebastian and Bailey, Paige and Xiao, Kefan and Ghelani, Nimesh and Aroyo, Lora and Slone, Ambrose and Houlsby, Neil and Xiong, Xuehan and Yang, Zhen and Gribovskaya, Elena and Adler, Jonas and Wirth, Mateo and Lee, Lisa and Li, Music and Kagohara, Thais and Pavagadhi, Jay and Bridgers, Sophie and Bortsova, Anna and Ghemawat, Sanjay and Ahmed, Zafarali and Liu, Tianqi and Powell, Richard and Bolina, Vijay and Iinuma, Mariko and Zablotskaia, Polina and Besley, James and Chung, Da-Woon and Dozat, Timothy and Comanescu, Ramona and Si, Xiance and Greer, Jeremy and Su, Guolong and Polacek, Martin and Kaufman, Rapha{\"e}l Lopez and Tokumine, Simon and Hu, Hexiang and Buchatskaya, Elena and Miao, Yingjie and Elhawaty, Mohamed and Siddhant, Aditya and Tomasev, Nenad and Xing, Jinwei and Greer, Christina and Miller, Helen and Ashraf, Shereen and Roy, Aurko and Zhang, Zizhao and Ma, Ada and Filos, Angelos and Besta, Milos and Blevins, Rory and Klimenko, Ted and Yeh, Chih-Kuan and Changpinyo, Soravit and Mu, Jiaqi and Chang, Oscar and Pajarskas, Mantas and Muir, Carrie and Cohen, Vered and Lan, Charline Le and Haridasan, Krishna and Marathe, Amit and Hansen, Steven and Douglas, Sholto and Samuel, Rajkumar and Wang, Mingqiu and Austin, Sophia and Lan, Chang and Jiang, Jiepu and Chiu, Justin and Lorenzo, Jaime Alonso and Sj{\"o}sund, Lars Lowe and Cevey, S{\'e}bastien and Gleicher, Zach and Avrahami, Thi and Boral, Anudhyan and Srinivasan, Hansa and Selo, Vittorio and May, Rhys and Aisopos, Konstantinos and Hussenot, L{\'e}onard and Soares, Livio Baldini and Baumli, Kate and Chang, Michael B. and Recasens, Adri{\`a} and Caine, Ben and Pritzel, Alexander and Pavetic, Filip and Pardo, Fabio and Gergely, Anita and Frye, Justin and Ramasesh, Vinay and Horgan, Dan and Badola, Kartikeya and Kassner, Nora and Roy, Subhrajit and Dyer, Ethan and Campos, V{\'i}ctor Campos and Tomala, Alex and Tang, Yunhao and Badawy, Dalia El and White, Elspeth and Mustafa, Basil and Lang, Oran and Jindal, Abhishek and Vikram, Sharad and Gong, Zhitao and Caelles, Sergi and Hemsley, Ross and Thornton, Gregory and Feng, Fangxiaoyu and Stokowiec, Wojciech and Zheng, Ce and Thacker, Phoebe and {\"U}nl{\"u}, {\c C}a{\u g}lar and Zhang, Zhishuai and Saleh, Mohammad and Svensson, James and Bileschi, Max and Patil, Piyush and Anand, Ankesh and Ring, Roman and Tsihlas, Katerina and Vezer, Arpi and Selvi, Marco and Shevlane, Toby and Rodriguez, Mikel and Kwiatkowski, Tom and Daruki, Samira and Rong, Keran and Dafoe, Allan and FitzGerald, Nicholas and {Gu-Lemberg}, Keren and Khan, Mina and Hendricks, Lisa Anne and Pellat, Marie and Feinberg, Vladimir and {Cobon-Kerr}, James and Sainath, Tara and Rauh, Maribeth and Hashemi, Sayed Hadi and Ives, Richard and Hasson, Yana and Noland, Eric and Cao, Yuan and Byrd, Nathan and Hou, Le and Wang, Qingze and Sottiaux, Thibault and Paganini, Michela and Lespiau, Jean-Baptiste and Moufarek, Alexandre and Hassan, Samer and Shivakumar, Kaushik and van Amersfoort, Joost and Mandhane, Amol and Joshi, Pratik and Goyal, Anirudh and Tung, Matthew and Brock, Andrew and Sheahan, Hannah and Misra, Vedant and Li, Cheng and Raki{\'c}evi{\'c}, Nemanja and Dehghani, Mostafa and Liu, Fangyu and Mittal, Sid and Oh, Junhyuk and Noury, Seb and Sezener, Eren and Huot, Fantine and Lamm, Matthew and Cao, Nicola De and Chen, Charlie and Mudgal, Sidharth and Stella, Romina and Brooks, Kevin and Vasudevan, Gautam and Liu, Chenxi and Chain, Mainak and Melinkeri, Nivedita and Cohen, Aaron and Wang, Venus and Seymore, Kristie and Zubkov, Sergey and Goel, Rahul and Yue, Summer and Krishnakumaran, Sai and Albert, Brian and Hurley, Nate and Sano, Motoki and Mohananey, Anhad and Joughin, Jonah and Filonov, Egor and K{\k e}pa, Tomasz and Eldawy, Yomna and Lim, Jiawern and Rishi, Rahul and Badiezadegan, Shirin and Bos, Taylor and Chang, Jerry and Jain, Sanil and Padmanabhan, Sri Gayatri Sundara and Puttagunta, Subha and Krishna, Kalpesh and Baker, Leslie and Kalb, Norbert and Bedapudi, Vamsi and Kurzrok, Adam and Lei, Shuntong and Yu, Anthony and Litvin, Oren and Zhou, Xiang and Wu, Zhichun and Sobell, Sam and Siciliano, Andrea and Papir, Alan and Neale, Robby and Bragagnolo, Jonas and Toor, Tej and Chen, Tina and Anklin, Valentin and Wang, Feiran and Feng, Richie and Gholami, Milad and Ling, Kevin and Liu, Lijuan and Walter, Jules and Moghaddam, Hamid and Kishore, Arun and Adamek, Jakub and Mercado, Tyler and Mallinson, Jonathan and Wandekar, Siddhinita and Cagle, Stephen and Ofek, Eran and Garrido, Guillermo and Lombriser, Clemens and Mukha, Maksim and Sun, Botu and Mohammad, Hafeezul Rahman and Matak, Josip and Qian, Yadi and Peswani, Vikas and Janus, Pawel and Yuan, Quan and Schelin, Leif and David, Oana and Garg, Ankur and He, Yifan and Duzhyi, Oleksii and {\"A}lgmyr, Anton and Lottaz, Timoth{\'e}e and Li, Qi and Yadav, Vikas and Xu, Luyao and Chinien, Alex and Shivanna, Rakesh and Chuklin, Aleksandr and Li, Josie and Spadine, Carrie and Wolfe, Travis and Mohamed, Kareem and Das, Subhabrata and Dai, Zihang and He, Kyle and von Dincklage, Daniel and Upadhyay, Shyam and Maurya, Akanksha and Chi, Luyan and Krause, Sebastian and Salama, Khalid and Rabinovitch, Pam G. and M, Pavan Kumar Reddy and Selvan, Aarush and Dektiarev, Mikhail and Ghiasi, Golnaz and Guven, Erdem and Gupta, Himanshu and Liu, Boyi and Sharma, Deepak and Shtacher, Idan Heimlich and Paul, Shachi and Akerlund, Oscar and Aubet, Fran{\c c}ois-Xavier and Huang, Terry and Zhu, Chen and Zhu, Eric and Teixeira, Elico and Fritze, Matthew and Bertolini, Francesco and Marinescu, Liana-Eleonora and B{\"o}lle, Martin and Paulus, Dominik and Gupta, Khyatti and Latkar, Tejasi and Chang, Max and Sanders, Jason and Wilson, Roopa and Wu, Xuewei and Tan, Yi-Xuan and Thiet, Lam Nguyen and Doshi, Tulsee and Lall, Sid and Mishra, Swaroop and Chen, Wanming and Luong, Thang and Benjamin, Seth and Lee, Jasmine and Andrejczuk, Ewa and Rabiej, Dominik and Ranjan, Vipul and Styrc, Krzysztof and Yin, Pengcheng and Simon, Jon and Harriott, Malcolm Rose and Bansal, Mudit and Robsky, Alexei and Bacon, Geoff and Greene, David and Mirylenka, Daniil and Zhou, Chen and Sarvana, Obaid and Goyal, Abhimanyu and Andermatt, Samuel and Siegler, Patrick and Horn, Ben and Israel, Assaf and Pongetti, Francesco and Chen, Chih-Wei "Louis" and Selvatici, Marco and Silva, Pedro and Wang, Kathie and Tolins, Jackson and Guu, Kelvin and Yogev, Roey and Cai, Xiaochen and Agostini, Alessandro and Shah, Maulik and Nguyen, Hung and Donnaile, Noah {\'O} and Pereira, S{\'e}bastien and Friso, Linda and Stambler, Adam and Kurzrok, Adam and Kuang, Chenkai and Romanikhin, Yan and Geller, Mark and Yan, Z. J. and Jang, Kane and Lee, Cheng-Chun and Fica, Wojciech and Malmi, Eric and Tan, Qijun and Banica, Dan and Balle, Daniel and Pham, Ryan and Huang, Yanping and Avram, Diana and Shi, Hongzhi and Singh, Jasjot and Hidey, Chris and Ahuja, Niharika and Saxena, Pranab and Dooley, Dan and Potharaju, Srividya Pranavi and O'Neill, Eileen and Gokulchandran, Anand and Foley, Ryan and Zhao, Kai and Dusenberry, Mike and Liu, Yuan and Mehta, Pulkit and Kotikalapudi, Ragha and {Safranek-Shrader}, Chalence and Goodman, Andrew and Kessinger, Joshua and Globen, Eran and Kolhar, Prateek and Gorgolewski, Chris and Ibrahim, Ali and Song, Yang and Eichenbaum, Ali and Brovelli, Thomas and Potluri, Sahitya and Lahoti, Preethi and Baetu, Cip and Ghorbani, Ali and Chen, Charles and Crawford, Andy and Pal, Shalini and Sridhar, Mukund and Gurita, Petru and Mujika, Asier and Petrovski, Igor and Cedoz, Pierre-Louis and Li, Chenmei and Chen, Shiyuan and Santo, Niccol{\`o} Dal and Goyal, Siddharth and Punjabi, Jitesh and Kappaganthu, Karthik and Kwak, Chester and LV, Pallavi and Velury, Sarmishta and Choudhury, Himadri and Hall, Jamie and Shah, Premal and Figueira, Ricardo and Thomas, Matt and Lu, Minjie and Zhou, Ting and Kumar, Chintu and Jurdi, Thomas and Chikkerur, Sharat and Ma, Yenai and Yu, Adams and Kwak, Soo and {\"A}hdel, Victor and Rajayogam, Sujeevan and Choma, Travis and Liu, Fei and Barua, Aditya and Ji, Colin and Park, Ji Ho and Hellendoorn, Vincent and Bailey, Alex and Bilal, Taylan and Zhou, Huanjie and Khatir, Mehrdad and Sutton, Charles and Rzadkowski, Wojciech and Macintosh, Fiona and Shagin, Konstantin and Medina, Paul and Liang, Chen and Zhou, Jinjing and Shah, Pararth and Bi, Yingying and Dankovics, Attila and Banga, Shipra and Lehmann, Sabine and Bredesen, Marissa and Lin, Zifan and Hoffmann, John Eric and Lai, Jonathan and Chung, Raynald and Yang, Kai and Balani, Nihal and Bra{\v z}inskas, Arthur and Sozanschi, Andrei and Hayes, Matthew and Alcalde, H{\'e}ctor Fern{\'a}ndez and Makarov, Peter and Chen, Will and Stella, Antonio and Snijders, Liselotte and Mandl, Michael and K{\"a}rrman, Ante and Nowak, Pawe{\l} and Wu, Xinyi and Dyck, Alex and Vaidyanathan, Krishnan and R, Raghavender and Mallet, Jessica and Rudominer, Mitch and Johnston, Eric and Mittal, Sushil and Udathu, Akhil and Christensen, Janara and Verma, Vishal and Irving, Zach and Santucci, Andreas and Elsayed, Gamaleldin and Davoodi, Elnaz and Georgiev, Marin and Tenney, Ian and Hua, Nan and Cideron, Geoffrey and Leurent, Edouard and Alnahlawi, Mahmoud and Georgescu, Ionut and Wei, Nan and Zheng, Ivy and Scandinaro, Dylan and Jiang, Heinrich and Snoek, Jasper and Sundararajan, Mukund and Wang, Xuezhi and Ontiveros, Zack and Karo, Itay and Cole, Jeremy and Rajashekhar, Vinu and Tumeh, Lara and {Ben-David}, Eyal and Jain, Rishub and Uesato, Jonathan and Datta, Romina and Bunyan, Oskar and Wu, Shimu and Zhang, John and Stanczyk, Piotr and Zhang, Ye and Steiner, David and Naskar, Subhajit and Azzam, Michael and Johnson, Matthew and Paszke, Adam and Chiu, Chung-Cheng and Elias, Jaume Sanchez and Mohiuddin, Afroz and Muhammad, Faizan and Miao, Jin and Lee, Andrew and Vieillard, Nino and Park, Jane and Zhang, Jiageng and Stanway, Jeff and Garmon, Drew and Karmarkar, Abhijit and Dong, Zhe and Lee, Jong and Kumar, Aviral and Zhou, Luowei and Evens, Jonathan and Isaac, William and Irving, Geoffrey and Loper, Edward and Fink, Michael and Arkatkar, Isha and Chen, Nanxin and Shafran, Izhak and Petrychenko, Ivan and Chen, Zhe and Jia, Johnson and Levskaya, Anselm and Zhu, Zhenkai and Grabowski, Peter and Mao, Yu and Magni, Alberto and Yao, Kaisheng and Snaider, Javier and Casagrande, Norman and Palmer, Evan and Suganthan, Paul and Casta{\~n}o, Alfonso and Giannoumis, Irene and Kim, Wooyeol and Rybi{\'n}ski, Miko{\l}aj and Sreevatsa, Ashwin and Prendki, Jennifer and Soergel, David and Goedeckemeyer, Adrian and Gierke, Willi and Jafari, Mohsen and Gaba, Meenu and Wiesner, Jeremy and Wright, Diana Gage and Wei, Yawen and Vashisht, Harsha and Kulizhskaya, Yana and Hoover, Jay and Le, Maigo and Li, Lu and Iwuanyanwu, Chimezie and Liu, Lu and Ramirez, Kevin and Khorlin, Andrey and Cui, Albert and LIN, Tian and Wu, Marcus and Aguilar, Ricardo and Pallo, Keith and Chakladar, Abhishek and Perng, Ginger and Abellan, Elena Allica and Zhang, Mingyang and Dasgupta, Ishita and Kushman, Nate and Penchev, Ivo and Repina, Alena and Wu, Xihui and van der Weide, Tom and Ponnapalli, Priya and Kaplan, Caroline and Simsa, Jiri and Li, Shuangfeng and Dousse, Olivier and Yang, Fan and Piper, Jeff and Ie, Nathan and Pasumarthi, Rama and Lintz, Nathan and Vijayakumar, Anitha and Andor, Daniel and Valenzuela, Pedro and Lui, Minnie and Paduraru, Cosmin and Peng, Daiyi and Lee, Katherine and Zhang, Shuyuan and Greene, Somer and Nguyen, Duc Dung and Kurylowicz, Paula and Hardin, Cassidy and Dixon, Lucas and Janzer, Lili and Choo, Kiam and Feng, Ziqiang and Zhang, Biao and Singhal, Achintya and Du, Dayou and McKinnon, Dan and Antropova, Natasha and Bolukbasi, Tolga and Keller, Orgad and Reid, David and Finchelstein, Daniel and Raad, Maria Abi and Crocker, Remi and Hawkins, Peter and Dadashi, Robert and Gaffney, Colin and Franko, Ken and Bulanova, Anna and Leblond, R{\'e}mi and Chung, Shirley and Askham, Harry and Cobo, Luis C. and Xu, Kelvin and Fischer, Felix and Xu, Jun and Sorokin, Christina and Alberti, Chris and Lin, Chu-Cheng and Evans, Colin and Dimitriev, Alek and Forbes, Hannah and Banarse, Dylan and Tung, Zora and Omernick, Mark and Bishop, Colton and Sterneck, Rachel and Jain, Rohan and Xia, Jiawei and Amid, Ehsan and Piccinno, Francesco and Wang, Xingyu and Banzal, Praseem and Mankowitz, Daniel J. and Polozov, Alex and Krakovna, Victoria and Brown, Sasha and Bateni, MohammadHossein and Duan, Dennis and Firoiu, Vlad and Thotakuri, Meghana and Natan, Tom and Geist, Matthieu and tan Girgin, Ser and Li, Hui and Ye, Jiayu and Roval, Ofir and Tojo, Reiko and Kwong, Michael and {Lee-Thorp}, James and Yew, Christopher and Sinopalnikov, Danila and Ramos, Sabela and Mellor, John and Sharma, Abhishek and Wu, Kathy and Miller, David and Sonnerat, Nicolas and Vnukov, Denis and Greig, Rory and Beattie, Jennifer and Caveness, Emily and Bai, Libin and Eisenschlos, Julian and Korchemniy, Alex and Tsai, Tomy and Jasarevic, Mimi and Kong, Weize and Dao, Phuong and Zheng, Zeyu and Liu, Frederick and Yang, Fan and Zhu, Rui and Teh, Tian Huey and Sanmiya, Jason and Gladchenko, Evgeny and Trdin, Nejc and Toyama, Daniel and Rosen, Evan and Tavakkol, Sasan and Xue, Linting and Elkind, Chen and Woodman, Oliver and Carpenter, John and Papamakarios, George and Kemp, Rupert and Kafle, Sushant and Grunina, Tanya and Sinha, Rishika and Talbert, Alice and Wu, Diane and {Owusu-Afriyie}, Denese and Du, Cosmo and Thornton, Chloe and {Pont-Tuset}, Jordi and Narayana, Pradyumna and Li, Jing and Fatehi, Saaber and Wieting, John and Ajmeri, Omar and Uria, Benigno and Ko, Yeongil and Knight, Laura and H{\'e}liou, Am{\'e}lie and Niu, Ning and Gu, Shane and Pang, Chenxi and Li, Yeqing and Levine, Nir and Stolovich, Ariel and {Santamaria-Fernandez}, Rebeca and Goenka, Sonam and Yustalim, Wenny and Strudel, Robin and Elqursh, Ali and Deck, Charlie and Lee, Hyo and Li, Zonglin and Levin, Kyle and Hoffmann, Raphael and {Holtmann-Rice}, Dan and Bachem, Olivier and Arora, Sho and Koh, Christy and Yeganeh, Soheil Hassas and P{\~o}der, Siim and Tariq, Mukarram and Sun, Yanhua and Ionita, Lucian and Seyedhosseini, Mojtaba and Tafti, Pouya and Liu, Zhiyu and Gulati, Anmol and Liu, Jasmine and Ye, Xinyu and Chrzaszcz, Bart and Wang, Lily and Sethi, Nikhil and Li, Tianrun and Brown, Ben and Singh, Shreya and Fan, Wei and Parisi, Aaron and Stanton, Joe and Koverkathu, Vinod and {Choquette-Choo}, Christopher A. and Li, Yunjie and Lu, T. J. and Ittycheriah, Abe and Shroff, Prakash and Varadarajan, Mani and Bahargam, Sanaz and Willoughby, Rob and Gaddy, David and Desjardins, Guillaume and Cornero, Marco and Robenek, Brona and Mittal, Bhavishya and Albrecht, Ben and Shenoy, Ashish and Moiseev, Fedor and Jacobsson, Henrik and Ghaffarkhah, Alireza and Rivi{\`e}re, Morgane and Walton, Alanna and Crepy, Cl{\'e}ment and Parrish, Alicia and Zhou, Zongwei and Farabet, Clement and Radebaugh, Carey and Srinivasan, Praveen and van der Salm, Claudia and Fidjeland, Andreas and Scellato, Salvatore and {Latorre-Chimoto}, Eri and {Klimczak-Pluci{\'n}ska}, Hanna and Bridson, David and de Cesare, Dario and Hudson, Tom and Mendolicchio, Piermaria and Walker, Lexi and Morris, Alex and Mauger, Matthew and Guseynov, Alexey and Reid, Alison and Odoom, Seth and Loher, Lucia and Cotruta, Victor and Yenugula, Madhavi and Grewe, Dominik and Petrushkina, Anastasia and Duerig, Tom and Sanchez, Antonio and Yadlowsky, Steve and Shen, Amy and Globerson, Amir and Webb, Lynette and Dua, Sahil and Li, Dong and Bhupatiraju, Surya and Hurt, Dan and Qureshi, Haroon and Agarwal, Ananth and Shani, Tomer and Eyal, Matan and Khare, Anuj and Belle, Shreyas Rammohan and Wang, Lei and Tekur, Chetan and Kale, Mihir Sanjay and Wei, Jinliang and Sang, Ruoxin and Saeta, Brennan and Liechty, Tyler and Sun, Yi and Zhao, Yao and Lee, Stephan and Nayak, Pandu and Fritz, Doug and Vuyyuru, Manish Reddy and Aslanides, John and Vyas, Nidhi and Wicke, Martin and Ma, Xiao and Eltyshev, Evgenii and Martin, Nina and Cate, Hardie and Manyika, James and Amiri, Keyvan and Kim, Yelin and Xiong, Xi and Kang, Kai and Luisier, Florian and Tripuraneni, Nilesh and Madras, David and Guo, Mandy and Waters, Austin and Wang, Oliver and Ainslie, Joshua and Baldridge, Jason and Zhang, Han and Pruthi, Garima and Bauer, Jakob and Yang, Feng and Mansour, Riham and Gelman, Jason and Xu, Yang and Polovets, George and Liu, Ji and Cai, Honglong and Chen, Warren and Sheng, XiangHai and Xue, Emily and Ozair, Sherjil and Angermueller, Christof and Li, Xiaowei and Sinha, Anoop and Wang, Weiren and Wiesinger, Julia and Koukoumidis, Emmanouil and Tian, Yuan and Iyer, Anand and Gurumurthy, Madhu and Goldenson, Mark and Shah, Parashar and Blake, M. K. and Yu, Hongkun and Urbanowicz, Anthony and Palomaki, Jennimaria and Fernando, Chrisantha and Durden, Ken and Mehta, Harsh and Momchev, Nikola and Rahimtoroghi, Elahe and Georgaki, Maria and Raul, Amit and Ruder, Sebastian and Redshaw, Morgan and Lee, Jinhyuk and Zhou, Denny and Jalan, Komal and Li, Dinghua and Hechtman, Blake and Schuh, Parker and Nasr, Milad and Milan, Kieran and Mikulik, Vladimir and Franco, Juliana and Green, Tim and Nguyen, Nam and Kelley, Joe and Mahendru, Aroma and Hu, Andrea and Howland, Joshua and Vargas, Ben and Hui, Jeffrey and Bansal, Kshitij and Rao, Vikram and Ghiya, Rakesh and Wang, Emma and Ye, Ke and Sarr, Jean Michel and Preston, Melanie Moranski and Elish, Madeleine and Li, Steve and Kaku, Aakash and Gupta, Jigar and Pasupat, Ice and Juan, Da-Cheng and Someswar, Milan and M, Tejvi and Chen, Xinyun and Amini, Aida and Fabrikant, Alex and Chu, Eric and Dong, Xuanyi and Muthal, Amruta and Buthpitiya, Senaka and Jauhari, Sarthak and Hua, Nan and Khandelwal, Urvashi and Hitron, Ayal and Ren, Jie and Rinaldi, Larissa and Drath, Shahar and Dabush, Avigail and Jiang, Nan-Jiang and Godhia, Harshal and Sachs, Uli and Chen, Anthony and Fan, Yicheng and Taitelbaum, Hagai and Noga, Hila and Dai, Zhuyun and Wang, James and Liang, Chen and Hamer, Jenny and Ferng, Chun-Sung and Elkind, Chenel and Atias, Aviel and Lee, Paulina and List{\'i}k, V{\'i}t and Carlen, Mathias and van de Kerkhof, Jan and Pikus, Marcin and Zaher, Krunoslav and M{\"u}ller, Paul and Zykova, Sasha and Stefanec, Richard and Gatsko, Vitaly and Hirnschall, Christoph and Sethi, Ashwin and Xu, Xingyu Federico and Ahuja, Chetan and Tsai, Beth and Stefanoiu, Anca and Feng, Bo and Dhandhania, Keshav and Katyal, Manish and Gupta, Akshay and Parulekar, Atharva and Pitta, Divya and Zhao, Jing and Bhatia, Vivaan and Bhavnani, Yashodha and Alhadlaq, Omar and Li, Xiaolin and Danenberg, Peter and Tu, Dennis and Pine, Alex and Filippova, Vera and Ghosh, Abhipso and Limonchik, Ben and Urala, Bhargava and Lanka, Chaitanya Krishna and Clive, Derik and Sun, Yi and Li, Edward and Wu, Hao and Hongtongsak, Kevin and Li, Ianna and Thakkar, Kalind and Omarov, Kuanysh and Majmundar, Kushal and Alverson, Michael and Kucharski, Michael and Patel, Mohak and Jain, Mudit and Zabelin, Maksim and Pelagatti, Paolo and Kohli, Rohan and Kumar, Saurabh and Kim, Joseph and Sankar, Swetha and Shah, Vineet and Ramachandruni, Lakshmi and Zeng, Xiangkai and Bariach, Ben and Weidinger, Laura and Vu, Tu and Andreev, Alek and He, Antoine and Hui, Kevin and Kashem, Sheleem and Subramanya, Amar and Hsiao, Sissie and Hassabis, Demis and Kavukcuoglu, Koray and Sadovsky, Adam and Le, Quoc and Strohman, Trevor and Wu, Yonghui and Petrov, Slav and Dean, Jeffrey and Vinyals, Oriol},
  year = {2024},
  month = jun,
  number = {arXiv:2312.11805},
  eprint = {2312.11805},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.11805},
  urldate = {2025-05-07},
  abstract = {This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\PGVPJBZP\\Team et al. - 2024 - Gemini A Family of Highly Capable Multimodal Models.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\YG3KDZHH\\2312.html}
}

@article{Transclusion2024,
  title = {Transclusion},
  year = {2024},
  month = dec,
  journal = {Wikipedia},
  urldate = {2025-05-05},
  abstract = {In computer science, transclusion is the inclusion of part or all of an electronic document into one or more other documents by reference via hypertext. Transclusion is usually performed when the referencing document is displayed, and is normally automatic and transparent to the end user. The result of transclusion is a single integrated document made of parts assembled dynamically from separate sources, possibly stored on different computers in disparate places. Transclusion facilitates modular design (using the "single source of truth" model, whether in data, code, or content): a resource  is stored once and distributed for reuse in multiple documents. Updates or corrections to a resource are then reflected in any referencing documents.  In systems where transclusion is not available, and in some situations where it is available but not desirable, substitution is often the complementary option, whereby a static copy of the "single source of truth" is integrated into the relevant document. Examples of both are provided by the ways in which they are both used in creating the content of Wikipedia, for example (see Wikipedia:Transclusion and Wikipedia:Substitution for more information). Substituted static copies introduce a different set of considerations for version control than transclusion does, but they are sometimes necessary.  Ted Nelson coined the term for his 1980 nonlinear book Literary Machines, but the idea of master copy and occurrences was applied 17 years before, in Sketchpad. Currently it is a common technique employed by textbook writers, where a single topic/subject needs to be discussed in multiple chapters. An advantage of this system in textbooks is that it helps data redundancy and keeps the book to a manageable size.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1262768825},
  file = {C:\Users\zahdehv\Zotero\storage\IRNVQUYU\Transclusion.html}
}

@misc{ullrichClaimExtractionFactChecking2025,
  title = {Claim {{Extraction}} for {{Fact-Checking}}: {{Data}}, {{Models}}, and {{Automated Metrics}}},
  shorttitle = {Claim {{Extraction}} for {{Fact-Checking}}},
  author = {Ullrich, Herbert and Mlyn{\'a}{\v r}, Tom{\'a}{\v s} and Drchal, Jan},
  year = {2025},
  month = feb,
  number = {arXiv:2502.04955},
  eprint = {2502.04955},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2502.04955},
  urldate = {2025-04-25},
  abstract = {In this paper, we explore1 the problem of Claim Extraction using one-to-many text generation methods, comparing LLMs, small summarization models finetuned for the task, and a previous NER-centric baseline QACG. As the current publications on Claim Extraction, Fact Extraction, Claim Generation and Checkworthy Claim Detection are quite scattered in their means and terminology, we compile their common objectives, releasing the FEVERFact dataset, with 17K atomic factual claims extracted from 4K contextualised Wikipedia sentences, adapted from the original FEVER. We compile the known objectives into an Evaluation framework of: Atomicity, Fluency, Decontextualization, Faithfulness checked for each generated claim separately, and Focus and Coverage measured against the full set of predicted claims for a single input. For each metric, we implement a scale using a reduction to an already-explored NLP task. We validate our metrics against human grading of generic claims, to see that the model ranking on Ffact, our hardest metric, did not change and the evaluation framework approximates human grading very closely in terms of F1 and RMSE.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\ZCHDI4P4\\Ullrich et al. - 2025 - Claim Extraction for Fact-Checking Data, Models, and Automated Metrics.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\WFDNDK5E\\2502.html}
}

@inproceedings{vandurmeOpenKnowledgeExtraction2008,
  title = {Open {{Knowledge Extraction}} through {{Compositional Language Processing}}},
  booktitle = {Semantics in {{Text Processing}}. {{STEP}} 2008 {{Conference Proceedings}}},
  author = {Van Durme, Benjamin and Schubert, Lenhart},
  editor = {Bos, Johan and Delmonte, Rodolfo},
  year = {2008},
  pages = {239--254},
  publisher = {College Publications},
  urldate = {2025-04-18},
  file = {C:\Users\zahdehv\Zotero\storage\SKNCEZIT\Van Durme and Schubert - 2008 - Open Knowledge Extraction through Compositional Language Processing.pdf}
}

@article{vanmeterCollegeStudentsTheory1994,
  title = {College Students' Theory of Note-Taking Derived from Their Perceptions of Note-Taking},
  author = {Van Meter, Peggy and Yokoi, Linda and Pressley, Michael},
  year = {1994},
  journal = {Journal of Educational Psychology},
  volume = {86},
  number = {3},
  pages = {323--338},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-2176},
  doi = {10.1037/0022-0663.86.3.323},
  abstract = {In this ethnographic interview study, college students' theory of note-taking emerged after 4 phases. The theory was confirmed in a 5th interview phase. The students' theory includes conclusions consistent with ones already in the note-taking literature, but also many insights into note-taking dynamics that have not been identified in previous research. The amalgamation of previous note-taking theory and empirical outcomes with the students' theory provides a more complete theory of self-regulated note-taking than existed previously. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {College Students,Metacognition,Note Taking,Student Attitudes,Theories},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\5NYMIK5L\\Van Meter et al. - 1994 - College students' theory of note-taking derived from their perceptions of note-taking.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\PHPKJ3DN\\1995-03561-001.html}
}

@inproceedings{wangKBLaMKnowledgeBase2024,
  title = {{{KBLaM}}: {{Knowledge Base}} Augmented {{Language Model}}},
  shorttitle = {{{KBLaM}}},
  booktitle = {The {{Thirteenth International Conference}} on {{Learning Representations}}},
  author = {Wang, Xi and Isazawa, Taketomo and Mikaelyan, Liana and Hensman, James},
  year = {2024},
  month = oct,
  urldate = {2025-03-20},
  abstract = {In this paper, we propose Knowledge Base augmented Language Model (KBLAM), a new method for augmenting Large Language Models (LLMs) with external knowledge. KBLAM works with a knowledge base (KB) constructed from a corpus of documents, transforming each piece of knowledge in the KB into continuous key-value vector pairs via pre-trained sentence encoders with linear adapters and integrating them into pre-trained LLMs via a specialized rectangular attention mechanism. Unlike Retrieval-Augmented Generation, KBLAM eliminates external retrieval modules, and unlike in-context learning, its computational overhead scales linearly with KB size rather than quadratically. Our approach enables integrating a large KB of more than 10K triples into an 8B pre-trained LLM of only 8K context window on one single A100 80GB GPU and allows for dynamic updates without model fine-tuning or retraining. Experiments demonstrate KBLAM's effectiveness in various tasks, including question-answering and open-ended reasoning, while providing interpretable insights into its use of the augmented knowledge. Code and datasets are available at https://github.com/microsoft/KBLaM/},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\5N4UXN7A\Wang et al. - 2024 - KBLaM Knowledge Base augmented Language Model.pdf}
}

@misc{wangKnowledgeEnhancedLearning2024,
  title = {A {{Knowledge Enhanced Learning}} and {{Semantic Composition Model}} for {{Multi-Claim Fact Checking}}},
  author = {Wang, Shuai and Wei, Penghui and Kong, Qingchao and Mao, Wenji},
  year = {2024},
  month = jul,
  number = {arXiv:2104.13046},
  eprint = {2104.13046},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2104.13046},
  urldate = {2025-04-25},
  abstract = {To inhibit the spread of rumorous information and its severe consequences, traditional fact checking aims at retrieving relevant evidence to verify the veracity of a given claim. Fact checking methods typically use knowledge graphs (KGs) as external repositories and develop reasoning mechanism to retrieve evidence for verifying the triple claim. However, existing methods only focus on verifying a single claim. As real-world rumorous information is more complex and a textual statement is often composed of multiple clauses (i.e. represented as multiple claims instead of a single one), multiclaim fact checking is not only necessary but more important for practical applications. Although previous methods for verifying a single triple can be applied repeatedly to verify multiple triples one by one, they ignore the contextual information implied in a multi-claim statement and could not learn the rich semantic information in the statement as a whole. In this paper, we propose an end-to-end knowledge enhanced learning and verification method for multi-claim fact checking. Our method consists of two modules, KG-based learning enhancement and multi-claim semantic composition. To fully utilize the contextual information, the KG-based learning enhancement module learns the dynamic context-specific representations via selectively aggregating relevant attributes of entities. To capture the compositional semantics of multiple triples, the multi-claim semantic composition module constructs the graph structure to model claim-level interactions, and integrates global and salient local semantics with multi-head attention. Experimental results on a real-world dataset and two benchmark datasets show the effectiveness of our method for multi-claim fact checking over KG.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence},
  file = {C:\Users\zahdehv\Zotero\storage\PUR59HHR\Wang et al. - 2024 - A Knowledge Enhanced Learning and Semantic Composition Model for Multi-Claim Fact Checking.pdf}
}

@misc{wangMetacognitivePromptingImproves2024,
  title = {Metacognitive {{Prompting Improves Understanding}} in {{Large Language Models}}},
  author = {Wang, Yuqing and Zhao, Yun},
  year = {2024},
  month = mar,
  number = {arXiv:2308.05342},
  eprint = {2308.05342},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2308.05342},
  urldate = {2025-05-06},
  abstract = {In Large Language Models (LLMs), there have been consistent advancements in task-specific performance, largely influenced by effective prompt design. Recent advancements in prompting have enhanced reasoning in logic-intensive tasks for LLMs, yet the nuanced understanding abilities of these models, crucial for processing and interpreting complex information, remain underexplored. In this study, we introduce Metacognitive Prompting (MP), a strategy inspired by human introspective reasoning processes. Using MP, LLMs undergo a systematic series of structured, self-aware evaluations, drawing on both their vast inherent knowledge and new insights. We conduct extensive experiments on four prevalent LLMs: Llama2, PaLM2, GPT-3.5, and GPT-4, across ten natural language understanding (NLU) datasets from GLUE, SuperGLUE, BLUE, and LexGLUE benchmarks. Additionally, we compare our method with chain-of-thought prompting and its advanced versions. The results show that GPT-4 consistently excels across all tasks, while other models have shown significant progress in some tasks when used in conjunction with MP. Furthermore, MP consistently outperforms existing prompting methods in both general and domain-specific NLU tasks. This study underscores the potential to amplify the understanding abilities of LLMs and highlights the benefits of mirroring human introspective reasoning in NLU tasks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\FGWJP6AE\\Wang and Zhao - 2024 - Metacognitive Prompting Improves Understanding in Large Language Models.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\E4TTXTU4\\2308.html}
}

@misc{wangPlanandSolvePromptingImproving2023,
  title = {Plan-and-{{Solve Prompting}}: {{Improving Zero-Shot Chain-of-Thought Reasoning}} by {{Large Language Models}}},
  shorttitle = {Plan-and-{{Solve Prompting}}},
  author = {Wang, Lei and Xu, Wanyu and Lan, Yihuai and Hu, Zhiqiang and Lan, Yunshi and Lee, Roy Ka-Wei and Lim, Ee-Peng},
  year = {2023},
  month = may,
  number = {arXiv:2305.04091},
  eprint = {2305.04091},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.04091},
  urldate = {2025-04-19},
  abstract = {Large language models (LLMs) have recently been shown to deliver impressive performance in various NLP tasks. To tackle multi-step reasoning tasks, few-shot chain-of-thought (CoT) prompting includes a few manually crafted step-by-step reasoning demonstrations which enable LLMs to explicitly generate reasoning steps and improve their reasoning task accuracy. To eliminate the manual effort, Zero-shot-CoT concatenates the target problem statement with "Let's think step by step" as an input prompt to LLMs. Despite the success of Zero-shot-CoT, it still suffers from three pitfalls: calculation errors, missing-step errors, and semantic misunderstanding errors. To address the missing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists of two components: first, devising a plan to divide the entire task into smaller subtasks, and then carrying out the subtasks according to the plan. To address the calculation errors and improve the quality of generated reasoning steps, we extend PS prompting with more detailed instructions and derive PS+ prompting. We evaluate our proposed prompting strategy on ten datasets across three reasoning problems. The experimental results over GPT-3 show that our proposed zero-shot prompting consistently outperforms Zero-shot-CoT across all datasets by a large margin, is comparable to or exceeds Zero-shot-Program-of-Thought Prompting, and has comparable performance with 8-shot CoT prompting on the math reasoning problem. The code can be found at https://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\CY4XM8WG\\Wang et al. - 2023 - Plan-and-Solve Prompting Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\LWYTD9W3\\2305.html}
}

@misc{wangSelfConsistencyImprovesChain2023,
  title = {Self-{{Consistency Improves Chain}} of {{Thought Reasoning}} in {{Language Models}}},
  author = {Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  year = {2023},
  month = mar,
  number = {arXiv:2203.11171},
  eprint = {2203.11171},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2203.11171},
  urldate = {2025-05-01},
  abstract = {Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It first samples a diverse set of reasoning paths instead of only taking the greedy one, and then selects the most consistent answer by marginalizing out the sampled reasoning paths. Self-consistency leverages the intuition that a complex reasoning problem typically admits multiple different ways of thinking leading to its unique correct answer. Our extensive empirical evaluation shows that self-consistency boosts the performance of chain-of-thought prompting with a striking margin on a range of popular arithmetic and commonsense reasoning benchmarks, including GSM8K (+17.9\%), SVAMP (+11.0\%), AQuA (+12.2\%), StrategyQA (+6.4\%) and ARC-challenge (+3.9\%).},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\Z977S5LC\\Wang et al. - 2023 - Self-Consistency Improves Chain of Thought Reasoning in Language Models.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\UYWQKVTB\\2203.html}
}

@inproceedings{wannerCloserLookClaim2024,
  title = {A {{Closer Look}} at {{Claim Decomposition}}},
  booktitle = {Proceedings of the 13th {{Joint Conference}} on {{Lexical}} and {{Computational Semantics}} (*{{SEM}} 2024)},
  author = {Wanner, Miriam and Ebner, Seth and Jiang, Zhengping and Dredze, Mark and Van Durme, Benjamin},
  editor = {Bollegala, Danushka and Shwartz, Vered},
  year = {2024},
  month = jun,
  pages = {153--175},
  publisher = {Association for Computational Linguistics},
  address = {Mexico City, Mexico},
  doi = {10.18653/v1/2024.starsem-1.13},
  urldate = {2025-04-12},
  abstract = {As generated text becomes more commonplace, it is increasingly important to evaluate how well-supported such text is by external knowledge sources. Many approaches for evaluating textual support rely on some method for decomposing text into its individual subclaims which are scored against a trusted reference. We investigate how various methods of claim decomposition---especially LLM-based methods---affect the result of an evaluation approach such as the recently proposed FActScore, finding that it is sensitive to the decomposition method used. This sensitivity arises because such metrics attribute overall textual support to the model that generated the text even though error can also come from the metric`s decomposition step. To measure decomposition quality, we introduce an adaptation of FActScore, which we call DecompScore. We then propose an LLM-based approach to generating decompositions inspired by Bertrand Russell`s theory of logical atomism and neo-Davidsonian semantics and demonstrate its improved decomposition quality over previous methods.},
  file = {C:\Users\zahdehv\Zotero\storage\55KZKMDG\Wanner et al. - 2024 - A Closer Look at Claim Decomposition.pdf}
}

@misc{weiChainofThoughtPromptingElicits2023,
  title = {Chain-of-{{Thought Prompting Elicits Reasoning}} in {{Large Language Models}}},
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  year = {2023},
  month = jan,
  number = {arXiv:2201.11903},
  eprint = {2201.11903},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2201.11903},
  urldate = {2025-05-01},
  abstract = {We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\CM363QRD\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\9U45NG5F\\2201.html}
}

@article{weiClaimDistillerScientificClaim,
  title = {{{ClaimDistiller}}: {{Scientific Claim Extraction}} with {{Supervised Contrastive Learning}}},
  author = {Wei, Xin},
  abstract = {The growth of scientific papers in the past decades calls for effective claim extraction tools to automatically and accurately locate key claims from unstructured text. Such claims will benefit content-wise aggregated exploration of scientific knowledge beyond the metadata level. One challenge of building such a model is how to effectively use limited labeled training data. In this paper, we compared transfer learning and contrastive learning frameworks in terms of performance, time and training data size. We found contrastive learning has better performance at a lower cost of data across all models. Our contrastivelearning-based model ClaimDistiller has the highest performance, boosting the F1 score of the base models by 3--4\%, and achieved an F1=87.45\%, improving the state-of-the-art by more than 7\% on the same benchmark data previously used for this task. The same phenomenon is observed on another benchmark dataset, and ClaimDistiller consistently has the best performance. Qualitative assessment on a small sample of out-of-domain data indicates that the model generalizes well. Our source codes and datasets can be found here: https://github.com/lamps-lab/sci-claim-distiller.},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\HEDYKG7A\Wei - ClaimDistiller Scientific Claim Extraction with Supervised Contrastive Learning.pdf}
}

@misc{wilenskyTakeNotePopular2022,
  title = {Take {{Note}}: {{Popular Study Method}} Has `{{Cornell}}' {{Written All Over It}}},
  shorttitle = {Take {{Note}}},
  author = {Wilensky, Joe},
  year = {2022},
  month = jul,
  journal = {Cornellians {\textbar} Cornell University},
  urldate = {2025-05-02},
  abstract = {University has embraced prof's '50s-era system as a key resource.},
  langid = {american},
  file = {C:\Users\zahdehv\Zotero\storage\G37ZPWNJ\cornell-notes.html}
}

@inproceedings{wrightGeneratingScientificClaims2022,
  title = {Generating {{Scientific Claims}} for {{Zero-Shot Scientific Fact Checking}}},
  booktitle = {Proceedings of the 60th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Wright, Dustin and Wadden, David and Lo, Kyle and Kuehl, Bailey and Cohan, Arman and Augenstein, Isabelle and Wang, Lucy Lu},
  editor = {Muresan, Smaranda and Nakov, Preslav and Villavicencio, Aline},
  year = {2022},
  month = may,
  pages = {2448--2460},
  publisher = {Association for Computational Linguistics},
  address = {Dublin, Ireland},
  doi = {10.18653/v1/2022.acl-long.175},
  urldate = {2025-04-12},
  abstract = {Automated scientific fact checking is difficult due to the complexity of scientific language and a lack of significant amounts of training data, as annotation requires domain expertise. To address this challenge, we propose scientific claim generation, the task of generating one or more atomic and verifiable claims from scientific sentences, and demonstrate its usefulness in zero-shot fact checking for biomedical claims. We propose CLAIMGEN-BART, a new supervised method for generating claims supported by the literature, as well as KBIN, a novel method for generating claim negations. Additionally, we adapt an existing unsupervised entity-centric method of claim generation to biomedical claims, which we call CLAIMGEN-ENTITY. Experiments on zero-shot fact checking demonstrate that both CLAIMGEN-ENTITY and CLAIMGEN-BART, coupled with KBIN, achieve up to 90\% performance of fully supervised models trained on manually annotated claims and evidence. A rigorous evaluation study demonstrates significant improvement in generated claim and negation quality over existing baselines},
  file = {C:\Users\zahdehv\Zotero\storage\LIZV6FIT\Wright et al. - 2022 - Generating Scientific Claims for Zero-Shot Scientific Fact Checking.pdf}
}

@article{wuMindsEyeLLMs2024,
  title = {Mind's {{Eye}} of {{LLMs}}: {{Visualization-of-Thought Elicits Spatial Reasoning}} in {{Large Language Models}}},
  author = {Wu, Wenshan and Mao, Shaoguang and Zhang, Yadong and Xia, Yan and Dong, Li and Cui, Lei and Wei, Furu},
  year = {2024},
  abstract = {Large language models (LLMs) have exhibited impressive performance in language comprehension and various reasoning tasks. However, their abilities in spatial reasoning, a crucial aspect of human cognition, remain relatively unexplored. Human possess a remarkable ability to create mental images of unseen objects and actions through a process known as the Mind's Eye, enabling the imagination of the unseen world. Inspired by this cognitive capacity, we propose Visualizationof-Thought (VoT) prompting. VoT aims to elicit spatial reasoning of LLMs by visualizing their reasoning traces, thereby guiding subsequent reasoning steps. We employed VoT for multi-hop spatial reasoning tasks, including natural language navigation, visual navigation, and visual tiling in 2D grid worlds. Experimental results demonstrated that VoT significantly enhances the spatial reasoning abilities of LLMs. Notably, VoT outperformed existing multimodal large language models (MLLMs) in these tasks. While VoT works surprisingly well on LLMs, the ability to generate mental images to facilitate spatial reasoning resembles the mind's eye process, suggesting its potential viability in MLLMs. Please find the dataset and codes in our project page.},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\B5BBM6YX\Wu et al. - Mind’s Eye of LLMs Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models.pdf}
}

@misc{yangBufferThoughtsThoughtAugmented2024,
  title = {Buffer of {{Thoughts}}: {{Thought-Augmented Reasoning}} with {{Large Language Models}}},
  shorttitle = {Buffer of {{Thoughts}}},
  author = {Yang, Ling and Yu, Zhaochen and Zhang, Tianjun and Cao, Shiyi and Xu, Minkai and Zhang, Wentao and Gonzalez, Joseph E. and Cui, Bin},
  year = {2024},
  month = oct,
  number = {arXiv:2406.04271},
  eprint = {2406.04271},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.04271},
  urldate = {2025-02-28},
  abstract = {We introduce Buffer of Thoughts (BoT), a novel and versatile thought-augmented reasoning approach for enhancing accuracy, efficiency and robustness of large language models (LLMs). Specifically, we propose meta-buffer to store a series of informative high-level thoughts, namely thought-template, distilled from the problem-solving processes across various tasks. Then for each problem, we retrieve a relevant thought-template and adaptively instantiate it with specific reasoning structures to conduct efficient reasoning. To guarantee the scalability and stability, we further propose buffer-manager to dynamically update the meta-buffer, thus enhancing the capacity of meta-buffer as more tasks are solved. We conduct extensive experiments on 10 challenging reasoning-intensive tasks, and achieve significant performance improvements over previous SOTA methods: 11\% on Game of 24, 20\% on Geometric Shapes and 51\% on Checkmate-in-One. Further analysis demonstrate the superior generalization ability and model robustness of our BoT, while requiring only 12\% of the cost of multi-query prompting methods (e.g., tree/graph of thoughts) on average. Notably, we find that our Llama3-8B+BoT has the potential to surpass Llama3-70B model. Our project is available at: https://github.com/YangLing0818/buffer-of-thought-llm},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {C:\Users\zahdehv\Zotero\storage\ZCWDYGCX\Yang et al. - 2024 - Buffer of Thoughts Thought-Augmented Reasoning with Large Language Models.pdf}
}

@inproceedings{yangLLMSupportedApproach2024,
  title = {An {{LLM}} Supported Approach to Ontology and Knowledge Graph Construction},
  booktitle = {2024 {{IEEE International Conference}} on {{Bioinformatics}} and {{Biomedicine}} ({{BIBM}})},
  author = {Yang, Hang and Xiao, Liang and Zhu, Rujun and Liu, Ziji and Chen, Jianxia},
  year = {2024},
  month = dec,
  pages = {5240--5246},
  issn = {2156-1133},
  doi = {10.1109/BIBM62325.2024.10822222},
  urldate = {2025-05-15},
  abstract = {The continuous development in the medical field faces multiple challenges in managing a large amount of literature and research results using traditional ontology and knowledge graph construction methods. These challenges include high labor costs, limited coverage, and poor dynamism of traditional ontology and knowledge graph construction methods. Large language models (LLMs) can solve various natural language processing tasks and can understand and generate human-like natural language, which makes automated construction of ontology expansion and knowledge graphs (KGs) possible. This paper proposes an ontology expansion method based on LLMs, using LLMs to formulate competency questions (CQs) to extend the initial ontology, and then constructing the knowledge graph based on the extended ontology. We demonstrated the feasibility of the method by creating a knowledge graph for breast cancer treatment. The combination of LLMs-based medical ontology and knowledge graph can achieve more efficient medical knowledge management and application, promoting the informatization and intelligent development of the medical field.},
  keywords = {Breast cancer treatment,Iterative methods,Knowledge graph,Knowledge graphs,Large language models,LLM,Medical services,Natural language processing,Ontologies,Ontology,Refining,Reliability,Semantic Web,Usability},
  file = {C:\Users\zahdehv\Zotero\storage\LY2PJ5NR\10822222.html}
}

@misc{yangQwen251MTechnicalReport2025,
  title = {Qwen2.5-{{1M Technical Report}}},
  author = {Yang, An and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Huang, Haoyan and Jiang, Jiandong and Tu, Jianhong and Zhang, Jianwei and Zhou, Jingren and Lin, Junyang and Dang, Kai and Yang, Kexin and Yu, Le and Li, Mei and Sun, Minmin and Zhu, Qin and Men, Rui and He, Tao and Xu, Weijia and Yin, Wenbiao and Yu, Wenyuan and Qiu, Xiafei and Ren, Xingzhang and Yang, Xinlong and Li, Yong and Xu, Zhiying and Zhang, Zipeng},
  year = {2025},
  month = jan,
  number = {arXiv:2501.15383},
  eprint = {2501.15383},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.15383},
  urldate = {2025-02-28},
  abstract = {In this report, we introduce Qwen2.5-1M, a series of models that extend the context length to 1 million tokens. Compared to the previous 128K version, the Qwen2.5-1M series have significantly enhanced long-context capabilities through long-context pretraining and post-training. Key techniques such as long data synthesis, progressive pre-training, and multi-stage supervised fine-tuning are employed to effectively enhance long-context performance while reducing training costs.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\QDCVAK9M\\Yang et al. - 2025 - Qwen2.5-1M Technical Report.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\BUAURL2A\\2501.html}
}

@misc{yaoReActSynergizingReasoning2023,
  title = {{{ReAct}}: {{Synergizing Reasoning}} and {{Acting}} in {{Language Models}}},
  shorttitle = {{{ReAct}}},
  author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  year = {2023},
  month = mar,
  number = {arXiv:2210.03629},
  eprint = {2210.03629},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2210.03629},
  urldate = {2025-04-25},
  abstract = {While large language models (LLMs) have demonstrated impressive performance across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with and gather additional information from external sources such as knowledge bases or environments. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines in addition to improved human interpretability and trustworthiness. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes prevalent issues of hallucination and error propagation in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generating human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. Furthermore, on two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34\% and 10\% respectively, while being prompted with only one or two in-context examples.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C:\Users\zahdehv\Zotero\storage\DUTJ73K9\Yao et al. - 2023 - ReAct Synergizing Reasoning and Acting in Language Models.pdf}
}

@misc{yaoTreeThoughtsDeliberate2023,
  title = {Tree of {{Thoughts}}: {{Deliberate Problem Solving}} with {{Large Language Models}}},
  shorttitle = {Tree of {{Thoughts}}},
  author = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L. and Cao, Yuan and Narasimhan, Karthik},
  year = {2023},
  month = dec,
  number = {arXiv:2305.10601},
  eprint = {2305.10601},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.10601},
  urldate = {2025-02-28},
  abstract = {Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, ``Tree of Thoughts'' (ToT), which generalizes over the popular ``Chain of Thought'' approach to prompting language models, and enables exploration over coherent units of text (``thoughts'') that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\% of tasks, our method achieved a success rate of 74\%. Code repo with all prompts: https://github.com/princeton-nlp/tree-of-thought-llm.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C:\Users\zahdehv\Zotero\storage\F8ZL6LKB\Yao et al. - 2023 - Tree of Thoughts Deliberate Problem Solving with Large Language Models.pdf}
}

@misc{yasunagaLargeLanguageModels2024,
  title = {Large {{Language Models}} as {{Analogical Reasoners}}},
  author = {Yasunaga, Michihiro and Chen, Xinyun and Li, Yujia and Pasupat, Panupong and Leskovec, Jure and Liang, Percy and Chi, Ed H. and Zhou, Denny},
  year = {2024},
  month = mar,
  number = {arXiv:2310.01714},
  eprint = {2310.01714},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.01714},
  urldate = {2025-02-28},
  abstract = {Chain-of-thought (CoT) prompting for language models demonstrates impressive performance across reasoning tasks, but typically needs labeled exemplars of the reasoning process. In this work, we introduce a new prompting approach, analogical prompting, designed to automatically guide the reasoning process of large language models. Inspired by analogical reasoning, a cognitive process in which humans draw from relevant past experiences to tackle new problems, our approach prompts language models to self-generate relevant exemplars or knowledge in the context, before proceeding to solve the given problem. This method presents several advantages: it obviates the need for labeling or retrieving exemplars, offering generality and convenience; it can also tailor the generated exemplars and knowledge to each problem, offering adaptability. Experimental results show that our approach outperforms 0-shot CoT and manual fewshot CoT in a variety of reasoning tasks, including math problem solving in GSM8K and MATH, code generation in Codeforces, and other reasoning tasks in BIG-Bench.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  file = {C:\Users\zahdehv\Zotero\storage\8MG6EJ2K\Yasunaga et al. - 2024 - Large Language Models as Analogical Reasoners.pdf}
}

@misc{zelikmanSTaRBootstrappingReasoning2022,
  title = {{{STaR}}: {{Bootstrapping Reasoning With Reasoning}}},
  shorttitle = {{{STaR}}},
  author = {Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah D.},
  year = {2022},
  month = may,
  number = {arXiv:2203.14465},
  eprint = {2203.14465},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2203.14465},
  urldate = {2025-02-28},
  abstract = {Generating step-by-step "chain-of-thought" rationales improves language model performance on complex reasoning tasks like mathematics or commonsense question-answering. However, inducing language model rationale generation currently requires either constructing massive rationale datasets or sacrificing accuracy by using only few-shot inference. We propose a technique to iteratively leverage a small number of rationale examples and a large dataset without rationales, to bootstrap the ability to perform successively more complex reasoning. This technique, the "Self-Taught Reasoner" (STaR), relies on a simple loop: generate rationales to answer many questions, prompted with a few rationale examples; if the generated answers are wrong, try again to generate a rationale given the correct answer; finetune on all the rationales that ultimately yielded correct answers; repeat. We show that STaR significantly improves performance on multiple datasets compared to a model fine-tuned to directly predict final answers, and performs comparably to finetuning a 30{\texttimes} larger state-of-the-art language model on CommensenseQA. Thus, STaR lets a model improve itself by learning from its own generated reasoning.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C:\Users\zahdehv\Zotero\storage\E4RL5HDM\Zelikman et al. - 2022 - STaR Bootstrapping Reasoning With Reasoning.pdf}
}

@misc{zhangCumulativeReasoningLarge2025,
  title = {Cumulative {{Reasoning}} with {{Large Language Models}}},
  author = {Zhang, Yifan and Yang, Jingqin and Yuan, Yang and Yao, Andrew Chi-Chih},
  year = {2025},
  month = mar,
  number = {arXiv:2308.04371},
  eprint = {2308.04371},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2308.04371},
  urldate = {2025-05-06},
  abstract = {Recent advancements in large language models (LLMs) have shown remarkable progress, yet their ability to solve complex problems remains limited. In this work, we introduce Cumulative Reasoning (CR), an approach that utilizes LLMs cumulatively and iteratively, mirroring human thought processes for problem-solving. CR decomposes tasks into smaller, manageable components and leverages previous propositions for effective composition, significantly enhancing problem-solving capabilities. We demonstrate CR's advantage through several complex reasoning tasks: it outperforms existing methods in logical inference tasks with up to a 9.3\% improvement, achieving 98.04\% accuracy on the curated FOLIO wiki dataset. In the Game of 24, it achieves 98\% accuracy, marking a 24\% improvement over the prior state-of-the-art. In solving MATH problems, CR achieves a 4.2\% increase from previous methods and a 43\% relative improvement in the most challenging level 5 problems. When incorporating a code environment with CR, we further harness LLMs' reasoning capabilities and outperform the Program of Thought (PoT) method by 38.8\%. The code is available at https://github.com/iiis-ai/cumulative-reasoning.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\ULVRFEBF\\Zhang et al. - 2025 - Cumulative Reasoning with Large Language Models.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\ID499PLL\\2308.html}
}

@misc{zhangExtractDefineCanonicalize2024,
  title = {Extract, {{Define}}, {{Canonicalize}}: {{An LLM-based Framework}} for {{Knowledge Graph Construction}}},
  shorttitle = {Extract, {{Define}}, {{Canonicalize}}},
  author = {Zhang, Bowen and Soh, Harold},
  year = {2024},
  month = oct,
  number = {arXiv:2404.03868},
  eprint = {2404.03868},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2404.03868},
  urldate = {2025-05-15},
  abstract = {In this work, we are interested in automated methods for knowledge graph creation (KGC) from input text. Progress on large language models (LLMs) has prompted a series of recent works applying them to KGC, e.g., via zero/few-shot prompting. Despite successes on small domain-specific datasets, these models face difficulties scaling up to text common in many real-world applications. A principal issue is that, in prior methods, the KG schema has to be included in the LLM prompt to generate valid triplets; larger and more complex schemas easily exceed the LLMs' context window length. Furthermore, there are scenarios where a fixed pre-defined schema is not available and we would like the method to construct a high-quality KG with a succinct self-generated schema. To address these problems, we propose a three-phase framework named Extract-Define-Canonicalize (EDC): open information extraction followed by schema definition and post-hoc canonicalization. EDC is flexible in that it can be applied to settings where a pre-defined target schema is available and when it is not; in the latter case, it constructs a schema automatically and applies self-canonicalization. To further improve performance, we introduce a trained component that retrieves schema elements relevant to the input text; this improves the LLMs' extraction performance in a retrieval-augmented generation-like manner. We demonstrate on three KGC benchmarks that EDC is able to extract high-quality triplets without any parameter tuning and with significantly larger schemas compared to prior works. Code for EDC is available at https://github.com/clear-nus/edc.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\HCQIHMR6\\Zhang and Soh - 2024 - Extract, Define, Canonicalize An LLM-based Framework for Knowledge Graph Construction.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\VPYAHBQX\\2404.html}
}

@misc{zhengTakeStepBack2024,
  title = {Take a {{Step Back}}: {{Evoking Reasoning}} via {{Abstraction}} in {{Large Language Models}}},
  shorttitle = {Take a {{Step Back}}},
  author = {Zheng, Huaixiu Steven and Mishra, Swaroop and Chen, Xinyun and Cheng, Heng-Tze and Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
  year = {2024},
  month = mar,
  number = {arXiv:2310.06117},
  eprint = {2310.06117},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.06117},
  urldate = {2025-05-02},
  abstract = {We present Step-Back Prompting, a simple prompting technique that enables LLMs to do abstractions to derive high-level concepts and first principles from instances containing specific details. Using the concepts and principles to guide reasoning, LLMs significantly improve their abilities in following a correct reasoning path towards the solution. We conduct experiments of Step-Back Prompting with PaLM-2L, GPT-4 and Llama2-70B models, and observe substantial performance gains on various challenging reasoning-intensive tasks including STEM, Knowledge QA, and Multi-Hop Reasoning. For instance, Step-Back Prompting improves PaLM-2L performance on MMLU (Physics and Chemistry) by 7\% and 11\% respectively, TimeQA by 27\%, and MuSiQue by 7\%.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\zahdehv\\Zotero\\storage\\PSU2WWXK\\Zheng et al. - 2024 - Take a Step Back Evoking Reasoning via Abstraction in Large Language Models.pdf;C\:\\Users\\zahdehv\\Zotero\\storage\\PCG79TPW\\2310.html}
}

@misc{zhouLeasttoMostPromptingEnables2023,
  title = {Least-to-{{Most Prompting Enables Complex Reasoning}} in {{Large Language Models}}},
  author = {Zhou, Denny and Sch{\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and Chi, Ed},
  year = {2023},
  month = apr,
  number = {arXiv:2205.10625},
  eprint = {2205.10625},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2205.10625},
  urldate = {2025-02-28},
  abstract = {Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. A notable finding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (including length split) with an accuracy of at least 99\% using just 14 exemplars, compared to only 16\% accuracy with chain-of-thought prompting. This is particularly noteworthy because neural-symbolic models in the literature that specialize in solving SCAN are trained on the entire training set containing over 15,000 examples. We have included prompts for all the tasks in the Appendix.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C:\Users\zahdehv\Zotero\storage\SC3WLN4Z\Zhou et al. - 2023 - Least-to-Most Prompting Enables Complex Reasoning in Large Language Models.pdf}
}

@misc{zhuangSelfTaughtAgenticLong2025,
  title = {Self-{{Taught Agentic Long Context Understanding}}},
  author = {Zhuang, Yufan and Yu, Xiaodong and Wu, Jialian and Sun, Ximeng and Wang, Ze and Liu, Jiang and Su, Yusheng and Shang, Jingbo and Liu, Zicheng and Barsoum, Emad},
  year = {2025},
  month = feb,
  number = {arXiv:2502.15920},
  eprint = {2502.15920},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2502.15920},
  urldate = {2025-02-27},
  abstract = {Answering complex, long-context questions remains a major challenge for large language models (LLMs) as it requires effective question clarifications and context retrieval. We propose Agentic Long-Context Understanding (AgenticLU), a framework designed to enhance an LLM's understanding of such queries by integrating targeted self-clarification with contextual grounding within an agentic workflow. At the core of AgenticLU is Chainof-Clarifications (CoC), where models refine their understanding through self-generated clarification questions and corresponding contextual groundings. By scaling inference as a tree search where each node represents a CoC step, we achieve 97.8\% answer recall on NarrativeQA with a search depth of up to three and a branching factor of eight. To amortize the high cost of this search process to training, we leverage the preference pairs for each step obtained by the CoC workflow and perform two-stage model finetuning: (1) supervised finetuning to learn effective decomposition strategies, and (2) direct preference optimization to enhance reasoning quality. This enables AgenticLU models to generate clarifications and retrieve relevant context effectively and efficiently in a single inference pass. Extensive experiments across seven long-context tasks demonstrate that AgenticLU significantly outperforms stateof-the-art prompting methods and specialized long-context LLMs, achieving robust multi-hop reasoning while sustaining consistent performance as context length grows.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C:\Users\zahdehv\Zotero\storage\NZPQTHCV\Zhuang et al. - 2025 - Self-Taught Agentic Long Context Understanding.pdf}
}

@article{zhuLLMsKnowledgeGraph2024,
  title = {{{LLMs}} for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities},
  shorttitle = {{{LLMs}} for Knowledge Graph Construction and Reasoning},
  author = {Zhu, Yuqi and Wang, Xiaohan and Chen, Jing and Qiao, Shuofei and Ou, Yixin and Yao, Yunzhi and Deng, Shumin and Chen, Huajun and Zhang, Ningyu},
  year = {2024},
  month = sep,
  journal = {World Wide Web},
  volume = {27},
  number = {5},
  pages = {58},
  issn = {1386-145X, 1573-1413},
  doi = {10.1007/s11280-024-01297-w},
  urldate = {2025-05-15},
  abstract = {This paper presents an exhaustive quantitative and qualitative evaluation of Large Language Models (LLMs) for Knowledge Graph (KG) construction and reasoning. We engage in experiments across eight diverse datasets, focusing on four representative tasks encompassing entity and relation extraction, event extraction, link prediction, and question-answering, thereby thoroughly exploring LLMs' performance in the domain of construction and inference. Empirically, our findings suggest that LLMs, represented by GPT-4, are more suited as inference assistants rather than few-shot information extractors. Specifically, while GPT-4 exhibits good performance in tasks related to KG construction, it excels further in reasoning tasks, surpassing fine-tuned models in certain cases. Moreover, our investigation extends to the potential generalization ability of LLMs for information extraction, leading to the proposition of a Virtual Knowledge Extraction task and the development of the corresponding VINE dataset. Based on these empirical findings, we further propose AutoKG, a multi-agent-based approach employing LLMs and external sources for KG construction and reasoning. We anticipate that this research can provide invaluable insights for future undertakings in the field of knowledge graphs.},
  langid = {english},
  file = {C:\Users\zahdehv\Zotero\storage\A4VW9T9I\Zhu et al. - 2024 - LLMs for knowledge graph construction and reasoning recent capabilities and future opportunities.pdf}
}

@misc{zhuOAgentsEmpiricalStudy2025,
  title = {{{OAgents}}: {{An Empirical Study}} of {{Building Effective Agents}}},
  shorttitle = {{{OAgents}}},
  author = {Zhu, He and Qin, Tianrui and Zhu, King and Huang, Heyuan and Guan, Yeyi and Xia, Jinxiang and Yao, Yi and Li, Hanhao and Wang, Ningning and Liu, Pai and Peng, Tianhao and Gui, Xin and Li, Xiaowan and Liu, Yuhui and Jiang, Yuchen Eleanor and Wang, Jun and Zhang, Changwang and Tang, Xiangru and Zhang, Ge and Yang, Jian and Liu, Minghao and Gao, Xitong and Liu, Jiaheng and Zhou, Wangchunshu},
  year = {2025},
  month = jun,
  number = {arXiv:2506.15741},
  eprint = {2506.15741},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2506.15741},
  urldate = {2025-06-25},
  abstract = {Recently, Agentic AI has become an increasingly popular research field. However, we argue that current agent research practices lack standardization and scientific rigor, making it hard to conduct fair comparisons among methods. As a result, it is still unclear how different design choices in agent frameworks affect effectiveness, and measuring their progress remains challenging. In this work, we conduct a systematic empirical study on GAIA benchmark and BrowseComp to examine the impact of popular design choices in key agent components in a fair and rigorous manner. We find that the lack of a standard evaluation protocol makes previous works, even open-sourced ones, non-reproducible, with significant variance between random runs. Therefore, we introduce a more robust evaluation protocol to stabilize comparisons. Our study reveals which components and designs are crucial for effective agents, while others are redundant, despite seeming logical. Based on our findings, we build and open-source OAgents, a new foundation agent framework that achieves state-of-the-art performance among open-source projects. OAgents offers a modular design for various agent components, promoting future research in Agentic AI.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C:\Users\zahdehv\Zotero\storage\733BGSCA\Zhu et al. - 2025 - OAgents An Empirical Study of Building Effective Agents.pdf}
}
